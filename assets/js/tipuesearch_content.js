var tipuesearch = {
  "pages": [
    {
      "title": "403 Forbidden",
      "text": "403 Forbidden\u00b6\nYou are not allowed to see this content.  You are probably here because you \nare visiting a directory, and directory browsing is disabled. This site has\nrecently been reorganized and so you might have ended up here from bad link\nin a search engine.  You can try the searching using the form above or\nnavigate to my landing page.",
      "tags": "",
      "url": "https://www.kevinsheppard.com/403/"
    },
    {
      "title": "50x Internal Error",
      "text": "50x Internal Error\u00b6\nSomething has gone very badly wrong.  This is really unexpected. You can try\nthe searching using the form above or navigate to my landing page. If you\nkeep seeing this page, could you please let me know.",
      "tags": "",
      "url": "https://www.kevinsheppard.com/50x/"
    },
    {
      "title": "404 Not Found",
      "text": "404 Not Found\u00b6\nThe page you are looking for has not been found. This site has recently been reorganized\nand so you might have ended up here from bad link in a search engine.  You can try\nthe searching using the form above or navigate to my landing page.",
      "tags": "",
      "url": "https://www.kevinsheppard.com/404/"
    },
    {
      "title": "Installing Anaconda on Windows",
      "text": "",
      "tags": "",
      "url": "https://www.kevinsheppard.com/teaching/python/course/videos/anaconda-widows/"
    },
    {
      "title": "Installing Anaconda on Linux",
      "text": "",
      "tags": "",
      "url": "https://www.kevinsheppard.com/teaching/python/course/videos/anaconda-linux/"
    },
    {
      "title": "UCSD Garch",
      "text": "DEPRECATED\nThe UCSD GARCH has been deprecated and will receive no further \nupdates. Recent changes in MATLAB have broken many of the functions in \nthe UCSD GARCH toolbox. Please use the MFE Toolbox which is the \nsuccessor to the UCSD GARCH toolbox.\n\nLegacy UCSD Toolbox\u00b6\n\n\nLegacy UCSD Toolbox\nUpdates\nHelp and Documentation\nMain Univariate Mean Functions\nMain Univariate GARCH Functions\nMain Multivariate Functions\nUnivariate Mean and GARCH Simulation\nMultivaraite GARCH Simulation\nUnivariate Mean Likelihood functions\nUnivariate GARCH Likelihood Functions\nMultivariate GARCH Likelihood Functions\nDiagnostics\nKernel Smoothing Routines\nBootstrap Routines\nUnivariate Density Functions\nHelper Functions\n\n\n\n\nLicense\n\n\nBefore reporting bugs, please be sure you have the\nlatest version, have downloaded the JPL toolbox, and ARE NOT using the\nucsd_garch code from the JPL toolbox (and don't have that directory on\nyour path)\nThe UCSD_Garch toolbox is a toolbox for Matlab that is useful in\nestimating and diagnosing univariate and multivariate heteroskedasticity\nin a Time Series models. The toolbox contains C-Mex files for the\nnecessary loops in the univariate models. It is being released under a\nBSD style [license]. This means you can do pretty much what ever you\nwant to including make money by selling it.\nDownload\nUpdates\u00b6\n2.0.14: Thanks for Mark Flood who pointed out an old bug in fattailed\ngarch. Even more reason to move to the MFE Toolbox if possible.\n2.0.13: Thanks for Mark Flood who pointed out an initialization bug in\nfull_bekk_simulate.\n2.0.12: Thanks to Dennis Turk who pointed out a bug in garchcore.m.\n2.0.11: I have updated the mex files to work with more modern versions\nof MATLAB and removed the 5.3 binaries. I also replaced the missing\ntarchcore.m so that all functions in the toolbox run with or without\nusing the binary files.\n2.0.10: New versions of bsds, bsds_studentized, block_bootstrap and\nstationary_bootstrap that use the latest version of Hansen's SPA paper\n2.0.9.: Quite a few bug/inconsistencies squashed thanks to Paul Koufalas\nand Lance Young\n2.0.8: 2 bugs in dcc_mvgarch and one in egarch squashed\n2.0.7: A few more bugs squashed thanks to Hansen Chen\n2.0.6: Fixed a couple of typos in the skewt garch functions\n2.0.5: Fixed a bug in vech()\n2.0.4: There is a Matlab limitation on filename length of 31 characters\non some versions. dagonal_bekk_mvgarch_likelihood was 1 character too\nlong. It has been renamed diagonalBekkMVgarchLikelihood.\n2.0.4: A bug was found in GARCHINMEAN. It is now fixed.\n2.0.3: A huge bug was found in EGARCH. The original file was using\nvariances, not std devs. This is now fixed. Not> I am unable to build\nthe 5.3 binary as I am out of the country. For now, egarchcore.dll is\nonly available for 6 and above.\nNote: A few last minute bugs have been caught and the toolbox has been\nfixed(Again!). Please fell free to contact ma about any errors you get\nat kevin.sheppard@economics.ox.ac.uk.\nHelp and Documentation\u00b6\nUCSD_GARCH Toolbox, Version 2.0.10 21-APR-2007 \n\nucsd_garch_demo - A demo of the garch toolbox\n\nMain Univariate Mean Functions\u00b6\n\narmaxfilter - Univariate ARMAX estimation\nmafilter - Univariate MA estimation\ngarchinmean - Univariate Garch-In-Mean estimation\n\nMain Univariate GARCH Functions\u00b6\n\ngarchpq_eviews - Univariare GARCH estimation without lower bound constraints; uses a penalty funcion(similar to eviews)\nskewt_garch - Univariat GARCH estimation with skew-t residuals(Hansen)\ntarch - Univariate TARCH and GJR estimation\ngarchpq - Univariate garch estimation with analytic derivatives\nfattailed_garch - Univariate GARCH estimation with normal, Students T and Generalized Error Distribution\nmulti_garch - Univariate GARCH proceeedure to estimate a variety of GARCH specifications including AP GARCH\negarch - Exponential garch estimation with normal, Students T and Generalized Error Distribution\n\nMain Multivariate Functions\u00b6\n\ncc_mvgarch - Estimates Bollerslev's Constant Correlation MV Garch\ndcc_mvgarch - Estimates Engle and Sheppard's Dynamic Correlation MV Garch\no_mvgarch - Estimates Orthogonal or Factor MV Garch\nscalar_bekk_mvgarch - Estimates Engle and Kroner's Scalar Bekk MV Garch\ndiagonal_bekk_mvgarch - Estimates Engle and Kroner's Diagonal Bekk MV Garch\nfull_bekk_mvgarch - Estimates Engle and Kroner's Bekk MV Garch\nIdcc_mvgarch - Estimates Engle and Sheppards Integrated DCC MV Garch\nscalar_bekk_T_mvgarch - Estimates Scalar Bekk MV Garch with Multivariate T disturbances\ndiagonal_bekk_T_mvgarch - Estimates Diagonal Bekk MV Garch with Multivariate T disturbances\nfull_bekk_T_mvgarch - Estimates Full Bekk MV Garch with Multivariate T disturbances\n\nUnivariate Mean and GARCH Simulation\u00b6\n\narmaxsimulate - Simulate an ARMAX model\ngarchsimulate - Sumilate Univariate GARCH series with normal innovations\nfattailed_garchsimulate - Simulate Univariate GARCH series with Normal, Students T, or GED innovations\ngarcheviewssimulate - Simulate a GARCH process with (some)negative smoothing terms\ngarchinmeansimulate - Simulate a garch in mean model\negarchsimulate - Simulate an EGARCH model\nmultigarchSimulate - Simulate one of 8 different forms of GARCH\ndcc_univariate_simulate - likelihood function called from dcc_univariate_simulate\n\nMultivaraite GARCH Simulation\u00b6\n\nscalar_bekk_simulate - Simulate a scalar BEKK\ndiagonal_bekk_simulate - Simulate a diagonal BEKK\nfull_bekk_simulate - Simulate a full BEKK model\ncc_mvgarch_simulate - Simulates Bollerslev's Constant Correlation MV Garch\ndcc_simulate - Simulates Engle and Sheppard's Dynamic Correlation MV Garch\n\nUnivariate Mean Likelihood functions\u00b6\n\ngarchinmeanlikelihood - Likelihood funtion for garch in mean estimation\nmaxfilter_likelihood - Likelihood function for MA estimation\narmaxfilter_likelihood.m - likelihood function called from armaxfilter\n\nUnivariate GARCH Likelihood Functions\u00b6\n\ngarcheviewslikelihood - likelihood function called from garchpq_eviews\nskewt_garchlikelihood - likelihood function called from skewt_garch\nskewtdis_LL - Log likelihod of a skew T distribution(helper)\ngarchlikelihood - likelihood function called from garchpq\nfattailed_garchlikelihood - likelihood function called from fattailed_garch\nmulti_garchlikelihood - likelihood function called from multi_garch\negarchlikelihood - likelihood function called from egarch\n`tarchlikelihood\n\nMultivariate GARCH Likelihood Functions\u00b6\n\ncc_mvgarch_full_likelihood - likelihood function called from cc_mvgarch_full_likelihood\ndcc_mvgarch_full_likelihood - likelihood function called from dcc_mvgarch_full_likelihood(correct)\ndcc_mvgarch_likelihood - likelihood function called from dcc_mvgarch_likelihood(restricted)\ndiagonal_bekk_mvgarch_likelihood - likelihood function called from diagonal_bekk_mvgarch_likelihood\nfull_bekk_mvgarch_likelihood - likelihood function called from full_bekk_mvgarch_likelihood\nscalar_bekk_mvgarch_likelihood - likelihood function called from scalar_bekk_mvgarch_likelihood\nIdcc_mvgarch_full_likelihood - likelihood function called from IDCC_mvgarch_likelihood(correct)\nIdcc_mvgarch_likelihood - likelihood function called from IDCC_mvgarch_likelihood(used in estimation)\nscalar_bekk_T_est_likelihood - likelihood function called from scalar_T_bekk_mvgarch_likelihood(used in estimation)\ndiagonal_bekk_T_est_likelihood - likelihood function called from diagonal_T_bekk_mvgarch_likelihood(used in estimation)\nfull_bekk_T_est_likelihood - likelihood function called from full_T_bekk_mvgarch_likelihood(used in estimation)\nscalar_bekk_T_likelihood - likelihood function called from scalar_T_bekk_mvgarch_likelihood(correct)\ndiagonal_bekk_T_likelihood - likelihood function called from diagonal_T_bekk_mvgarch_likelihood(correct)\nfull_bekk_T_likelihood - likelihood function called from full_T_bekk_mvgarch_likelihood(correct)\n\nDiagnostics\u00b6\n\ndcc_mvgarch_test - Engle and Sheppards test for dynamic correlation\nlilliefors - Lillifors test for normality\nljq2 - Ljung-Box Q Test\nlmtest1 - Lagrange Multiplier Test for autocorrelation\nlmtest2 - Lagrange Multiplier Test for autocorrelation in the squarred residuals, an ARCH test\njarquebera - Jarque-Bera test for normality\nshapirowilks - Shapiro-Wilks Test for normality\nshapirofrancia - Shapiro-Francia Test for normality\nkolmogorov - Kolmorogov-Shmirnov non-parametric test\nberkowitz - The berkowitz transform of the KS test\n\nKernel Smoothing Routines\u00b6\n\ncosinus - Cosinus kernel\nepanechnikov - Epanechnikov kernel\nkern_dens_contour - Bivariate kernel density plot of a density contour\nkern_dens_plot - Univariate kernel density plot\nkern_dens_plot2 - 3d bivariate kernel density plot\nnormal - Normal kernel\nquartic - Quaritc kernel\ntriangular - Triangular kernel\ntriweight - Triweight kernel\nuniform - Uniform kernel\n\nBootstrap Routines\u00b6\n\nblock_bootstrap - Block time series bootstrap\nbsds - Bootstrap Data Snooper(White 2000, Hansen 2001) with upper, lower and consistent pvals\nbsds_studentized - Bootstrap Data Snooper, using studentized bootstraps(Hansen 2001)\ncont_bootstrap - Continuous Bootstrap for unit root data\nstationary_bootstrap - Stationary Bootstrap(Politis and Romano(1994)) for time series\n\nUnivariate Density Functions\u00b6\n\nexppowcdf - Exponential Power Cumulative Density Function\nexppowrnd - Exponential Power Random number generator\nexppowpdf - Exponential Power Random Probability Density Function\ngedcdf - Generalized Error Distribution Cumulative Density Function\ngedinv - Generalized Error Distribution Inverse CDF\ngedpdf - Generalized Error Distribution Probability Density Function\ngedrnd - Generalized Error Distribution Random Number Generator\nskewtdis_cdf - Skew-T Cumulative Density Function\nskewtdis_inv - Skew-T Inverse CDF\nskewtdis_pdf - Skew-T Probability Density Function\nskewtdis_rnd - Skew-T Random Number Generator\nstdtdis_cdf - Standardized T distribution(unit variance for all nu) Cumulative Density Function\nstdtdis_pdf - Standardized T distribution(unit variance for all nu) Probability Density Function\nstdtdis_rnd - Standardized T distribution(unit variance for all nu) Random Number Generator\n\nHelper Functions\u00b6\n\nkscritical - Lookup table for KS critical values\ncc_ivech - Specialized ivech for correlation matrices\nfx.mat - a data set for foreign exchange return used by the demos\nmulti_garch_paramsetup - helper function for multi_garch\nmulti_garch_constraints - helper function for multi_garch\ndcc_hessian - A modified version of HESSIAN for use in with CC_MVGARCH and DCC_MVGARCH\nivech - Creates a square lower triangular matrix, inverse of vech\nvech - Takes teh half-vec of a square matrix, inverse of ivech\nlagmatrix - Returns a matrix of lags of a dependant variable\npca - Performs Principal Componet Analysis\n\nC-MEX functions(should be compilable using any C compiler, binaries for Win32 provided)\nNOTE: WHILE .M FILESARE AVAILABLE FOR ALL OF THESE, YOU SHOULD COMPILE THESE OR USE THE PROVIDED BINARIES\nBINARIES END IN .DLL, MATLAB FUNCTIONS END IN .M, AND SOURCE ENDS IN .C\n\narmaxcore - Core routine for ARMAX\negarchcore - Core routine for EGARCH\ngarchcore - Core routine for GARCH and FATTAILED_GARCH\ngarchgrad - Core routine for GARCH derivative estimation\ngarchinmeancore - Core routine for Garch in mean estimation\nmultigarchcore - Core routine for MULTIGARCH\nivech - C version of ivech\nvech - C version of vech\nmaxcore - Core routing for MA estimation\nrecserarcore - C core for recserar\ntarchcore - Core routine for TARCH estimation\nmultigarchcore - Core routine for MULTIGARCH\n\nNOTE: This toolbox requires both MATLAB optimization toolbox and the excellent J.P.LeSage Library\navailable from www.spatial-econometrics.com\nCopyright (c) 2001-2007 Kevin Sheppard All Rights Reserved.\nLicense\u00b6\nAll of the documentation and software included in the UCSD_Garch toolbox for Matlab is copyrighted by Kevin Sheppard.\nCopyright 2001-2007 Kevin Sheppard\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. All advertising materials mentioning features or use of this software must display the following acknowledgement: This product includes software developed by the Kevin Sheppard. Neither the name of the University of California at San Diego nor Kevin Sheppard may be used to endorse or promote products derived from this software without specific prior written permission. THIS SOFTWARE IS PROVIDED BY KEVIN SHEPPARD ``AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL KEVIN SHEPPARD OR UCSD OR THE REGENTS OF THE UNIVERSITY OF CALIFORNIA BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\nThe views and conclusions contained in the software and documentation are those of the authors and should not be interpreted as representing official policies, either expressed or implied, of the Regents of the University of California or UCSD.\nPlease feel free to contact the author at kevin.k.sheppard with comments, suggestions, or bugfixes.",
      "tags": "",
      "url": "https://www.kevinsheppard.com/code/matlab/ucsd-garch/"
    },
    {
      "title": "IPython Magics",
      "text": "",
      "tags": "",
      "url": "https://www.kevinsheppard.com/teaching/python/course/videos/ipython-magics/"
    },
    {
      "title": "Getting Started with Jupyter Notebooks",
      "text": "",
      "tags": "",
      "url": "https://www.kevinsheppard.com/teaching/python/course/videos/jupyter-notebooks/"
    },
    {
      "title": "Core IPython",
      "text": "",
      "tags": "",
      "url": "https://www.kevinsheppard.com/teaching/python/course/videos/ipython/"
    },
    {
      "title": "Advanced Econometrics",
      "text": "Elective Presentation\nCourse Outline\n\nCollected Slides\u00b6\nThese downloads contain complete slide sets from the course split into two parts.  The first covers material related to data snooping bias and multiple testing in the context of technical trading.  The second covers forecasting methodologies that are suitable with large number of predictors.\n\nTechnical Trading: Fools Gold? Forecast Evaluation with Many Predictions \nForecasting with Many Predictors\n\nSyllabus\u00b6\n\nSyllabus\n\nAssessments\u00b6\n\nAssignment 1\nAssignment 1 Data - Note - You will need the password distributed in the course email to open the Excel file in this zip.\nAssignment 2\nAssignment 2 Data\n\nCourse Material\u00b6\nWeek 1\u00b6\n\n\n\nWeek\nPresentation\nHandout\nMarkup\n\n\n\n\n1\nPresentation\nHandout\nMarkup\n\n\n2\nPresentation\nHandout\nMarkup\n\n\n3\nPresentation\nHandout\nMarkup\n\n\n4\nPresentation\nHandout\nLecture 4 Demonstration\n\n\n5\nPresentation\nHandout\nMarkup\n\n\n6\nPresentation\nHandout\nMarkup\n\n\n7\nPresentation\nHandout\nMarkup\n\n\n8\nPresentation\nHandout\nMarkup\n\n\n\nReadings\u00b6\nWeek 1\u00b6\n\nChernick Ch 2\nChernick Ch 3\nChernick Ch 4 and 5\nLahiri Chs 2 and 7\nPolitis and White\nPatton, Politis and White\nKreiss and Lahiri\n\nWeek 2\u00b6\n\nBrown & Jennings (1989)\nBrock, Lakonishok & LeBaron (1992)\nBlume, Easley & O\u2019Hara (1994)\nSullivan, Timmermann & White (1999)\nLo, Mamaysky & Wang (2000)\nNeely, Rapach, Tu & Zhou (2010)\nHan, Yang & Zhou (2010)\nBajgrowicz & Scaillet (2012)\n\nWeek 3\u00b6\n\nElliott & Timmermann (2008)\nWhite (2000)\nHansen (2005)\n\nWeek 4\u00b6\n\nRomano & Wolf (2005)\nHansen, Lunde & Nason (2010)\nBajgrowicz & Scaillet (2012)\n\nWeek 8\u00b6\n\nReduced Rank Regression Demonstration Code - Shows\nhow to compute reduced rank regression and the spectral version of regularized reduced rank\nregression in simulated data.",
      "tags": "econometrics,mfe",
      "url": "https://www.kevinsheppard.com/teaching/mfe/advanced-econometrics/"
    },
    {
      "title": "Working Papers",
      "text": "Write your page here.",
      "tags": "",
      "url": "https://www.kevinsheppard.com/research/working-papers/"
    },
    {
      "title": "Publications",
      "text": "Write your page here.",
      "tags": "",
      "url": "https://www.kevinsheppard.com/research/publications/"
    },
    {
      "title": "CV - Kevin Sheppard",
      "text": "Write your page here.",
      "tags": "",
      "url": "https://www.kevinsheppard.com/research/cv/"
    },
    {
      "title": "MFE Financial Econometrics Notes",
      "text": "These notes are used in Financial Econometrics I & II in the M.Sc. in Financial Economics at the \nUniversity of Oxford.  Comments and corrections are welcome. \nNotes\u00b6\nTablet Optimized\u00b6\nThese files contain the same content as the print optimized version but are built with a \ntemplate that makes them more friendly for reading on a tablet or iPad.\n\n\n\nChapter\nPrint Optimized\nTablet Optimized\n\n\n\n\nComplete\nFinancial Econometrics\nFinancial Econometrics\n\n\n1\nChapter 1\nChapter 1\n\n\n2\nChapter 2\nChapter 2\n\n\n3\nChapter 3\nChapter 3\n\n\n4\nChapter 4\nChapter 4\n\n\n5\nChapter 5\nChapter 5\n\n\n6\nChapter 6\nChapter 6\n\n\n7\nChapter 7\nChapter 7\n\n\n8\nChapter 8\nChapter 8\n\n\n9\nChapter 9\nChapter 9\n\n\nFront Matter\nFront matter\nFront matter\n\n\nBibliography\nBibliography\nBibliography",
      "tags": "mfe",
      "url": "https://www.kevinsheppard.com/teaching/mfe/notes/"
    },
    {
      "title": "MATLAB Introduction",
      "text": "This set of notes is a detailed introduction of using MATLAB and covers virtually all aspects required to implement\nnew models in MATLAB.  It assumes no knowledge of MATLAB and coverall everything required to complete econometric\nand statistical analysis in MATLAB.\nMATLAB Notes for Econometric and Statistical Analysis\nData\u00b6\nSome sections of the notes makes use of additional data files.\nMATLAB Notes for Econometric and Statistical Analysis Data",
      "tags": "",
      "url": "https://www.kevinsheppard.com/teaching/matlab/notes/"
    },
    {
      "title": "MFE Toolbox",
      "text": "The Oxford MFE Toolbox is the follow on to the UCSD_GARCH\ntoolbox. It has been widely used by students here at Oxford, and represents a\nsubstantial improvement in robustness over the original UCSD GARCH code,\nalthough in its current form it only contains univariate routines.\n\n\nCurrent Version\nLast Updated\nUpdate News\n\n\nCode\nDocumentation\nHigh Level List of Functions\nFunctions Missing from Previous UCSD GARCH Toolbox\n\n\n\n\nCurrent Version\u00b6\nThe latest version, including any work in progress, can be downloaded on\nthe GitHub repository for the MFE Toolbox\n(Direct link to zip).\nLast Updated\u00b6\nJune 7, 2013\nUpdate News\u00b6\nMany changes have occurred since the last release. The most notable are:\n\nA major rework of the subsampling in the Realized code\nModern versions of BEKK (Scalar, Diagonal and Full) and RARCH, a\n    recent model by Diaa Noureldin, Neil Sheppard and me.\nDCC, BEKK and HEAVY are all finally available in this toolbox, and\n    so the retirement of the UCSD GARCH toolbox is almost ready.\nOGARCH and GOGARCH have been added.\nRCC, an alternative to DCC, is also available (by Diaa Noureldin,\n    Neil Sheppard and Kevin Sheppard).\n\nThe next developments should include the TODO include:\n\nSARIMA\nClean up of unused files and more coherent naming\n\nCode\u00b6\nOxford MFE Toolbox\nDocumentation\u00b6\nOxford MFE Toolbox Documentation\nHigh Level List of Functions\u00b6\n\nRegression\nARMA Simulation\nARMA Estimation\nHeterogeneous Autoregression\nInformation Criteria\n\n\nARMA Forecasting\nSample autocorrelation and partial autocorrelation\nTheoretical autocorrelation and partial autocorrelation\nTesting for serial correlation\nLjung-BoxQ Statistic\nLM Serial Correlation Test\n\n\nFiltering\nBaxter-King Filtering\nHodrick-Prescott Filtering\n\n\nRegression with Time Series Data\nLong-run Covariance Estimation\nNewey-West covariance estimation\nDen Hann-Levin covariance estimation\n\n\nNonstationary Time Series\nUnit Root Testing\nAugmented Dickey-Fuller testing\nAugmented Dickey-Fuller testing with automated lag selection\n\n\nVector Autoregressions\nGranger Causality Testing: grangercause\nImpulse Response function calculation\n\n\nVolatility Modeling\nARCH/GARCH/AVARCH/TARCH/ZARCH Simulation\nEGARCH Simulation\nAPARCH Simulation\nFIGARCH Simulation\n\n\nGARCH Model Estimation\nARCH/GARCH/GJR-GARCH/TARCH/AVGARCH/ZARCH Estimation\nEGARCH Estimation\nAPARCH Estimation\nAGARCH and NAGARCH estimation\nIGARCH estimation\nFIGARCH estimation\nHEAVY models\n\n\nDensity Estimation\nKernel Density Estimation\n\n\nDistributional Fit Testing\nJarque-Bera Test\nKolmogorov-Smirnov Test\nBerkowitz Test\n\n\nBootstraps\nBlock Bootstrap\nStationary Bootstrap\n\n\nMultiple Hypothesis Tests\nReality Check and Test for Superior Predictive Accuracy\nModel Confidence Set\n\n\nMultaivariate GARCH\nCCC MVGARCH\nScalar Variance Targetting VECH\nMATRIX GARCH\nDCC and ADCC\nOGARCH\nGOGARCH\nRARCH\n\n\nRealized Measures\nRealized Variance\nRealized Covariance\nRealized Kernels\nMultivariate Realized Kernels\nRealized Quantile Variance\nTwo-scale Realized Variance\nMulti-scale Realized Variance\nRealized Range\nQMLE Realized Variance\nMin Realized Variance, Median Realized Variance (MinRV, MedRV)\nIntegrated Quarticity Estimation\n\n\n\nFunctions Missing from Previous UCSD GARCH Toolbox\u00b6\nThe following list of function have not been updated and so if needed,\nyou should continue to use the UCSD GARCH code.\n\nGARCH in mean\nIDCC MVGARCH\nShapirowilks\nShapirofrancia",
      "tags": "",
      "url": "https://www.kevinsheppard.com/code/matlab/mfe-toolbox/"
    },
    {
      "title": "MFE MATLAB",
      "text": "Solutions are posted after the class that covers the assignment has completed.  Solutions are available both as\nMATLAB Live Scripts, which provide an integrated view of code, text and mathematics and generic m-file scripts.\nLive Scripts are only usable in recent versions of MATLAB.\n\n\nMATLAB Notes\nIntroduction\nIntroduction Solutions\n\n\nCompanion Course\nSolutions\n\n\n\n\nMATLAB Notes\u00b6\nA complete set of notes covering the core aspects of MATLAB used in\neconometric analysis serves as a reference for the companion course.\nIntroduction\u00b6\nMATLAB Introduction Course\nMATLAB Introduction Course Data\nIntroduction Solutions\u00b6\n\n\n\nMATLAB Live Script (mlx)\nMATLAB Script (m)\n\n\n\n\nImporting Data into MATLAB\nImporting Data into MATLAB\n\n\nUsing functions\nUsing functions\n\n\nAccessing elements in matrices\nAccessing elements in matrices\n\n\nProgram flow\nProgram flow\n\n\nLogical statements\nLogical statements\n\n\nTables\nTables\n\n\nGraphics\nGraphics\n\n\n\nCompanion Course\u00b6\nMATLAB Companion Course (Complete)\nSolutions\u00b6\n\nSolution Availability\nSolutions are provided in the week when a module is taught.",
      "tags": "matlab,mfe",
      "url": "https://www.kevinsheppard.com/teaching/matlab/mfe-matlab/"
    },
    {
      "title": "Presentations (Beamer) in LyX",
      "text": "",
      "tags": "lyx",
      "url": "https://www.kevinsheppard.com/teaching/lyx/beamer-presentations/"
    },
    {
      "title": "Exporting Completed Documents",
      "text": "",
      "tags": "lyx",
      "url": "https://www.kevinsheppard.com/teaching/lyx/exporting/"
    },
    {
      "title": "Adding Custom LaTeX in LyX",
      "text": "",
      "tags": "lyx",
      "url": "https://www.kevinsheppard.com/teaching/lyx/custom-latex/"
    },
    {
      "title": "The Bibliography",
      "text": "",
      "tags": "lyx",
      "url": "https://www.kevinsheppard.com/teaching/lyx/bibliography/"
    },
    {
      "title": "Figures",
      "text": "",
      "tags": "lyx",
      "url": "https://www.kevinsheppard.com/teaching/lyx/figures/"
    },
    {
      "title": "Tables",
      "text": "",
      "tags": "lyx",
      "url": "https://www.kevinsheppard.com/teaching/lyx/tables/"
    },
    {
      "title": "Adding Math",
      "text": "",
      "tags": "lyx",
      "url": "https://www.kevinsheppard.com/teaching/lyx/math/"
    },
    {
      "title": "List Environments",
      "text": "",
      "tags": "lyx",
      "url": "https://www.kevinsheppard.com/teaching/lyx/lists/"
    },
    {
      "title": "Basic Text Input",
      "text": "",
      "tags": "lyx",
      "url": "https://www.kevinsheppard.com/teaching/lyx/basic-input/"
    },
    {
      "title": "Setting up a New Document and Basic Structure",
      "text": "",
      "tags": "lyx",
      "url": "https://www.kevinsheppard.com/teaching/lyx/new-document/"
    },
    {
      "title": "Notebook Specimen",
      "text": "Jupyter Notebooks\u00b6The nbsphinx extension allow notebooks to be seemlessly integrated into a Sphinx website.  This page demonstrates how notebooks are rendered.\n\n\n\n\n\n\n\nMathematics\u00b6MathJax can use used to render mathematical equations. Equations can\nbe rendered either in their own line using double dollar signs\n$$ y_{it} = \\alpha_i + \\gamma_t + \\beta x_{it} + \\epsilon_{it} $$or inline using single dollar signs ($\\LaTeX$).\n\n\n\n\n\n\n\nDataFrames\u00b6pandas DataFrames are rendered with useful markup.\n\n\n\n\n\n\nIn\u00a0[1]:\n\n    \nimport numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame({'ints': [1, 2, 3], \n                   'floats': [np.pi, np.exp(1), (1+np.sqrt(5))/2],\n                   'strings': ['aardvark', 'bananarama', 'charcuterie' ]})\n\ndf\n\n\n    \n\n\n\n\n\n\n\n\n\n    Out[1]:\n\n\n\n\n\n\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n\n\n  \n    \n      \n      ints\n      floats\n      strings\n    \n  \n  \n    \n      0\n      1\n      3.141593\n      aardvark\n    \n    \n      1\n      2\n      2.718282\n      bananarama\n    \n    \n      2\n      3\n      1.618034\n      charcuterie\n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\nPlots and Figures\u00b6matplotlib can be used to produce plots in notebooks\nThis example comes from the matplotlib gallery.\n\n\n\n\n\n\nIn\u00a0[2]:\n\n    \n%matplotlib inline\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib import cm\n\nfig, ax = plt.subplots(figsize=(12,8))\n\ndata = np.clip(np.random.randn(250, 250), -1, 1)\n\ncax = ax.imshow(data, interpolation='nearest', cmap=cm.coolwarm)\nax.set_title('Gaussian noise with vertical colorbar', fontsize=16)\nplt.tick_params(labelsize=16)\n\n# Add colorbar, make sure to specify tick locations to match desired ticklabels\ncbar = fig.colorbar(cax, ticks=[-1, 0, 1])\ncbar.ax.set_yticklabels(['< -1', '0', '> 1'])  # vertically oriented colorbar\ncbar.ax.tick_params(labelsize=16)",
      "tags": "",
      "url": "https://www.kevinsheppard.com/notebook-specimen/"
    },
    {
      "title": "Final exam",
      "text": "Final Exam\u00b6This self-grading notebook serves as a final exam for the introductory course.\nIf you have grasped the contents of the course, you should be able to complete\nthis exam.\nIt is essential that you answer each cell by assigning the solution to QUESTION_#\nwhere # is the question number.\nWe will start with a warm-up question that is already answered.\nQuestion 0\u00b6Create a 3-element 1-dimensional array containing the values [1,1,1]\nNote: This answer is not assessed.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n# Setup: The solution is used as a model\nimport numpy as np\n\nQUESTION_0 = np.ones(3) \n\n\n    \n\n\n\n\n\n\n\nQuestion 1\u00b6Construct the correlation matrix\n$$\\left[\\begin{array}{ccc} 1 & 0.2 & 0.5 \\\\ 0.2 & 1 & 0.8 \\\\ 0.5 & 0.8 & 1 \\end{array}\\right]$$as a NumPy array.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nQuestion 2\u00b6Construct the correlation matrix\n$$\\left[\\begin{array}{ccc} 1 & 0.2 & 0.5 \\\\ 0.2 & 1 & 0.8 \\\\ 0.5 & 0.8 & 1 \\end{array}\\right]$$as a DataFrame with columns and index both equal to ['A', 'B', 'C'].\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nQuestion 3\u00b6Load the momentum data in the CSV file momentum.csv, set the column date \nas the index, and ensure that date is a DateTimeIndex.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nQuestion 4\u00b6Construct a DataFrame using the data loaded in the previous question\nthat contains the returns from momentum portfolio 5 in March and April 2016.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nQuestion 5\u00b6What is the standard deviation of the data:\n$$ 1, 3, 1, 2,9, 4, 5, 6, 10, 4 $$Note Use 1 degree of freedom in the denominator.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nQuestion 6\u00b6Compute the correlation matrix of momentum portfolios 1, 4, 6, and 10 as a DataFrame\nwhere the index and columns are the portfolio names (e.g., 'mom_01') in the order\nlisted above.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nQuestion 7\u00b6Compute the percentage of returns of each of the 10 momentum portfolios\nthat are outside of the interval\n$$ [\\hat{\\mu} - \\hat{\\sigma}, \\hat{\\mu} + \\hat{\\sigma}]$$where $\\hat{\\mu}$ is the mean and $\\hat{\\sigma}$ is the standard deviation computed using\n1 dof.  The returned variable must be a Series where the index is the portfolio\nnames ordered from 1 to 10.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nQuestion 8\u00b6Import the data the data in the sheet question 8 in final-exam.xlsx into\na DataFrame where the index contains the dates and variable name is the column\nname.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nQuestion 9\u00b6Enter the DataFrame in the table below and save it to HDF with the key 'question9'. The answer to\nthis problem must be the full path to the hdf file. The values in\nindex should be the DataFrame's index.\n\n\nindex\ndata\n\n\n\n\nA\n6.0\n\n\nE\n2.7\n\n\nG\n1.6\n\n\nP\n3.1\n\n\n\nNote: If you want to get the full path to a file saved in the current directory, \nyou can use\nimport os\n\nfile_name = 'my_file_name'\nfull_path = os.path.join(os.getcwd(), file_name)\n\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nQuestion 10\u00b6Compute the cumulative return on a portfolio the longs mom_10 and shorts mom_01. The\nfirst value should be 1 + mom_10.iloc[0] - mom_01.iloc[0]. The second cumulative\nreturn should be the first return times 1 + mom_10.iloc[1] - mom_01.iloc[1], and\nso on.  The solution must be a Series with the name 'momentum_factor' and index\nequal to the index of the momentum DataFrame.\nNote: The data in the momentum return file is in percentages, i.e., a return of\n4.2% is recorded as 4.2.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nQuestion 11\u00b6Write a function named QUESTION_11 that take 1 numerical input x and returns:\n\n$exp(x)$ is x is less than 0\n$log(1+x)$ if x is greater than or equal to 0\n\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nQuestion 12\u00b6Produce a scatter plot of the momentum returns of portfolios 1 (x-axis) and 10 using only\ndata in 2016.  Set the x limits and y limits to be tight so that the lower bound is the \nsmallest return plotted and the upper bound is the largest return plotted. Use the 'darkgrid'\ntheme from seaborn.  Assign the figure handle to QUESTION_12.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nQuestion 13\u00b6Compute the excess kurtosis of daily, weekly (using Friday and the end of the week) and monthly \nreturns on the 10 momentum portfolios using the pandas function kurt. The solution must be a\nDataFrame with the portfolio names as the index ordered form 1 to 10 and the sampling frequencies,\n'daily', 'weekly', or 'monthly' as the columns (in order). When computing weekly or monthly returns\nfrom daily data, use the sum of the daily returns.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nQuestion 14\u00b6Simulate a random walk using 100 normal observations from a\nNumPy RandomState initialized with a seed of 19991231.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nQuestion 15\u00b6Defining\n\nimport numpy as np\n\ncum_momentum = np.cumprod(1 + momentum / 100)\ncompute the ratio of the high-price to the low price in each month.  The solution\nshould be a DataFrame where the index is the last date in each month and the columns\nare the variables names.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nQuestion 16\u00b6Simulate 100 observations from the model\n$$ y_i = 0.2 + 1.2 y_{i-1} - 0.2 y_{i-2} + \\epsilon_i$$where $\\epsilon_i$ is a standard normal shock.  Set $y_0=\\epsilon_0$ and\n$y_1=\\epsilon_0 + \\epsilon_1$. The solution should be a 1-d NumPy array with 100 elements. Use\na RandomState with a seed value of 19991231.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nQuestion 17\u00b6What is the ratio of the largest eigenvalue to the smallest eigenvalue \nof the correlation matrix of the 10 momentum returns?\nNote: This is called the condition number of a matrix and is a measure of\nhow closely correlated the series are. You can compute the eigenvalues from\nthe correlation matrix using np.linalg.eigs.  See the help of this function\nfor more details.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nQuestion 18\u00b6Write a function that takes a single input 'x' and return the string\n\"The value of x is \" and the value of x. For example, if x is 3.14,\nthen the returned value should be \"The value of x is 3.14\". The function name\nmust be QUESTION_18.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nQuestion 19\u00b6Compute the percentage of days where all 10 returns are positive and subtract the\npercentage of days where all 10 momentum returns are negative on the same day.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nQuestion 20\u00b6Write the function QUESTION_20 that will take a single input s, which is a string\nand will return a Series that counts the number of times each letter in s appears in s\nwithout regard to case. Do not include spaces.  Ensure the Series returned as its index sorted.\nHints:\n\nHave a look at value_counts for a pandas Series.\nYou can iterate across the letters of a string using\n\n\nsome_string = 'abcdefg'\nfor letter in some_string:\n    do somethign with letter...\n\nstr.lower can be used to get the lower case version of a string\n\n\n\n\n\n\n\nIn\u00a0[\u00a0]:",
      "tags": "",
      "url": "https://www.kevinsheppard.com/teaching/python/course/final-exam/"
    },
    {
      "title": "Installation",
      "text": "Installing\u00b6Install Anaconda\u00b6\nDownload the Anaconda Python/R Distribution 2019.07 (or later).\nWhen the download is complete, install into your user account. \n\n\n\n\n\n\n\n\nInstall Visual Studio Code and the Python extension\u00b6\nDownload VS Code and install\nInstall the Python extension by clicking on Extensions and searching for \"Python\"\nOpen the mfe-introduction folder created in the previous step\nCreate a file called second.py and enter\n#%%\n\nprint(\"Python may be harder to learn than other languages since\")\nprint(\"there is rarely a single approach to completing a task.\")\n\n\nClick on Run Cell\n\nNote the #%% makes it a magic cell\n\n\n\n\n\n\n\nInstall Pycharm Professional\u00b6\nDownload PyCharm Professional and install using the 30-day trial. You can get a free \ncopy using your academic email address if you want to continue after the first 30 days.\nOpen PyCharm, and create a new project called mfe-introduction\nOpen File > Setting and select Python Interpreter. Select the Anaconda interpreter if it\nis not already selected.\nCreate a new python file called first.py and enter\nprint(\"Python has a steeper curve than MATLAB but more long-run upside\")\n\n\nRight-click on this file, and select \"Run\".",
      "tags": "",
      "url": "https://www.kevinsheppard.com/teaching/python/course/installation/"
    },
    {
      "title": "Lesson 1",
      "text": "Getting Started\u00b6This lesson covers:\n\nOpening a terminal window\nLaunching Jupyter notebook\nRunning IPython in a Terminal\nRunning IPython in Jupyter QtConsole\nExecuting a standalone Python file in IPython\nOptional\nJupyter notebooks in VSCode\nJupyter notebooks in PyCharm Professional\n\n\n\n\n\n\n\n\n\n\nOpening an Anaconda Terminal\u00b6An Anaconda terminal allows python to be run directly.  It also allows other\nuseful programs, for example pip, the Python package manager to be used to\ninstall packages that are not available through Anaconda.\nWindows\u00b6Launch Anaconda Prompt from the start menu.\nOSX and Linux\u00b6Open the terminal (instructions depend on your distribution). If you allowed\nconda to initialize, then you should be ready to call Anaconda\"s python and\nsupporting functions.  If not, you should\n\ncd ~/anaconda3/bin\n./conda init\nand then reopen your terminal.\n\n\n\n\n\n\n\nRunning IPython in a Terminal\u00b6\nOpen a terminal.\nRun IPython by entering ipython in the terminal window. You should see a \nwindow like the one below with the iconic In [1] indicating that you\nare at the start of a new IPython session.\n\n\n\n\n\n\n\n\n\nLaunching Jupyter notebook\u00b6\nLaunch Jupyter Notebook from the Start Menu or launcher.\nChange directory to the location where you store your notebooks.\n\n\n\n\n\n\n\n\n\nExecuting a standalone Python file in IPython\u00b6\nOpen a text editor and enter the following lines. Save the file as\nlesson-2.py. Note that Python is white-space sensitive, and so these\nlines should not not indented.\n\nfrom math import exp, log\n\nx = exp(1)\ny = log(x)\n\nprint(f\"exp(1)={x}, log(exp(1))={y}\")\n\n\nRun the code in an IPython session using %run -i lesson-2.py.  Note: you\nshould create the python file in the same directory as the notebook. \n\nIf everything works as expected, you should see\nexp(1)=2.718281828459045, log(exp(1))=1.0\n\n\n\n\n\n\n\n\nJupyter notebooks in VSCode\u00b6Visual Studio Code (or VS Code) is a\nlightweight IDE that supports adding features through extensions.  The\nkey extension for working with notebooks is \nPython extension for Visual Studio Code.\nWith this extension installed, VS code provides native support for \nJupyter notebooks.\n\nInstall VS Code and the Python extension\nOpen the command palette and enter \"create jupyter\" and select the only\navailable item.\n\nSee the screenshot below for an example of the experience of using Jupyter notebooks in \nVS Code.\n\n\n\n\n\n\n\n\nMagic Python in VSCode\u00b6Visual Studio Code supports Magic Python mode in \nstandard Python files that can be executed cell-by-cell.\n\nInstall VS Code and the Python extension\nSelect File, New and then save your file with the exteniosn .py (e.g., file.py).\nThis is a Python file that supports a cell demarcation using #%% for\ncode cells and #%% [markdown] for cells that contain markdown code.\nNote that markdown text must be either:\n\nSurrounded by triple quotes, e.g. \"\"\"markdown text\"\"\" or \"\"\"markdown text\"\"\"; e.g.,\n\"\"\"\n# Cell Heading\n\nLikeness darkness. That give brought creeping. Doesn\"t may. Fruit kind \nmidst seed. Creature, let under created void god to. Them day was Was\ncreature set it from. Fourth. Created don\"t man. Man. Light fourth\nlight given the he image first multiply after deep she\"d great. Morning \nlikeness very have give also fowl third land beast from moving thing\ncreepeth herb creeping won\"t fifth. Us bring was our beast wherein our\nvoid and green he fruit kind upon a given, saying fruit, moveth face \nforth. His you it. Good beginning hath.\n\"\"\"\n\n\nOr commented # (with a single space) at the start of each line,\n# # Cell Heading\n#\n# Likeness darkness. That give brought creeping. Doesn\"t may. Fruit kind \n# midst seed. Creature, let under created void god to. Them day was Was\n# creature set it from. Fourth. Created don\"t man. Man. Light fourth\n# light given the he image first multiply after deep she\"d great. Morning \n# likeness very have give also fowl third land beast from moving thing\n# creepeth herb creeping won\"t fifth. Us bring was our beast wherein our\n# void and green he fruit kind upon a given, saying fruit, moveth face \n# forth. His you it. Good beginning hath.\n\n\n\n\n\nThe cells have a special button above them that allows the contents to be\nexecuted and the result to be displayed in the interactive window. See the \nscreenshot below for an example of the experience of using VS Code. There \nis also an interactive console at the bottom left where commands can be \ndirectly executed.\n\n\n\n\n\n\n\n\nImporting an exiting notebook into Magic Python\u00b6VS Code only understands Magic Python files as notebook-like documents, and so\n.ipynb files must be converted to use. The process of importing is simple:\n\nOpen a Jupyter notebook file\nClick on Import in the popup that appears.\n\n\n\n\n\n\n\n\n\nExporting Magic Python to a Jupyter notebook\u00b6To export a Magic Python file, open the command palette and enter \"import jupyter\". \nSelect the option to import the notebook.\n\n\n\n\n\n\n\n\nJupyter notebooks in PyCharm Professional\u00b6\nPyCharm Professional is my recommended approach if you are going to use Python\nthroughout the course. It provides the best experience and can be acquired for\nfree using the student program.\nPyCharm Professional has deeply integrated Jupyter Notebooks. To create\nan IPython notebook:\n\nOpen PyCharm Profession\nOpen the directory where your notebooks are stored\nRight-click on the root directory and select New > Jupyter Notebook.\nGive your file a meaningful name, and it will open in the main window.\n\n\nPyCharm uses a special syntax where cells look like code and so can be edited\nlike text. This allows PyCharm to use introspection and code completion on the\ncode you have written, a highly useful set of features. PyCharm stores the\nnotebook in a Jupyter notebook file (.ipynb), which means that you can\ntrivially open it in any other Jupyter notebook aware app.  This differs from\nVS code which stores the file as a play Python\nfile (.py) and requires an explicit export to a Jupyter notebook file.\nA code cell is demarcated using #%% and a markdown cell begins with #%% md.\nBelow is a screenshot of this notebook in PyCharm.\n\nMagic Python in PyCharm\u00b6PyCharm supports Magic Python cell execution. To use Magic Python, you need\nto enable Scientific Mode in the View menu. You can then use #%% to\nindicate the start and end of cells. Individual Cells can be executed in\nthe console by pressing CTRL+Enter.\n\nIn PyCharm, right-click on the root directory and select New > Python File. Give\nyour file a meaningful name.\nEnter\n#%%\nprint(\"This is the first cell\")\n\n#%%\nprint(\"This is not executed when the first cell is run\")\n\n\nEnable Scientific Mode in the View menu.\nRun the first cell by placing you mouse in the cell and pressing CTRL+Enter.\nRun the second cell by clicking on the Play button (arrow) that appears in the\ngutter of the editor.\n\n\nNote: Magic Python in PyCharm only supports python code, and so it is\nnot possible to mix Markdown text and Python in the same file.",
      "tags": "",
      "url": "https://www.kevinsheppard.com/teaching/python/course/lesson-1/"
    },
    {
      "title": "Lesson 10",
      "text": "Accessing Elements in DataFrames\u00b6This lesson covers:\n\nAssessing specific elements in Pandas Series and DataFrames \n\nAccessing elements in an array or a DataFrame is a common task. To begin this\nlesson, clear the workspace set up some vectors and a $5\\times5$ array. These\nvectors and matrix will make it easy to determine which elements are selected\nby a command.\nStart by creating 2 DataFrame and 2 Series. Define x=np.arange(24).reshape(5,5) \nwhich is a 5 by 5 array and y=np.arange(5) which is a 5-element 1-d array.\nWe need:\n\nx_df: A default DataFrame containing x\nx_named: A DataFrame containing x with index \"r0\", \"r1\", ..., \"r4\" and\ncolumns \"c0\", \"c1\", ... \"c4\".\ny_s: A default Series containing y\ny_named: A Series containing y that has the index \"r0\", \"r1\", ..., \"r4\"\n\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Selecting a row by name\u00b6Select the 2nd row of x_name using .loc.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Selecting a column by name\u00b6Select the 2nd columns of x_name using  both [] and .loc.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Selecting a elements of a Series by name\u00b6Select the 2nd element of y_name using both [] and loc.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Selecting rows and columns by name\u00b6Select the 2nd and 4th rows and 1st and 3rd columns of x_name.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: DataFrame selection with default index and column names\u00b6Select the 2nd and 4th rows and 1st and 3rd columns of x_df.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Series selection with the default index\u00b6Select the final element in y_s\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Subseries selection\u00b6Select the subseries of y_named and y_s containing the first, fourth and fifth element.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nLoad the data in momentum.csv.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n# Setup: Load the momentum data\n\nimport pandas as pd\n\nmomentum = pd.read_csv(\"data/momentum.csv\", index_col=\"date\", parse_dates=True)\nmomentum.head()\n\n\n    \n\n\n\n\n\n\n\nProblem: Selecting data on a single day\u00b6Select returns on February 16, 2016.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Selecting data in a single month\u00b6Select return in March 2016.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Selecting data in a single year\u00b6Select return in 2016.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Selecting data in a date range\u00b6Select returns between May 1, 2016, and June 15, 2016.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:",
      "tags": "",
      "url": "https://www.kevinsheppard.com/teaching/python/course/lesson-10/"
    },
    {
      "title": "Lesson 11",
      "text": "Accessing Elements in NumPy Arrays\u00b6This lesson covers:\n\nAccessing specific elements in NumPy arrays\n\nAccessing elements in an array or a DataFrame is a common task. To begin this lesson, clear the\nworkspace set up some vectors and a $5\\times5$ array. These vectors and matrix will make it easy\nto determine which elements are selected by a command.\nUsing arange and reshape to create 3 arrays:\n\n5-by-5 array x containing the values 0,1,...,24 \n5-element, 1-dimensional array y containing 0,1,...,4\n5-by-1 array z containing 0,1,...,4\n\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nZero-based indexing\u00b6Python indexing is 0 based so that the first element has position 0, the second has position 1\nand so on until the last element has position n-1 in an array that contains n elements in\ntotal.\nProblem: Scalar selection\u00b6Select the number 2 in all three, x, y, and z.\nQuestion:  Which index is rows and which index is columns?\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Scalar selection of a single row\u00b6Select row 2 in x and z using a single integer value.\nQuestion: What is the dimension of x and the second row of x\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Slice selection of a single row\u00b6Use a slice to select the 2nd row of x and the 2nd element of y and z.\nQuestion: What are the dimension selections?\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: List selection of a single row\u00b6Use a list to select the 2nd row of x and the 2nd element of y and z.\nQuestion: What are the dimension selections?\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Selecting a single Column\u00b6Select the 2nd column of x using a scalar integer, a slice and a list.\nQuestion: What the the dimensions of the selected elemets?\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Selecting a block of specific columns\u00b6Select the 2nd and 3rd columns of x using a slice.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Selecting a block of specific rows\u00b6Select the 2nd and 4th rows of x using both a slice and a list.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Selecting a block of specific rows and columns\u00b6Combine these be combined to select columns 2 and 3 and rows 2 and 4.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Use ix_ to select rows and columns using lists\u00b6Use ix_ to select the 2nd and 4th rows and 1st and 3rd columns of x.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Convert a DataFrame to a NumPy array\u00b6Use  .to_numpy to convert a DataFrame to a NumPy array.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n# Setup: Create a DataFrame\nimport pandas as pd\nimport numpy as np\n\nnames = [\"a\", \"b\", \"c\", \"d\", \"e\"]\nx = np.arange(25).reshape((5,5))\nx_df = pd.DataFrame(x, index=names, columns=names)\nprint(x_df)\n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Use np.asarray to convert to an array\u00b6Use  np.asarray to convert a DataFrame to a NumPy array.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:",
      "tags": "",
      "url": "https://www.kevinsheppard.com/teaching/python/course/lesson-11/"
    },
    {
      "title": "Lesson 12",
      "text": "Numeric Indexing of DataFrames\u00b6This lesson covers:\n\nAccessing specific elements in DataFrames using numeric indices\n\nAccessing elements in a DataFrame is a common task. To begin this lesson,\nclear the workspace set up some vectors and a $5\\times5$ array. These vectors\nand matrix will make it easy to determine which elements are selected by a\ncommand.\nBegin by creating:\n\nA 5-by-5 DataFrame x_df containing np.arange(25).reshape((5,5)).\nA 5-element Series y_s containing np.arange(5).\nA 5-by-5 DataFrame x_named that is x_df with columns \"c0\", \"c1\", ...,\n\"c4\" and rows \"r0\", \"r1\", ..., \"r4\".\nA 5-element Series y_named with index \"r0\", \"r1\", ..., \"r4\". \n\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Picking an Element out of a DataFrame\u00b6Using double index notation, select the (0,2) and the (2,0) element of\nx_named.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Select Elements from Series\u00b6Select the 2nd element of y_named.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Selecting Rows as Series\u00b6Select the 2nd row of x_named using the colon (:) operator.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Selecting Rows as DataFrames\u00b6\nSelect the 2nd row of x_named using a slice so that the selection\nremains a DataFrame.\nRepeat using a list of indices to retain the DataFrame. \n\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Selecting Entire Columns as Series\u00b6Select the 2nd column of x_named using the colon (:) operator.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Selecting Single Columns as DataFrames\u00b6Select the 2nd column of x_named  so that the selection remains a DataFrame.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Selecting Specific Columns\u00b6Select the 2nd and 3rd columns of x_named using a slice.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Select Specific Rows\u00b6Select the 2nd and 4th rows of x_named using a slice.  Repeat the \nselection using a list of integers.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Select arbitrary rows and columns\u00b6Combine the previous selections to select columns 2 and 3 and rows 2 and 4\nof x_named.\nNote: This is the only important difference with NumPy.  Arbitrary\nrow/column selection using DataFrame.iloc is simpler but less flexible.\nprint(x_named.iloc[1:4:2, 1:3])\nprint(x_named.iloc[[1, 3],[1, 2]])\nprint(x_named.iloc[[1,3], 1:3])\n\n\n\n\n\n\n\nProblem: Mixed selection\u00b6Select the columns c1 and c2 and rows 0, 2 and 4.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Mixed selection 2\u00b6Select the rows r1 and r2 and columns 0, 2 and 4.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:",
      "tags": "",
      "url": "https://www.kevinsheppard.com/teaching/python/course/lesson-12/"
    },
    {
      "title": "Lesson 13",
      "text": "for Loops\u00b6This lesson covers:\n\nfor loops \nNested loops \n\n\n\n\n\n\n\n\nProblem: Basic For Loops\u00b6Construct a for loop to sum the numbers between 1 and N for any N. A for loop\nthat does nothing can be written:\nn = 10\nfor i in range(n):\n    pass\n\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Compute a compound return\u00b6The compound return on a bond that pays interest annually at rate r is given\nby $cr_{t}=\\prod_{i=1}{T}(1+r)=(1+r){T}$. Use a for loop compute the total\nreturn for \u00a3100 invested today for $1,2,\\ldots,10$ years. Store this variable\nin a 10 by 1 vector cr.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Simulate a random walk\u00b6(Pseudo) Normal random variables can be simulated using the command\nnp.random.standard_normal(shape) where shape is a tuple (or a scalar)\ncontaining the dimensions of the desired random numbers. Simulate 100 normals\nin a 100 by 1 vector and name the result e. Initialize a vector p\ncontaining zeros using the function zeros. Add the 1st element of e to the\nfirst element of p. Use a for loop to simulate a process\n$y_{i}=y_{i-1}+e_{i}$. When finished plot the results using\n%matplotlib inline\n\nimport matplotlib.pyplot as plt\nplt.rc('figure', figsize=(16,9))\n\nplt.plot(y)\n\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Nested Loops\u00b6Begin by loading momentum data used in an earlier lesson. Compute a\n22-day moving-window standard deviation for each of the columns. Store\nthe value at the end of the window.\nWhen finished, plot the annualized percentage standard deviations using\nplt.plot(100 * np.sqrt(252) * std_dev).\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n# Setup: Load the momentum data\n\nimport pandas as pd\nmomentum = pd.read_csv(\"data/momentum.csv\", index_col=\"date\", parse_dates=True)\nmomentum = momentum / 100  # Convert to numeric values from percentages\n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nExercises\u00b6Exercise\u00b6\nSimulate a 1000 by 10 matrix consisting of 10 standard random walks using\nboth nested loops and np.cumsum. \nPlot the results. \n\nQuestion to think about\nIf you rerun the code in this Exercise, do the results change? Why?",
      "tags": "",
      "url": "https://www.kevinsheppard.com/teaching/python/course/lesson-13/"
    },
    {
      "title": "Lesson 14",
      "text": "Logical Operators\u00b6This lesson covers:\n\nBasic logical operators \nCompound operators \n\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n# Setup: Reproducible random numbers\n\nimport numpy as np\nrs = np.random.RandomState(20000101)\n\n\n    \n\n\n\n\n\n\n\nProblem: Basic Logical Statements\u00b6Create the variables (in order)\n\nx as rs.sample(), a uniform on $[0, 1)$\ny as rs.standard_normal(), a standard normal ($N(0,1)$)\nz as rs.randint(1, 11), a uniform ranomd integer on $[1, 2,\\ldots, 10]$\n\nCheck whether each of these are above their expected value.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Using comparison operators\u00b6\nCheck if z if 7\nCheck is z is not 5\nCheck if z is greater than or equal to 9\n\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Combining booleans\u00b6\nDetermine if $2\\leq z < 8$\nDetermine if $z < 2 \\cup z \\geq 8$ using or\nRewrite 2 using not and your result from 1.\n\n\n\n\n\n\n\nIn\u00a0[\u00a0]:",
      "tags": "",
      "url": "https://www.kevinsheppard.com/teaching/python/course/lesson-14/"
    },
    {
      "title": "Lesson 15",
      "text": "Boolean Arrays\u00b6This lesson covers:\n\nCreating Boolean arrays\nCombining Boolean arrays\nall and any\n\nBegin by loading the data in momentum.csv.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n# Setup: Load the momentum data\n\nimport numpy as np\nimport pandas as pd\n\nmomentum = pd.read_csv(\"data/momentum.csv\", index_col=\"date\", parse_dates=True)\n\nprint(momentum.head())\n\nmom_01 = momentum[\"mom_01\"]\nmom_10 = momentum[\"mom_10\"]\nmom_05 = momentum[\"mom_05\"]\n\n\n    \n\n\n\n\n\n\n\nProblem: Boolean arrays\u00b6For portfolios 1 and 10, determine whether each return is $<0$ (separately).\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Combining boolean arrays\u00b6Count the number of times that the returns in both portfolio 1 and portfolio\n10 are negative. Next count the number of times that the returns in portfolios\n1 and 10 are both greater, in absolute value, that 2 times their respective\nstandard deviations.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Combining boolean arrays\u00b6For portfolios 1 and 10, count the number of times either of the returns is $<0$.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Count the frequency of negative returns\u00b6What percent of returns are negative for each of the 10 momentum portfolios?\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Use any to find large losses\u00b6Use any to determine if any of the 10 portfolios experienced a loss\ngreater than -5%.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nUse all and negation to do the same check as any.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nExercises\u00b6Exercise: all and any\u00b6Use all to determine the number of days where all of the portfolio returns\nwere negative. Use any to compute the number of days with at least 1 negative\nreturn and with no negative returns (Hint: use negation (~ or logical_not)).",
      "tags": "",
      "url": "https://www.kevinsheppard.com/teaching/python/course/lesson-15/"
    },
    {
      "title": "Lesson 16",
      "text": "Boolean Selection\u00b6This lesson covers:\n\nBoolean selection\nwhere\n\nBegin by loading the data in momentum.csv.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n# Setup: Load the momentum data\n\nimport numpy as np\nimport pandas as pd\n\nmomentum = pd.read_csv(\"data/momentum.csv\", index_col=\"date\", parse_dates=True)\n\nprint(momentum.head())\n\n\n    \n\n\n\n\n\n\n\nProblem: Selecting rows with boolean conditions\u00b6Select the rows in momentum where all returns on a day are negative.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Selecting rows\u00b6Select the rows in momentum where 50% or more of the returns on a day are negative.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Selecting columns\u00b6Select the columns in momentum what have the smallest and second smallest average returns.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Selecting rows and columns\u00b6Select the returns for the column with the single most negative return\non days where all of the returns are negative.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Selecting Elements using Logical Statements\u00b6For portfolio 1 and portfolio 10 compute the correlation when both \nreturns are negative and when both are positive.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n# Setup: Reproducible random numbers\n\nrs = np.random.RandomState(19991231)\nx = rs.randint(1, 11, size=(10,3))\nx\n\n\n    \n\n\n\n\n\n\n\nProblem: Select the columns of x that means >= $E[x]$\u00b6\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Select the rows of x that means >= $E[x]$\u00b6\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Select the rows and column of x where both have means < $E[x]$\u00b6\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Using where\u00b6Use where to select the index of the elements in portfolio 5 that are\nnegative. Next, use the where command in its two output form to determine\nwhich elements of the portfolio return matrix are less than -2%.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:",
      "tags": "",
      "url": "https://www.kevinsheppard.com/teaching/python/course/lesson-16/"
    },
    {
      "title": "Lesson 17",
      "text": "Conditional Statements\u00b6\nif-elif-else blocks\n\n\n\n\n\n\n\n\nProblem: Print value if negative\u00b6Draw a standard normal value using np.random.standard_normal and print the\nvalue if it is negative.\nNote: Rerun the cell a few time to see different output.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Print different messages based on value\u00b6Draw a standard normal value and print \"Positive\" if it is positive\nand \"Negative\" if not.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem:\u00b6Draw a standard t random variable with 2 degrees of freedom using\nnp.random.standard_t(2) and print \"Negative Outlier\" if less than -2,\n\"Positive Outlier\" if larger than 2, and \"Inlier\" if between -2 and 2.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:",
      "tags": "",
      "url": "https://www.kevinsheppard.com/teaching/python/course/lesson-17/"
    },
    {
      "title": "Lesson 18",
      "text": "Logic and Loops\u00b6This lesson covers:\n\nMixing logic and loops \n\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n# Setup: Load the momentum data\n\nimport numpy as np\nimport pandas as pd\n\nmomentum = pd.read_csv(\"data/momentum.csv\", index_col=\"date\", parse_dates=True)\n\nmom_01 = momentum.mom_01\nprint(momentum.head())\n\n\n    \n\n\n\n\n\n\n\nProblem: Logical Statements and for Loops\u00b6Use a for loop along with an if statement to simulate an asymmetric random\nwalk of the form\n$$y_{i}=y_{i-1}+e_{i}+I_{[e_{i}<0]}e_{i}$$where $I_{[e_{i}<0]}$ is known as an indicator variable that takes the value\n1 if the statement in brackets is true. Plot y. $e$ is a standard normal\nshock. Use cumsum to simulate a symmetric one (z), and plot the two using\nthe code in the cell below.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nPlot the two random walks using the code.  We will cover data visualization\nin a later lesson.\n%matplotlib inline\nimport matplotlib.pyplot as plt\nplt.plot(y)\nplt.plot(z)\nplt.legend([\"y\", \"z\"])\n\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Simulate the asymmetricc random walk without an if-then\u00b6Use boolean multiplication to simulate the same random walk without using\nan if-then statement.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n# Setup: Plot the data\n%matplotlib inline\n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Combining flow control\u00b6For momentum portfolios 1 and 10, compute the length of the runs in the\nseries. In pseudo code,\n\nStart at i=1 and define run(1) = 1\nFor i in 2,...,T, define run(i) = run(i-1) + 1 if \n$\\textrm{sgn}\\left(r_{i}\\right)=\\textrm{sgn}\\left(r_{i-1}\\right)$ else 1.\n\nYou will need to use len and zeros.\n\nCompute the length longest run in the series and the index of the\nlocation of the longest run. Was it positive or negative?\nHow many distinct runs lasted 5 or more days?\n\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nPlot the runs using\n%matplotlib inline\n\nimport matplotlib.pyplot as plt\nplt.plot(run)\n\n\n\n\n\n\n\nIn\u00a0[\u00a0]:",
      "tags": "",
      "url": "https://www.kevinsheppard.com/teaching/python/course/lesson-18/"
    },
    {
      "title": "Lesson 19",
      "text": "Importing Data\u00b6This lesson covers:\n\nImporting data \nConverting dates \n\n\n\n\n\n\n\n\nProblem: Reading in data with Dates\u00b6Read in the files GS10.csv and GS10.xls which have both been downloaded\nfrom FRED.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Converting Dates\u00b6\nLoad the CSV file without converting the dates in read_csv.\nConvert the date column, remove it from the DataFrame, and set it as the\nindex. \n\n\n\n\n\n\n\nIn\u00a0[\u00a0]:",
      "tags": "",
      "url": "https://www.kevinsheppard.com/teaching/python/course/lesson-19/"
    },
    {
      "title": "Lesson 2",
      "text": "Basic Python Types\u00b6This lesson covers:\n\nInputting scalars and strings\nLists\nTuples\nDictionaries\n\n\n\n\n\n\n\n\nProblem: Input scalar floating point and integers\u00b6\nCreate a variable called scalar_float containing $\\pi$ to 4 digits.\nCreate a variable called scalar_int containing 31415. \nPrint each value using the print function.   \n\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Create a string and an f-string\u00b6\nCreate a variable called a_string containing This is a string\nCreate a f-string the prints The value of scalar_float is 3.1415 using\nthe variable created in the previous step\nCreate two string, first containing String concatenation and the\nsecond containing is like addition, and join the two using + to produce\nString concatenation is like addition. \n\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Create a list\u00b6\nCreate a list containing scalar_float and scalar_int\nAdd a_string to the list.\nSelect the second element from the list \nSelect the the lst two elements of the list\n\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Create a list of lists\u00b6\nCreate a list containing the two lists [1, 2, 3] and [4, 5, 6]\nSelect the element 5 from the nested list\n\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Create a tuple\u00b6\nCreate a tuple containing the values (1, 2.0, \"c\")\nSelect the element \"c\" from the tuple\n\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Convert a list to a tuple and back\u00b6\nConvert the list-of-lists created to a tuple-of-tuples\nConvert the tuple-of-tuples back to a list of lists\n\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Create a dictionary\u00b6\nCreate a dictionary containing the key-value pairs \"float\" and 3.1415,\n\"int\" and 31415, and \"string\" and \"three-point-one-four-one-five\".\n\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Lookup and Change a value\u00b6\nLook up the value of \"float\".\nChange the value of \"float\" to 22 / 7.\n\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Add and remove a key\u00b6\nAdd the new key \"better_float\" with the value 3.141592.\nRemove the key \"float\" and its value.\n\n\n\n\n\n\n\nIn\u00a0[\u00a0]:",
      "tags": "",
      "url": "https://www.kevinsheppard.com/teaching/python/course/lesson-2/"
    },
    {
      "title": "Lesson 20",
      "text": "Saving and Exporting Data\u00b6This lesson covers:\n\nSaving and reloading data\n\nThis first block loads the data that was used in the previous lesson.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n# Setup: Load the data to use later\nimport pandas as pd\n\ngs10_csv = pd.read_csv(\"data/GS10.csv\", index_col=\"DATE\", parse_dates=True)\ngs10_excel = pd.read_excel(\"data/GS10.xls\", skiprows=10,\n                           index_col=\"observation_date\")\n\n\n    \n\n\n\n\n\n\n\nProblem: Export to Excel\u00b6Export gs10_csv to the Excel file gs10-exported.xlsx.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Export to CSV\u00b6Export gs10_excel to CSV.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Export to HDF\u00b6Export both to a single HDF file (the closest thing to a \"native\" format in pandas).\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Import from HDF and\u00b6Import the data saved as HDF.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:",
      "tags": "",
      "url": "https://www.kevinsheppard.com/teaching/python/course/lesson-20/"
    },
    {
      "title": "Lesson 21",
      "text": "Graphics: Line Plots\u00b6This lesson covers:\n\nBasic plotting \nSubplots \nHistograms \nScatter Plots\n\n\n\n\n\n\n\n\nPlotting in notebooks requires using a magic command, which starts with\n%, to initialize the plotting backend.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n# Setup\n%matplotlib inline\n\n\n    \n\n\n\n\n\n\n\nBegin by loading the data in hf.h5. This data set contains high-frequency\nprice data for IBM and MSFT on a single day stored as two Series. IBM is\nstored as \"IBM\" in the HDF file, and MSFT is stored as \"MSFT.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Basic Plotting\u00b6\nPlot the ibm series which contains the price of IBM. \nAdd a title and label the axes. \nAdd markers and remove the line. \n\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Subplot\u00b6Create a 2 by 1 subplot with the price of IBM in the top subplot and the\nprice of MSFT in the bottom subplot.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Plot with Dates\u00b6Use matplotlib to directly plot ibm against its index. This is a\nrepeat of a previous plot but shows how to use the plot command directly.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:",
      "tags": "",
      "url": "https://www.kevinsheppard.com/teaching/python/course/lesson-21/"
    },
    {
      "title": "Lesson 22",
      "text": "Graphics: Other Plots\u00b6This lesson covers:\n\nHistograms \nScatter Plots\n\n\n\n\n\n\n\n\nPlotting in notebooks requires using a magic command, which starts with %,\nto initialize the plotting backend.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n# Setup\n%matplotlib inline\n\n\n    \n\n\n\n\n\n\n\nBegin by loading the data in hf.h5. This data set contains high-frequency\nprice data for IBM and MSFT on a single day stored as two Series. IBM is\nstored as \"IBM\" in the HDF file, and MSFT is stored as \"MSFT.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Histogram\u00b6Produce a histogram of MSFT 1-minute returns (Hint: you have to produce\nthe 1-minute Microsoft returns first using resample and pct_change).\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Scatter Plot\u00b6Scatter the 5-minute MSFT returns against the 5-minute IBM returns.\nHint: You will need to create both 5-minute return series, merge them,\nand then plot using the combined DataFrame.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Saving plots\u00b6Save the previous plot to PNG and PDF.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:",
      "tags": "",
      "url": "https://www.kevinsheppard.com/teaching/python/course/lesson-22/"
    },
    {
      "title": "Lesson 3",
      "text": "Importing Modules\u00b6This lesson covers:\n\nModule import\n\n\n\n\n\n\n\n\nProblem: Importing Modules\u00b6Python is a general-purpose programming language and is not specialized for\nnumerical or statistical computation. The core modules that enable Python to\nstore and access data efficiently and that provide statistical algorithms are\nlocated in modules.  The most important are:\n\nNumPy (numpy) - provide the basic array block used throughout numerical\nPython\npandas (pandas) - provides DataFrames which are used to store \ndata in an easy-to-use format\nSciPy (scipy) - Basic statistics and random number generators. The most\nimportant submodule is scipy.stats\nmatplotlib (matplotlib) - graphics. The most important submodule is\nmatplotlib.pyplot.\nstatsmodels (statsmodels) - statistical models such as OLS. The most\nimportant submodules are statsmodels.api and statsmodels.tsa.api.\n\nBegin by importing the important modules.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Canonical Names\u00b6Use the as keyword to import the modules using their canonical names:\n\n\nModule\nCanonical Name\n\n\n\n\nnumpy\nnp\n\n\npandas\npd\n\n\nscipy\nsp\n\n\nscipy.stats\nstats\n\n\nmatplotlib.pyplot\nplt\n\n\nstatsmodels.api\nsm\n\n\nstatsmodels.tsa.api\ntsa\n\n\n\nImport the core modules using import module as canonical.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Importing individual functions\u00b6\nImport array, sqrt, log and exp from NumPy.\nImport OLS from statsmodels.regression.linear_model\nImport the stats module from scipy\n\n\n\n\n\n\n\nIn\u00a0[\u00a0]:",
      "tags": "",
      "url": "https://www.kevinsheppard.com/teaching/python/course/lesson-3/"
    },
    {
      "title": "Lesson 4",
      "text": "Series and DataFrames\u00b6This lesson covers:\n\nConstructing pandas Series and DataFrames \n\n\nData\u00b6September 2018 prices (adjusted closing prices) for the S&P 500 EFT (SPY),\nApple (AAPL) and Google (GOOG) are listed below:\n\n\nDate\nSPY Price\nAAPL Price\nGOOG Price\n\n\n\n\nSept4\n289.81\n228.36\n1197.00\n\n\nSept5\n289.03\n226.87\n1186.48\n\n\nSept6\n288.16\n223.10\n1171.44\n\n\nSept7\n287.60\n221.30\n1164.83\n\n\nSept10\n288.10\n218.33\n1164.64\n\n\nSept11\n289.05\n223.85\n1177.36\n\n\nSept12\n289.12\n221.07\n1162.82\n\n\nSept13\n290.83\n226.41\n1175.33\n\n\nSept14\n290.88\n223.84\n1172.53\n\n\nSept17\n289.34\n217.88\n1156.05\n\n\nSept18\n290.91\n218.24\n1161.22\n\n\nSept19\n291.44\n216.64\n1158.78\n\n\n\nPrices in September 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProblem: Input a pandas Series\u00b6Create vectors for each of the days in the Table named sep_xx\nwhere xx is the numeric date. For example,\nimport pandas as pd\n\nsep_04 = pd.Series([289.81,228.36,1197.00], index=[\"SPY\",\"AAPL\",\"GOOG\"]);\n\nUsing the ticker names as the index of each series\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Create a Vector of Dates\u00b6Use the pandas function pd.to_datetime to convert a list of string dates to\na pandas DateTimeIndex, which can be used to set dates in other arrays.\nFor example, the first two dates are\nimport pandas as pd\n\ndates_2 = pd.to_datetime([\"4-9-2018\",\"5-9-2018\"])\nprint(dates_2)\n\nwhich produces\n\nDatetimeIndex([\"2018-04-09\", \"2018-05-09\"], dtype=\"datetime64[ns]\", freq=None)\nCreate a vector containing all of the dates in the table.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Input a Series with Dates\u00b6Create vectors for each of the ticker symbols in Table named\nspy, aapl and goog, respectively. Use the variable dates that you created\nin the previous step as the index.\nFor example\ngoog = pd.Series([1197.00,1186.48,1171.44,...], index=dates)\n\nSet the name of each series as the series\" ticker.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Create a DataFrame\u00b6Create a DataFrame named prices containing Table. Set the\ncolumn names equal to the ticker and set the index to dates.\nprices = pd.DataFrame([[289.81, 228.36, 1197.00], [289.03, 226.87, 1186.48]],\n                      columns = [\"SPY\", \"AAPL\", \"GOOG\"],index=dates_2)\n\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nSave the price data\nThis block saves prices to a HDF file for use in later lessons. The\nfunction used to save the data is covered in a later lesson.\nThis function uses some sophisticated features of Python. Do not\nworry if it is unclear at this point.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n# Setup: Save prices, goog and sep_04 into a single file for use in other lessons\n\n# Only run if prices has been defined\nif \"prices\" in globals():\n    import pandas as pd\n    dates = pd.Series(dates)\n    variables = [\"sep_04\", \"sep_05\", \"sep_06\", \"sep_07\", \"sep_10\", \"sep_11\",\n                 \"sep_12\", \"sep_13\", \"sep_14\", \"sep_17\", \"sep_18\", \"sep_19\",\n                 \"spy\", \"goog\", \"aapl\", \"prices\", \"dates\"]\n    with pd.HDFStore(\"data/dataframes.h5\", mode=\"w\") as h5:\n        for var in variables:\n            h5.put(var, globals()[var])",
      "tags": "",
      "url": "https://www.kevinsheppard.com/teaching/python/course/lesson-4/"
    },
    {
      "title": "Lesson 5",
      "text": "Constructing DataFrames from Series\u00b6This lesson introduced method to construct a DataFrame from multiple\nSeries.\nThis first block loads the variables created in an earlier lesson.  A\nlater lesson will cover loading and saving data.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n# Setup: Load data created in an earlier lesson\n\nimport pandas as pd\n\nhdf_file = \"data/dataframes.h5\"\n\nsep_04 = pd.read_hdf(hdf_file, \"sep_04\")\nsep_05 = pd.read_hdf(hdf_file, \"sep_05\")\nsep_06 = pd.read_hdf(hdf_file, \"sep_06\")\nsep_07 = pd.read_hdf(hdf_file, \"sep_07\")\nsep_10 = pd.read_hdf(hdf_file, \"sep_10\")\nsep_11 = pd.read_hdf(hdf_file, \"sep_11\")\nsep_12 = pd.read_hdf(hdf_file, \"sep_12\")\nsep_13 = pd.read_hdf(hdf_file, \"sep_13\")\nsep_14 = pd.read_hdf(hdf_file, \"sep_14\")\nsep_17 = pd.read_hdf(hdf_file, \"sep_17\")\nsep_18 = pd.read_hdf(hdf_file, \"sep_18\")\nsep_19 = pd.read_hdf(hdf_file, \"sep_19\")\n\nspy = pd.read_hdf(hdf_file, \"spy\")\naapl = pd.read_hdf(hdf_file, \"aapl\")\ngoog = pd.read_hdf(hdf_file, \"goog\")\n\ndates = pd.to_datetime(pd.read_hdf(hdf_file, \"dates\"))\n\nprices = pd.read_hdf(hdf_file, \"prices\")\n\n\n    \n\n\n\n\n\n\n\nProblem: Construct a DataFrame from rows\u00b6Create a DataFrame named prices_row from the row vectors previously\nentered such that the results are identical to prices. For example, the first\ntwo days worth of data are:\npricess_row = pd.DataFrame([sep_04, sep_05])\n# Set the index after using concat to join\npricess_row.index = dates_2\n\nVerify that the DataFrame identical by printing the difference with\nprices\nprint(prices_row - prices)\n\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Construct a DataFrame from columns\u00b6Create a DataFrame named prices_col from the 3 column vectors entered\nsuch that the results are identical to prices.\nNote: .T transposes a 2-d array since DataFrame builds the\narray by rows.\nVerify that the DataFrame identical by printing the difference with\nprices\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Construct a DataFrame from a dictionary\u00b6Create a DataFrame named prices_dict from the 3 column vectors entered\nsuch that the results are identical to prices\nVerify that the DataFrame identical by printing the difference with\nprices\n\n\n\n\n\n\nIn\u00a0[\u00a0]:",
      "tags": "",
      "url": "https://www.kevinsheppard.com/teaching/python/course/lesson-5/"
    },
    {
      "title": "Lesson 6",
      "text": "Methods and Functions\u00b6This lesson covers:\n\nCalling functions with more than one input and output \nCalling functions when some inputs are not used\n\n\n\n\n\n\n\n\nRead the data in momentum.csv and creating some variable. This cell uses\nsome magic to automate repeated typing.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n# Setup: Load the momentum data\nimport pandas as pd\n\nmomentum = pd.read_csv(\"data/momentum.csv\", index_col=\"date\", parse_dates=True)\n\nprint(momentum.head())\n\nmom_01 = momentum[\"mom_01\"]\nmom_10 = momentum[\"mom_10\"]\n\n\n    \n\n\n\n\n\n\n\nThis data set contains 2 years of data on the 10 momentum portfolios from\n2016\u20132018. The variables are named mom_XX where XX ranges from 01 (work\nreturn over the past 12 months) to 10 (best return over the past 12 months).\n\n\n\n\n\n\n\nProblem: Calling Methods\u00b6Get used to calling methods by computing the mean, standard deviation, skewness, kurtosis, max, and min.\nUse the DataFrame functions mean, std, skew and kurt, min and max to print the\nvalues for mom_01.\nIn the second cell, call describe, a method that summariezes Series and DataFrames on mom_01.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Use NumPy and SciPy functions\u00b6Use the NumPy functions mean, std, min, max and the SciPy stats functions\nskew and kurtosis to produce the same output.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Calling Functions with 2 Outputs\u00b6Some useful functions return 2 or more outputs. One example is np.linalg.slogdet \ncomputes the signed log determinant of a square array. It returns two output,\nthe sign and the log of the absolute determinant.\nUse this function to compute the sign and log determinant of the 2 by 2 array:\n\n1  2\n2  9\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Calling Functions with 2 Inputs\u00b6Many functions take two or more inputs. Like outputs, the inputs are simply\nlisted in order separated by commas. Use np.linspace to produce a series\nof 11 points evenly spaced between 0 and 1.\n\nnp.linspace(start, stop, num=50, endpoint=True, retstep=False, dtype=None, axis=0)\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Calling Functions using Keyword Arguments\u00b6Many functions have optional arguments. You can see these in a docstring since\noptional arguments take the form variable=default. For example, see\nthe help for scipy.special.comb, which has the function signature\n\ncomb(N, k, exact=False, repetition=False)\nThis tells us that N and k are required and\nthat the other 2 inputs can be omitted if you are happy with the defaults.\nHowever, if we want to change some of the optional inputs, then we can\ndirectly use the inputs name in the function call.\nCompute the number of distinct combinations of 5 objects from a set of 10.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nCompute the total number of combinations allowing for repetition \nusing the repetition=True keyword argument.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nCompute the number of combinations using the exact representation using \nonly positional arguments for all 3 inputs.  Repeat using the keyword\nargument for exact.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Function Help\u00b6Explore the help available for calling functions ? operator. For example,\nimport scipy.stats as stats\n\nstats.kurtosis?\n\nopens a help window that shows the inputs and output, while\nhelp(stats.kurtosis)\n\nshows the help in the console.\nNote: VS Code does not support the ? form of help\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Use help with a method\u00b6Use help to get the help for the kurt method attached to momentum.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:",
      "tags": "",
      "url": "https://www.kevinsheppard.com/teaching/python/course/lesson-6/"
    },
    {
      "title": "Lesson 7",
      "text": "Custom Functions\u00b6This lesson covers:\n\nWriting a custom function \n\n\n\n\n\n\n\n\nProblem: Writing a Custom Function\u00b6Custom functions will play an important role later in the course when\nestimating parameters. Construct a custom function that takes two arguments,\nmu and sigma2 and computes the likelihood function of a normal random variable.\n$$f(x;\\mu,\\sigma{2})=\\frac{1}{\\sqrt{2\\pi\\sigma{2}}}\\exp\\left(-\\frac{(x-\\mu){2}}{2\\sigma{2}}\\right)$$Use def to start the function and compute the likelihood of:\n$$x=0,\\mu=0,\\sigma{2}=1.$$The text in the triple quotes is the docstring which is optional.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nExercises\u00b6Exercise: Custom Function\u00b6Write a function named summary_stats that will take a single input, x,\na DataFrame and return a DataFrame with 4 columns and as many rows as\nthere were columns in the original data where the columns contain the mean,\nstandard deviation, skewness and kurtosis of x.\nCheck your function by running\nsummary_stats(momentum)\n\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n# Setup: Load the momentum data\nimport pandas as pd\nmomentum = pd.read_csv(\"data\\momentum.csv\",index_col=\"date\", parse_dates=True)\n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nTest your function using the momentum data in the next cell.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nExercise: Custom Function\u00b6Change your previous function to return 4 outputs, each a pandas Series for the mean,\nstandard deviation, skewness, and the kurtosis.\nReturning multiple outputs uses the syntax\nreturn w, x, y, z\n\nTest your function using the momentum data.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nTest your function using the momentum data in the next cell.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:",
      "tags": "",
      "url": "https://www.kevinsheppard.com/teaching/python/course/lesson-7/"
    },
    {
      "title": "Lesson 8",
      "text": "Using DataFrames\u00b6This lesson introduces:\n\nComputing returns (percentage change)\nBasic mathematical operations on DataFrames\n\nThis first cell load data for use in this lesson.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n# Setup: Load prices\nimport pandas as pd\nprices = pd.read_hdf(\"data/dataframes.h5\", \"prices\")\nsep_04 = pd.read_hdf(\"data/dataframes.h5\", \"sep_04\")\ngoog = pd.read_hdf(\"data/dataframes.h5\", \"goog\")\n\n\n    \n\n\n\n\n\n\n\nProblem: Compute Returns\u00b6Compute returns using\nreturns = prices.pct_change()\n\nwhich computes the percentage change.\nAdditionally, extract returns for each name using\nspy_returns = returns[\"SPY\"]\n\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Compute Log Returns\u00b6import numpy as np\n\nlog_returns = np.log(prices).diff()\n\nfirst difference of the natural log of the prices. Mathematically this is \n$r_{t}=\\ln\\left(P_{t}\\right)-\\ln\\left(P_{t-1}\\right)=\\ln\\left(\\frac{P_{t}}{P_{t-1}}\\right)\\approx\\frac{P_{t}}{P_{t-1}}-1$.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nBasic Mathematical Operations\u00b6\n\nOperation\nSymbol\nPrecedence\n\n\n\n\nParentheses\n()\n4\n\n\nExponentiation\n**\n3\n\n\nMultiplication\n*\n2\n\n\nDivision\n/\n2\n\n\nFloor division\n//\n2\n\n\nModulus\n%\n2\n\n\nMatrix multiplication\n@\n2\n\n\nAddition\n+\n1\n\n\nSubtraction\n-\n1\n\n\n\nNote: Higher precedence operators are evaluated first, and ties are\nevaluated left to right.\nProblem: Scalar Operations\u00b6\nAdd 1 to all returns\nSquare the returns\nMultiply the price of Google by 2. \nExtract the fractional return using floor division and modulus\n\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Addition on Series\u00b6Add the returns on SPY to those of AAPL\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Addition on Series\u00b6Using only basic mathematical operations compute the \ncorrelation between the returns on AAPL and SPY.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Addition of DataFrames\u00b6Construct a DataFrame that only contains the SPY column from returns\nand add it to the return DataFrame\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Non-conformable math\u00b6Add the prices in sep_04 to the prices of goog. What happens?\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Constructing portfolio returns\u00b6Set up a 3-element array of portfolio weights\n$$w=\\left(\\frac{1}{3},\\,\\frac{1}{3}\\,,\\frac{1}{3}\\right)$$and compute the return of a portfolio with weight $\\frac{1}{3}$ in each security.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:",
      "tags": "",
      "url": "https://www.kevinsheppard.com/teaching/python/course/lesson-8/"
    },
    {
      "title": "Lesson 9",
      "text": "Common DataFrame methods\u00b6This lesson introduces the common DataFrame methods that\nwe will repeatedly use in the course.\nThis first cell load data for use in this lesson.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n# Setup: Load prices\nimport pandas as pd\nprices = pd.read_hdf(\"data/dataframes.h5\", \"prices\")\nsep_04 = pd.read_hdf(\"data/dataframes.h5\", \"sep_04\")\ngoog = pd.read_hdf(\"data/dataframes.h5\", \"goog\")\nreturns = prices.pct_change().dropna()\nspy_returns = returns.SPY\naapl_returns = returns.AAPL\ngoog_returns = returns.GOOG\n\n\n    \n\n\n\n\n\n\n\nProblem: Constructing portfolio returns\u00b6Compute the return of a portfolio with weight $\\frac{1}{3}$ in each security using\nmultiplication (*) and .sum().\nNote: You need to use the axis keyword for the sum.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Compute the Mean and Standard Deviation\u00b6Using the function mean, compute the mean of the three returns series one at a time. For example\ngoog_mean = goog_returns.mean()\n\nNext, compute the mean of the matrix of returns using\nretmean = returns.mean()\n\nWhat is the relationship between these two? Repeat this exercise for the standard deviation (std()).\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Compute Correlation\u00b6Compute the correlation of the matrix of returns (corr()).\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Summing all elements\u00b6Compute the sum of the columns of returns using .sum(). How is this related to the mean computed \nin the previous step?\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Maximum and Minimum Values\u00b6Compute the minimum and maximum values of the columns of returns using the min() and max() commands.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Rounding Up, Down and to the Closest Integer\u00b6Rounding up is handled by ceil, rounding down is handled by floor and rounding to the closest \ninteger is handled by round. Try all of these commands on 100 times returns. For example,\nrounded = (100*returns).round()\n\nUse ceil and floor to round up and down, respectively.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:",
      "tags": "",
      "url": "https://www.kevinsheppard.com/teaching/python/course/lesson-9/"
    },
    {
      "title": "Example: Fama-MacBeth regression",
      "text": "Estimating the Risk Premia using Fama-MacBeth Regressions\u00b6\n\n\n\n\n\n\nThis example highlights how to implement a Fama-MacBeth 2-stage regression to estimate factor risk premia, make inference on the risk premia, and test whether a linear factor model can explain a cross-section of portfolio returns. This example closely follows [Cochrane::2001] (See also [JagannathanSkoulakisWang::2010]). As in the previous example, the first segment contains the imports.\n\n\n\n\n\n\nIn\u00a0[1]:\n\n    \nfrom numpy import mat, cov, mean, hstack, multiply,sqrt,diag, \\\n    squeeze, ones, array, vstack, kron, zeros, eye, savez_compressed\nfrom numpy.linalg import inv\nfrom scipy.stats import chi2\nfrom pandas import read_csv\nimport statsmodels.api as sm\n\n\n    \n\n\n\n\n\n\n\nNext, the data are imported. I formatted the data downloaded from Ken French's website into an easy-to-import CSV which can be read by pandas.read_csv. The data is split using named columns for the small sets of variables and ix for the portfolios. The code uses pure NumPy arrays, and so values is used to retrieve the array from the DataFrame. The dimensions are determined using shape. Finally the risk free rate is forced to have 2 dimensions so that it will be broadcastable with the portfolio returns in the construction of the excess returns to the Size and Value-weighted portfolios. asmatrix is used to return matrix views of all of the arrays. This code is linear algebra-heavy and so matrices are easier to use than arrays.\n\n\n\n\n\n\nIn\u00a0[2]:\n\n    \ndata = read_csv('FamaFrench.csv')\n\n# Split using both named colums and ix for larger blocks\ndates = data['date'].values\nfactors = data[['VWMe', 'SMB', 'HML']].values\nriskfree = data['RF'].values\nportfolios = data.iloc[:, 5:].values\n\n# Use mat for easier linear algebra\nfactors = mat(factors)\nriskfree = mat(riskfree)\nportfolios = mat(portfolios)\n\n# Shape information\nT,K = factors.shape\nT,N = portfolios.shape\n# Reshape rf and compute excess returns\nriskfree.shape = T,1\nexcessReturns = portfolios - riskfree\n\n\n    \n\n\n\n\n\n\n\nThe next block does 2 things:\n\nCompute the time-series $\\beta$s. This is done be regressing the full array of excess returns on the factors (augmented with a constant) using lstsq.\nCompute the risk premia using a cross-sectional regression of average excess returns on the estimates $\\beta$s. This is a standard regression where the step 1 $\\beta$ estimates are used as regressors, and the dependent variable is the average excess return.\n\n\n\n\n\n\n\nIn\u00a0[3]:\n\n    \n# Time series regressions\nX = sm.add_constant(factors)\nts_res = sm.OLS(excessReturns, X).fit()\nalpha = ts_res.params[0]\nbeta = ts_res.params[1:]\navgExcessReturns = mean(excessReturns, 0)\n# Cross-section regression\ncs_res = sm.OLS(avgExcessReturns.T, beta.T).fit()\nriskPremia = cs_res.params\n\n\n    \n\n\n\n\n\n\n\nThe asymptotic variance requires computing the covariance of the demeaned returns and the weighted pricing errors. The problem is formulated using 2-step GMM where the moment conditions are \n\\begin{equation}\ng_{t}\\left(\\theta\\right)=\\left[\\begin{array}{c}\n\\epsilon_{1t}\\\\\n\\epsilon_{1t}f_{t}\\\\\n\\epsilon_{2t}\\\\\n\\epsilon_{2t}f_{t}\\\\\n\\vdots\\\\\n\\epsilon_{Nt}\\\\\n\\epsilon_{Nt}f_{t}\\\\\n\\beta u_{t}\n\\end{array}\\right]\n\\end{equation}\nwhere $\\epsilon_{it}=r_{it}{e}-\\alpha_{i}-\\beta_{i}{\\prime}f_{t}$, $\\beta_{i}$ is a $K$ by 1 vector of factor loadings, $f_{t}$ is a $K$ by 1 set of factors, $\\beta=\\left[\\beta_{1}\\,\\beta_{2}\\ldots\\beta_{N}\\right]$ is a $K$ by $N$ matrix of all factor loadings, $u_{t}=r_{t}{e}-\\beta'\\lambda$ are the $N$ by 1 vector of pricing errors and $\\lambda$ is a $K$  by 1 vector of risk premia. \nThe vector of parameters is then $\\theta= \\left[\\alpha_{1}\\:\\beta_{1}{\\prime}\\:\\alpha_{2}\\:\\beta_{2}{\\prime}\\:\\ldots\\:\\alpha_{N}\\,\\beta_{N}{\\prime}\\:\\lambda'\\right]'$\n To make inference on this problem, the derivative of the moments with respect to the parameters, $\\partial g_{t}\\left(\\theta\\right)/\\partial\\theta{\\prime}$ is needed. With some work, the estimator of this matrix can be seen to be\n\\begin{equation}\n G=E\\left[\\frac{\\partial g_{t}\\left(\\theta\\right)}{\\partial\\theta{\\prime}}\\right]=\\left[\\begin{array}{cc}\n-I_{n}\\otimes\\Sigma_{X} & 0\\\\\nG_{21} & -\\beta\\beta{\\prime}\n\\end{array}\\right].\n\\end{equation}where $X_{t}=\\left[1\\: f_{t}{\\prime}\\right]'$  and $\\Sigma_{X}=E\\left[X_{t}X_{t}{\\prime}\\right]$. $G_{21}$ is a matrix with the structure\n\\begin{equation}\nG_{21}=\\left[G_{21,1}\\, G_{21,2}\\,\\ldots G_{21,N}\\right]\n\\end{equation}where\n\\begin{equation}\nG_{21,i}=\\left[\\begin{array}{cc} \n0_{K,1} & \\textrm{diag}\\left(E\\left[u_{i}\\right]-\\beta_{i}\\odot\\lambda\\right)\\end{array}\\right]\\end{equation}and where $E\\left[u_{i}\\right]$ is the expected pricing error. In estimation, all expectations are replaced with their sample analogues.\n\n\n\n\n\n\nIn\u00a0[4]:\n\n    \n# Moment conditions\nX = sm.add_constant(factors)\np = vstack((alpha, beta))\nepsilon = excessReturns - X @ p\nmoments1 = kron(epsilon, ones((1, K + 1)))\nmoments1 = multiply(moments1, kron(ones((1, N)), X))\nu = excessReturns - riskPremia[None,:] @ beta\nmoments2 = u * beta.T\n# Score covariance\nS = mat(cov(hstack((moments1, moments2)).T))\n# Jacobian\nG = mat(zeros((N * K + N + K, N * K + N + K)))\nSigmaX = (X.T @ X) / T\nG[:N * K + N, :N * K + N] = kron(eye(N), SigmaX)\nG[N * K + N:, N * K + N:] = -beta @ beta.T\nfor i in range(N):\n    temp = zeros((K, K + 1))\n    values = mean(u[:, i]) - multiply(beta[:, i], riskPremia)\n    temp[:, 1:] = diag(values)\n    G[N * K + N:, i * (K + 1):(i + 1) * (K + 1)] = temp\n\nvcv = inv(G.T) * S * inv(G) / T\n\n\n    \n\n\n\n\n\n\n\nThe $J$-test examines whether the average pricing errors, $\\hat{\\alpha}$, are zero. The $J$ statistic has an asymptotic $\\chi_{N}{2}$  distribution, and the model is badly rejected.\n\n\n\n\n\n\nIn\u00a0[5]:\n\n    \nvcvAlpha = vcv[0:N * K + N:4, 0:N * K + N:4]\nJ = alpha @ inv(vcvAlpha) @ alpha.T\nJ = J[0, 0]\nJpval = 1 - chi2(25).cdf(J)\n\n\n    \n\n\n\n\n\n\n\nThe final block using formatted output to present all of the results in a readable manner.\n\n\n\n\n\n\nIn\u00a0[6]:\n\n    \nvcvRiskPremia = vcv[N * K + N:, N * K + N:]\nannualizedRP = 12 * riskPremia\narp = list(squeeze(annualizedRP))\narpSE = list(sqrt(12 * diag(vcvRiskPremia)))\nprint('        Annualized Risk Premia')\nprint('           Market       SMB        HML')\nprint('--------------------------------------')\nprint('Premia     {0:0.4f}    {1:0.4f}     {2:0.4f}'.format(arp[0], arp[1], arp[2]))\nprint('Std. Err.  {0:0.4f}    {1:0.4f}     {2:0.4f}'.format(arpSE[0], arpSE[1], arpSE[2]))\nprint('\\n\\n')\n\nprint('J-test:   {:0.4f}'.format(J))\nprint('P-value:   {:0.4f}'.format(Jpval))\n\ni = 0\nbetaSE = []\nfor j in range(5):\n    for k in range(5):\n        a = alpha[i]\n        b = beta[:, i]\n        variances = diag(vcv[(K + 1) * i:(K + 1) * (i + 1), (K + 1) * i:(K + 1) * (i + 1)])\n        betaSE.append(sqrt(variances))\n        s = sqrt(variances)\n        c = hstack((a, b))\n        t = c / s\n        print('Size: {:}, Value:{:}   Alpha   Beta(VWM)   Beta(SMB)   Beta(HML)'.format(j + 1, k + 1))\n        print('Coefficients: {:>10,.4f}  {:>10,.4f}  {:>10,.4f}  {:>10,.4f}'.format(a, b[0], b[1], b[2]))\n        print('Std Err.      {:>10,.4f}  {:>10,.4f}  {:>10,.4f}  {:>10,.4f}'.format(s[0], s[1], s[2], s[3]))\n        print('T-stat        {:>10,.4f}  {:>10,.4f}  {:>10,.4f}  {:>10,.4f}'.format(t[0], t[1], t[2], t[3]))\n        print('')\n        i += 1\n\n\n    \n\n\n\n\n\n\n\n\n\n    \n\n\n\n        Annualized Risk Premia\n           Market       SMB        HML\n--------------------------------------\nPremia     6.6642    2.8731     2.8080\nStd. Err.  0.5994    0.4010     0.4296\n\n\n\nJ-test:   95.2879\nP-value:   0.0000\nSize: 1, Value:1   Alpha   Beta(VWM)   Beta(SMB)   Beta(HML)\nCoefficients:    -0.8354      1.3099      1.2892      0.3943\nStd Err.          0.1820      0.1269      0.1671      0.2748\nT-stat           -4.5904     10.3196      7.7127      1.4348\n\nSize: 1, Value:2   Alpha   Beta(VWM)   Beta(SMB)   Beta(HML)\nCoefficients:    -0.3911      1.0853      1.6100      0.3317\nStd Err.          0.1237      0.0637      0.1893      0.1444\nT-stat           -3.1616     17.0351      8.5061      2.2971\n\nSize: 1, Value:3   Alpha   Beta(VWM)   Beta(SMB)   Beta(HML)\nCoefficients:    -0.1219      1.0747      1.1812      0.4648\nStd Err.          0.0997      0.0419      0.0938      0.0723\nT-stat           -1.2225     25.6206     12.5952      6.4310\n\nSize: 1, Value:4   Alpha   Beta(VWM)   Beta(SMB)   Beta(HML)\nCoefficients:     0.0388      0.9630      1.2249      0.5854\nStd Err.          0.0692      0.0232      0.1003      0.0353\nT-stat            0.5614     41.5592     12.2108     16.5705\n\nSize: 1, Value:5   Alpha   Beta(VWM)   Beta(SMB)   Beta(HML)\nCoefficients:     0.0918      0.9850      1.3453      0.9052\nStd Err.          0.0676      0.0255      0.0818      0.0610\nT-stat            1.3580     38.5669     16.4489     14.8404\n\nSize: 2, Value:1   Alpha   Beta(VWM)   Beta(SMB)   Beta(HML)\nCoefficients:    -0.2397      1.0691      1.0520     -0.2647\nStd Err.          0.0725      0.0318      0.0609      0.0591\nT-stat           -3.3052     33.6540     17.2706     -4.4768\n\nSize: 2, Value:2   Alpha   Beta(VWM)   Beta(SMB)   Beta(HML)\nCoefficients:    -0.0194      1.0416      0.9880      0.1877\nStd Err.          0.0615      0.0170      0.0776      0.0350\nT-stat           -0.3162     61.1252     12.7393      5.3646\n\nSize: 2, Value:3   Alpha   Beta(VWM)   Beta(SMB)   Beta(HML)\nCoefficients:     0.0898      0.9590      0.8619      0.3553\nStd Err.          0.0517      0.0170      0.0733      0.0320\nT-stat            1.7359     56.4856     11.7528     11.0968\n\nSize: 2, Value:4   Alpha   Beta(VWM)   Beta(SMB)   Beta(HML)\nCoefficients:     0.0482      0.9788      0.8178      0.5562\nStd Err.          0.0495      0.0138      0.0454      0.0281\nT-stat            0.9733     70.7006     18.0210     19.8055\n\nSize: 2, Value:5   Alpha   Beta(VWM)   Beta(SMB)   Beta(HML)\nCoefficients:    -0.0109      1.0502      0.9373      0.8493\nStd Err.          0.0596      0.0182      0.0281      0.0263\nT-stat           -0.1830     57.7092     33.3971     32.2980\n\nSize: 3, Value:1   Alpha   Beta(VWM)   Beta(SMB)   Beta(HML)\nCoefficients:    -0.1556      1.1416      0.7883     -0.1980\nStd Err.          0.0591      0.0190      0.0445      0.0411\nT-stat           -2.6320     60.1173     17.6973     -4.8171\n\nSize: 3, Value:2   Alpha   Beta(VWM)   Beta(SMB)   Beta(HML)\nCoefficients:     0.0889      1.0133      0.5151      0.0720\nStd Err.          0.0553      0.0179      0.0340      0.0334\nT-stat            1.6068     56.6380     15.1651      2.1546\n\nSize: 3, Value:3   Alpha   Beta(VWM)   Beta(SMB)   Beta(HML)\nCoefficients:     0.1118      1.0129      0.4130      0.3379\nStd Err.          0.0578      0.0267      0.0324      0.0321\nT-stat            1.9344     37.9790     12.7488     10.5399\n\nSize: 3, Value:4   Alpha   Beta(VWM)   Beta(SMB)   Beta(HML)\nCoefficients:     0.0818      0.9615      0.4646      0.5068\nStd Err.          0.0568      0.0141      0.0475      0.0301\nT-stat            1.4399     68.3360      9.7754     16.8580\n\nSize: 3, Value:5   Alpha   Beta(VWM)   Beta(SMB)   Beta(HML)\nCoefficients:    -0.0526      1.1447      0.4970      0.9143\nStd Err.          0.0687      0.0197      0.0509      0.0390\nT-stat           -0.7655     58.0319      9.7690     23.4302\n\nSize: 4, Value:1   Alpha   Beta(VWM)   Beta(SMB)   Beta(HML)\nCoefficients:     0.0902      1.0661      0.2857     -0.3692\nStd Err.          0.0498      0.0151      0.0444      0.0323\nT-stat            1.8127     70.4710      6.4268    -11.4334\n\nSize: 4, Value:2   Alpha   Beta(VWM)   Beta(SMB)   Beta(HML)\nCoefficients:    -0.0104      1.0308      0.2430      0.1328\nStd Err.          0.0534      0.0217      0.0300      0.0294\nT-stat           -0.1952     47.5567      8.0926      4.5183\n\nSize: 4, Value:3   Alpha   Beta(VWM)   Beta(SMB)   Beta(HML)\nCoefficients:     0.0392      1.0096      0.2214      0.2980\nStd Err.          0.0572      0.0209      0.0436      0.0486\nT-stat            0.6862     48.3271      5.0836      6.1333\n\nSize: 4, Value:4   Alpha   Beta(VWM)   Beta(SMB)   Beta(HML)\nCoefficients:     0.0148      1.0437      0.2016      0.5857\nStd Err.          0.0593      0.0224      0.0343      0.0484\nT-stat            0.2497     46.5053      5.8694     12.0922\n\nSize: 4, Value:5   Alpha   Beta(VWM)   Beta(SMB)   Beta(HML)\nCoefficients:    -0.1762      1.2284      0.2974      0.9834\nStd Err.          0.0803      0.0224      0.0490      0.0378\nT-stat           -2.1927     54.8427      6.0726     26.0265\n\nSize: 5, Value:1   Alpha   Beta(VWM)   Beta(SMB)   Beta(HML)\nCoefficients:     0.0794      1.0310     -0.1507     -0.2508\nStd Err.          0.0372      0.0095      0.0247      0.0168\nT-stat            2.1369    108.0844     -6.1067    -14.9673\n\nSize: 5, Value:2   Alpha   Beta(VWM)   Beta(SMB)   Beta(HML)\nCoefficients:     0.0535      0.9576     -0.1893     -0.0107\nStd Err.          0.0457      0.0170      0.0243      0.0239\nT-stat            1.1690     56.3228     -7.7765     -0.4458\n\nSize: 5, Value:3   Alpha   Beta(VWM)   Beta(SMB)   Beta(HML)\nCoefficients:    -0.0236      0.9753     -0.2173      0.3127\nStd Err.          0.0559      0.0178      0.0309      0.0256\nT-stat           -0.4225     54.6936     -7.0217     12.2061\n\nSize: 5, Value:4   Alpha   Beta(VWM)   Beta(SMB)   Beta(HML)\nCoefficients:    -0.1978      1.0546     -0.1732      0.7115\nStd Err.          0.0587      0.0230      0.0300      0.0316\nT-stat           -3.3679     45.7933     -5.7749     22.5339\n\nSize: 5, Value:5   Alpha   Beta(VWM)   Beta(SMB)   Beta(HML)\nCoefficients:    -1.2737      1.1045      0.0076      0.8527\nStd Err.          0.3557      0.1143      0.1594      0.1490\nT-stat           -3.5805      9.6657      0.0477      5.7232\n\n\n\n\n\n\n\n\n\n\n\n\nThe final block converts the standard errors of $\\beta$ to be an array and saves the results.\n\n\n\n\n\n\nIn\u00a0[7]:\n\n    \nbetaSE = array(betaSE)\nsavez_compressed('fama-macbeth-results', alpha=alpha, beta=beta,\n                 betaSE=betaSE, arpSE=arpSE, arp=arp, J=J, Jpval=Jpval)\n\n\n    \n\n\n\n\n\n\n\nSave Results\u00b6Save the estimated values for use in the $\\LaTeX$ notebook.\n\n\n\n\n\n\nIn\u00a0[8]:\n\n    \nfrom numpy import savez\nsavez('fama-macBeth-results.npz', arp=arp, beta=beta, arpSE=arpSE,\n      betaSE=betaSE, J=J, Jpval=Jpval)",
      "tags": "",
      "url": "https://www.kevinsheppard.com/teaching/python/notes/notebooks/example-fama-macbeth/"
    },
    {
      "title": "Example: GJR-GARCH Estimation",
      "text": "IPython Notebook Setup\u00b6This commands are used needed for plots to appear in the notebook.\n\n\n\n\n\n\nIn\u00a0[1]:\n\n    \n%matplotlib inline\n\n\n    \n\n\n\n\n\n\n\nEstimating the Parameters of a GJR-GARCH Model\u00b6This example will highlight the steps needed to estimate the parameters of a GJR-GARCH(1,1,1) model with a constant mean. The volatility dynamics in a GJR-GARCH model are given by \n$$\\sigma_{t}{2}=\\omega+\\sum_{i=1}{p}\\alpha_{i}\\epsilon_{t-i}{2}+\\sum_{j=1}{o}\\gamma_{j}r_{t-j}{2}I_{\\left[\\epsilon_{t-j}<0\\right]}+\\sum_{k=1}{q}\\beta_{k}\\sigma_{t-k}{2}.$$\nReturns are assumed to be conditionally normal, $r_{t}|\\mathcal{F}_{t-1}\\sim N\\left(\\mu,\\sigma_{t}{2}\\right)$, $\\epsilon_{t}=r_{t}-\\mu$ and parameters are estimated by maximum likelihood. To estimate the parameters, it is necessary to:\n\nProduce some starting values\nEstimate the parameters using (quasi-) maximum likelihood\nCompute standard errors using a \u201csandwich\u201d covariance estimator (also known as the [BollerslevWooldridge::1992] covariance estimator)\n\nThe first task is to write the log-likelihood which can be used in an optimizer. The log-likelihood function will compute the volatility recursion and the log-likelihood. It will also, optionally, return the $T$ by 1 vector of individual log-likelihoods which are useful when approximating the scores.\n\n\n\n\n\n\nIn\u00a0[2]:\n\n    \nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom numpy import size, log, pi, sum, array, zeros, diag, mat, asarray, sqrt, \\\n    copy\nfrom numpy.linalg import inv\nfrom scipy.optimize import fmin_slsqp\n\n\n    \n\n\n\n\n\n\n\nThe conditional log-likelihood of a normal random variable is\n$$\\ln f\\left(r_{t}|\\mu,\\sigma_{t}{2}\\right)=-\\frac{1}{2}\\left(\\ln2\\pi+\\ln\\sigma_{t}{2}+\\frac{\\left(r_{t}-\\mu\\right){2}}{\\sigma_{t}{2}}\\right),$$which is negated in the code since the optimizers all minimize.\n\n\n\n\n\n\nIn\u00a0[3]:\n\n    \ndef gjr_garch_likelihood(parameters, data, sigma2, out=None):\n    ''' Returns negative log-likelihood for GJR-GARCH(1,1,1) model.'''\n    mu = parameters[0]\n    omega = parameters[1]\n    alpha = parameters[2]\n    gamma = parameters[3]\n    beta = parameters[4]\n    \n    T = size(data,0)\n    eps = data - mu\n    # Data and sigma2 are T by 1 vectors\n    for t in range(1,T):\n        sigma2[t] = (omega + alpha * eps[t-1]**2 \n                     + gamma * eps[t-1]**2 * (eps[t-1]<0) + beta * sigma2[t-1])\n    \n    logliks = 0.5*(log(2*pi) + log(sigma2) + eps**2/sigma2)\n    loglik = sum(logliks)\n    \n    if out is None:\n        return loglik\n    else:\n        return loglik, logliks, copy(sigma2)\n\n\n    \n\n\n\n\n\n\n\nThe keyword argument out has a default value of None, and is used to determine whether to return 1 output or 3. This is common practice since the optimizer requires a single output -- the log-likelihood function value, but it is also useful to be able to output other useful quantities, such as $\\left\\{ \\sigma_{t}{2}\\right\\}$.\nThe optimization is constrained so that $\\alpha+\\gamma/2+\\beta\\leq 1$, and the constraint is provided in a separate function.\n\n\n\n\n\n\nIn\u00a0[4]:\n\n    \ndef gjr_constraint(parameters, data, sigma2, out=None):\n    ''' Constraint that alpha+gamma/2+beta<=1'''\n    \n    alpha = parameters[2]\n    gamma = parameters[3]\n    beta = parameters[4]\n\n    return array([1-alpha-gamma/2-beta])\n\n\n    \n\n\n\n\n\n\n\nNote that the constraint function takes the same inputs as the negative of the log-likelihood function, even though only parameters is required to compute the constraint.\nIt is necessary to discuss one other function before proceeding with the main block of code. The asymptotic variance is estimated using the \u201csandwich\u201d form which is commonly expressed as\n$$\\mathcal{J}{-1}\\mathcal{I}\\mathcal{J}{-1}$$where $\\mathcal{J}$ is the expected Hessian and $\\mathcal{I}$ is the covariance of the scores. Both are numerically approximated, and the strategy for computing the Hessian is to use the definition that\n$$\\mathcal{J}_{ij}\\approx\\frac{f\\left(\\theta+e_{i}h_{i}+e_{j}h_{j}\\right)-f\\left(\\theta+e_{i}h_{i}\\right)-f\\left(\\theta+e_{j}h_{j}\\right)+f\\left(\\theta\\right)}{h_{i}h_{j}}$$where $h_{i}$ is a scalar \u201cstep size\u201d and $e_{i}$ is a vector of 0s except for element $i$, which is 1. A 2-sided version of this approximation, which takes both forward and backward steps and then averages, is below. For more on numerical derivatives, see [FlanneryPressTeukolskyTeukolsky::1992].\n\n\n\n\n\n\nIn\u00a0[5]:\n\n    \ndef hessian_2sided(fun, theta, args):\n    f = fun(theta, *args)\n    h = 1e-5*np.abs(theta)\n    thetah = theta + h\n    h = thetah - theta\n    K = size(theta,0)\n    h = np.diag(h)\n    \n    fp = zeros(K)\n    fm = zeros(K)\n    for i in range(K):\n        fp[i] = fun(theta+h[i], *args)\n        fm[i] = fun(theta-h[i], *args)\n        \n    fpp = zeros((K,K))\n    fmm = zeros((K,K))\n    for i in range(K):\n        for j in range(i,K):\n            fpp[i,j] = fun(theta + h[i] + h[j],  *args)\n            fpp[j,i] = fpp[i,j]\n            fmm[i,j] = fun(theta - h[i] - h[j],  *args)\n            fmm[j,i] = fmm[i,j]\n            \n    hh = (diag(h))\n    hh = hh.reshape((K,1))\n    hh = hh @ hh.T\n    \n    H = zeros((K,K))\n    for i in range(K):\n        for j in range(i,K):\n            H[i,j] = (fpp[i,j] - fp[i] - fp[j] + f \n                       + f - fm[i] - fm[j] + fmm[i,j])/hh[i,j]/2\n            H[j,i] = H[i,j]\n    \n    return H\n\n\n    \n\n\n\n\n\n\n\nFinally, the code that does the actual work can be written. The first block imports the data, flips it using a slicing operator, and computes 100 times returns. Scaling data can be useful to improve optimizer performance, and ideally estimated parameters should have similar magnitudes (i.e. $\\omega\\approx.01$  and $\\alpha\\approx.05$).\n\n\n\n\n\n\nIn\u00a0[6]:\n\n    \n# Import data\nFTSE = pd.read_csv('FTSE_1984_2012.csv', parse_dates=[0])\n# Set index\nFTSE.index = FTSE.pop('Date')\n# Flip upside down\nFTSE = FTSE.iloc[::-1]\n# Compute returns\nFTSEprice = FTSE['Adj Close']\nFTSEreturn = 100 * FTSEprice.pct_change().dropna()\n\n\n    \n\n\n\n\n\n\n\nGood starting values are important. These are my guesses based on experience fitting these types of models models. An alternative is to attempt a crude grid search and use the best (smallest) log-likelihood value from the grid search.\n\n\n\n\n\n\nIn\u00a0[7]:\n\n    \n# Starting values\nstartingVals = array([FTSEreturn.mean(),\n                      FTSEreturn.var() * .01,\n                      .03, .09, .90])\n\n\n    \n\n\n\n\n\n\n\nBounds are used in estimation to ensure that all parameters in the conditional variance are $\\geq 0$  and to set sensible upper bounds on the mean and $\\omega$. The vector sigma2 is then initialized, and the arguments are placed in a tuple.\n\n\n\n\n\n\nIn\u00a0[8]:\n\n    \n# Estimate parameters\nfinfo = np.finfo(np.float64)\nbounds = [(-10*FTSEreturn.mean(), 10*FTSEreturn.mean()),\n          (finfo.eps, 2*FTSEreturn.var() ),\n          (0.0,1.0), (0.0,1.0), (0.0,1.0)]\n       \nT = FTSEreturn.shape[0]\nsigma2 = np.ones(T) * FTSEreturn.var()\n# Pass a NumPy array, not a pandas Series\nargs = (np.asarray(FTSEreturn), sigma2)\nestimates = fmin_slsqp(gjr_garch_likelihood, startingVals,\n                       f_ieqcons=gjr_constraint, bounds = bounds,\n                       args = args)\n\n\n    \n\n\n\n\n\n\n\n\n\n    \n\n\n\nOptimization terminated successfully.    (Exit mode 0)\n            Current function value: 9569.030507603133\n            Iterations: 12\n            Function evaluations: 101\n            Gradient evaluations: 12\n\n\n\n\n\n\n\n\n\n\n\nThe optimized log-likelihood and the time series of variances are computed by calling the objective using the keyword argument out=True.\n\n\n\n\n\n\nIn\u00a0[9]:\n\n    \nloglik, logliks, sigma2final = gjr_garch_likelihood(estimates, FTSEreturn,\n                                                    sigma2, out=True)\n\n\n    \n\n\n\n\n\n\n\nNext, the numerical scores and the covariance of the scores are computed. These exploit the definition of a derivative, so that for a scalar function,\n$$\\frac{\\partial f\\left(\\theta\\right)}{\\partial\\theta_{i}}\\approx\\frac{f\\left(\\theta+e_{i}h_{i}\\right)-f\\left(\\theta\\right)}{h_{i}}.$$The covariance is computed as the outer product of the scores since the scores should have mean 0 when evaluated at the solution to the optimization problem.\n\n\n\n\n\n\nIn\u00a0[10]:\n\n    \nstep = 1e-5 * estimates\nscores = zeros((T,5))\nfor i in range(5):\n    h = step[i]\n    delta = np.zeros(5)\n    delta[i] = h\n    \n    loglik, logliksplus, sigma2 = gjr_garch_likelihood(estimates + delta, \\\n                               np.asarray(FTSEreturn), sigma2, out=True)\n    loglik, logliksminus, sigma2 = gjr_garch_likelihood(estimates - delta, \\\n                              np.asarray(FTSEreturn), sigma2, out=True)                   \n               \n    scores[:,i] = (logliksplus - logliksminus)/(2*h)\n\nI = (scores.T @ scores)/T\n\n\n    \n\n\n\n\n\n\n\nThe next block calls hessian_2sided to estimate the Hessian, and then computes the asymptotic covariance.\n\n\n\n\n\n\nIn\u00a0[11]:\n\n    \nJ = hessian_2sided(gjr_garch_likelihood, estimates, args)\nJ = J/T\nJinv = mat(inv(J))\nvcv = Jinv*mat(I)*Jinv/T\nvcv = asarray(vcv)\n\n\n    \n\n\n\n\n\n\n\nThe penultimate step is to pretty print the results and to produce a plot of the conditional variances.\n\n\n\n\n\n\nIn\u00a0[12]:\n\n    \noutput = np.vstack((estimates,sqrt(diag(vcv)),estimates/sqrt(diag(vcv)))).T    \nprint('Parameter   Estimate       Std. Err.      T-stat')\nparam = ['mu','omega','alpha','gamma','beta']\nfor i in range(len(param)):\n    print('{0:<11} {1:>0.6f}        {2:0.6f}    {3: 0.5f}'.format(param[i],\n           output[i,0], output[i,1], output[i,2]))\n    \n\n\n    \n\n\n\n\n\n\n\n\n\n    \n\n\n\nParameter   Estimate       Std. Err.      T-stat\nmu          0.032146        0.010084     3.18795\nomega       0.017610        0.003330     5.28813\nalpha       0.030658        0.006730     4.55564\ngamma       0.091709        0.012944     7.08484\nbeta        0.906327        0.009784     92.62951\n\n\n\n\n\n\n\n\n\n\n\nThis final block produces a plot of the annualized conditional standard deviations.\n\n\n\n\n\n\nIn\u00a0[13]:\n\n    \n# Register date converters\nfrom pandas.plotting import register_matplotlib_converters\nregister_matplotlib_converters()\n\n# Produce a plot\ndates = FTSE.index[1:]\nfig = plt.figure()\nax = fig.add_subplot(111)\nvolatility = pd.DataFrame(np.sqrt(252 * sigma2), index=dates)\nax.plot(volatility.index,volatility)\nax.autoscale(tight='x')\nfig.autofmt_xdate()\nfig.tight_layout(pad=1.5)\nax.set_ylabel('Volatility')\nax.set_title('FTSE Volatility (GJR GARCH(1,1,1))')\nplt.show()",
      "tags": "",
      "url": "https://www.kevinsheppard.com/teaching/python/notes/notebooks/example-gjr-garch/"
    },
    {
      "title": "Example: GMM Estimation",
      "text": "Risk Premia Estimation using GMM\u00b6\n\n\n\n\n\n\nStart by importing the modules and functions needed\n\n\n\n\n\n\nIn\u00a0[1]:\n\n    \nfrom numpy import hstack, ones, array, mat, tile, reshape, squeeze, eye, asmatrix\nfrom numpy.linalg import inv\nfrom pandas import read_csv, Series \nfrom scipy.linalg import kron\nfrom scipy.optimize import fmin_bfgs\nimport numpy as np\nimport statsmodels.api as sm\n\n\n    \n\n\n\n\n\n\n\nNext a callable function is used to produce iteration-by-iteration output when using the non-linear optimizer.\n\n\n\n\n\n\nIn\u00a0[2]:\n\n    \niteration = 0\nlastValue = 0\nfunctionCount = 0\n\ndef iter_print(params):\n    global iteration, lastValue, functionCount\n    iteration += 1\n    print('Func value: {0:}, Iteration: {1:}, Function Count: {2:}'.format(lastValue, iteration, functionCount))\n\n\n    \n\n\n\n\n\n\n\nThe GMM objective, which is minimized, is defined next.\n\n\n\n\n\n\nIn\u00a0[3]:\n\n    \ndef gmm_objective(params, pRets, fRets, Winv, out=False):\n    global lastValue, functionCount\n    T,N = pRets.shape\n    T,K = fRets.shape\n    beta = squeeze(array(params[:(N*K)]))\n    lam = squeeze(array(params[(N*K):]))\n    beta = reshape(beta,(N,K))\n    lam = reshape(lam,(K,1))\n    betalam = beta @ lam\n    expectedRet = fRets @ beta.T\n    e = pRets - expectedRet\n    instr = tile(fRets,N)\n    moments1  = kron(e,ones((1,K)))\n    moments1 = moments1 * instr\n    moments2 = pRets - betalam.T\n    moments = hstack((moments1,moments2))\n\n    avgMoment = moments.mean(axis=0)\n    \n    J = T * mat(avgMoment) * mat(Winv) * mat(avgMoment).T\n    J = J[0,0]\n    lastValue = J\n    functionCount += 1\n    if not out:\n        return J\n    else:\n        return J, moments\n\n\n    \n\n\n\n\n\n\n\nThe G matrix, which is the derivative of the GMM moments with respect to the parameters, is defined.\n\n\n\n\n\n\nIn\u00a0[4]:\n\n    \ndef gmm_G(params, pRets, fRets):\n    T,N = pRets.shape\n    T,K = fRets.shape\n    beta = squeeze(array(params[:(N*K)]))\n    lam = squeeze(array(params[(N*K):]))\n    beta = reshape(beta,(N,K))\n    lam = reshape(lam,(K,1))\n    G = np.zeros((N*K+K,N*K+N))\n    ffp = (fRets.T @ fRets) / T\n    G[:(N*K),:(N*K)]=kron(eye(N),ffp)\n    G[:(N*K),(N*K):] = kron(eye(N),-lam)\n    G[(N*K):,(N*K):] = -beta.T\n    \n    return G\n\n\n    \n\n\n\n\n\n\n\nNext, the data is imported and a subset of the test portfolios is selected to make the estimation faster.\n\n\n\n\n\n\nIn\u00a0[5]:\n\n    \ndata = read_csv('FamaFrench.csv')\n\n# Split using both named colums and ix for larger blocks\ndates = data['date'].values\nfactors = data[['VWMe','SMB','HML']].values\nriskfree = data['RF'].values\nportfolios = data.iloc[:,5:].values\n\nT,N = portfolios.shape\nportfolios = portfolios[:,np.arange(0,N,2)]\nT,N = portfolios.shape\nexcessRet = portfolios - np.reshape(riskfree,(T,1))\nK = np.size(factors,1)\n\n\n    \n\n\n\n\n\n\n\nStarting values for the factor loadings and rick premia are estimated using OLS and simple means.\n\n\n\n\n\n\nIn\u00a0[6]:\n\n    \nbetas = []\nfor i in range(N):\n    res = sm.OLS(excessRet[:,i],sm.add_constant(factors)).fit()\n    betas.append(res.params[1:])\n\navgReturn = excessRet.mean(axis=0)\navgReturn.shape = N,1\nbetas = array(betas)\nres = sm.OLS(avgReturn, betas).fit()\nriskPremia = res.params\n\n\n    \n\n\n\n\n\n\n\nThe starting values are computed the first step estimates are found using the non-linear optimizer.  The initial weighting matrix is just the identify matrix.\n\n\n\n\n\n\nIn\u00a0[7]:\n\n    \nriskPremia.shape = 3\nstartingVals = np.concatenate((betas.flatten(),riskPremia))\n\nWinv = np.eye(N*(K+1))\nargs = (excessRet, factors, Winv)\niteration = 0\nfunctionCount = 0\nstep1opt = fmin_bfgs(gmm_objective, startingVals, args=args, callback=iter_print)\n\n\n    \n\n\n\n\n\n\n\n\n\n    \n\n\n\nFunc value: 1915.975414620774, Iteration: 1, Function Count: 132\nFunc value: 1817.0224254364093, Iteration: 2, Function Count: 220\nFunc value: 1814.9526088153193, Iteration: 3, Function Count: 308\nFunc value: 1814.8636328788023, Iteration: 4, Function Count: 396\nFunc value: 1814.7320075212833, Iteration: 5, Function Count: 440\nFunc value: 1814.4944170296885, Iteration: 6, Function Count: 484\nFunc value: 1814.4840096314288, Iteration: 7, Function Count: 572\nFunc value: 1814.4835355894866, Iteration: 8, Function Count: 660\nFunc value: 1814.4834334886873, Iteration: 9, Function Count: 748\nFunc value: 1814.4832402214106, Iteration: 10, Function Count: 792\nFunc value: 1814.483239345376, Iteration: 11, Function Count: 880\nFunc value: 1814.4832044513546, Iteration: 12, Function Count: 1012\nFunc value: 1814.3989963962504, Iteration: 13, Function Count: 1276\nFunc value: 1814.3642859418874, Iteration: 14, Function Count: 1320\nFunc value: 1814.301102018856, Iteration: 15, Function Count: 1364\nFunc value: 1814.301098499327, Iteration: 16, Function Count: 1452\nFunc value: 1814.3010704933515, Iteration: 17, Function Count: 1540\nFunc value: 1814.296612835476, Iteration: 18, Function Count: 1716\nFunc value: 1814.2538448019918, Iteration: 19, Function Count: 1804\nFunc value: 1814.253749266872, Iteration: 20, Function Count: 1892\nFunc value: 1814.2536217543443, Iteration: 21, Function Count: 1936\nFunc value: 1814.2341819587186, Iteration: 22, Function Count: 2112\nFunc value: 1814.2190046927274, Iteration: 23, Function Count: 2156\nFunc value: 1814.1901664290635, Iteration: 24, Function Count: 2200\nFunc value: 1814.1900618989262, Iteration: 25, Function Count: 2288\nFunc value: 1814.1899629209177, Iteration: 26, Function Count: 2332\nFunc value: 1814.1315029565549, Iteration: 27, Function Count: 2552\nFunc value: 1814.1207160483482, Iteration: 28, Function Count: 2640\nFunc value: 1814.120651593227, Iteration: 29, Function Count: 2728\nFunc value: 1814.1206404952559, Iteration: 30, Function Count: 2816\nFunc value: 1814.093987040505, Iteration: 31, Function Count: 3080\nFunc value: 1814.0931557560025, Iteration: 32, Function Count: 3168\nFunc value: 1814.0922310255569, Iteration: 33, Function Count: 3212\nFunc value: 1814.0921898261458, Iteration: 34, Function Count: 3300\nFunc value: 1814.092112795961, Iteration: 35, Function Count: 3344\nFunc value: 1814.080248929288, Iteration: 36, Function Count: 3520\nFunc value: 1814.0799729900195, Iteration: 37, Function Count: 3608\nFunc value: 1814.079961881844, Iteration: 38, Function Count: 3696\nFunc value: 1814.0799614793552, Iteration: 39, Function Count: 3784\nFunc value: 1814.0757650935916, Iteration: 40, Function Count: 4092\nFunc value: 1814.0755830705248, Iteration: 41, Function Count: 4180\nFunc value: 1814.0755746091875, Iteration: 42, Function Count: 4268\nFunc value: 1814.0702842972405, Iteration: 43, Function Count: 4488\nFunc value: 1814.0700243731067, Iteration: 44, Function Count: 4576\nFunc value: 1814.0700110352632, Iteration: 45, Function Count: 4664\nFunc value: 1814.0678482400072, Iteration: 46, Function Count: 4840\nFunc value: 1814.067660339931, Iteration: 47, Function Count: 4928\nFunc value: 1814.067656754271, Iteration: 48, Function Count: 5016\nFunc value: 1814.065377183398, Iteration: 49, Function Count: 5236\nFunc value: 1814.0652521531151, Iteration: 50, Function Count: 5324\nFunc value: 1814.0652503654978, Iteration: 51, Function Count: 5412\nFunc value: 1814.0640861808768, Iteration: 52, Function Count: 5632\nFunc value: 1814.0640022668042, Iteration: 53, Function Count: 5720\nFunc value: 1814.0611488164795, Iteration: 54, Function Count: 5852\nFunc value: 1814.059515832646, Iteration: 55, Function Count: 5896\nFunc value: 1814.0595158325361, Iteration: 56, Function Count: 5940\nFunc value: 1814.0595158325355, Iteration: 57, Function Count: 6072\nWarning: Desired error not necessarily achieved due to precision loss.\n         Current function value: 1814.059516\n         Iterations: 57\n         Function evaluations: 9031\n         Gradient evaluations: 205\n\n\n\n\n\n\n\n\n\n\n\nHere we look at the risk premia estimates from the first step (inefficient) estimates.\n\n\n\n\n\n\nIn\u00a0[8]:\n\n    \npremia = step1opt[-3:]\npremia = Series(premia,index=['VWMe', 'SMB', 'HML'])\nprint('Annualized Risk Premia (First step)')\nprint(12 * premia)\n\n\n    \n\n\n\n\n\n\n\n\n\n    \n\n\n\nAnnualized Risk Premia (First step)\nVWMe    5.829995\nSMB     4.068224\nHML     1.680948\ndtype: float64\n\n\n\n\n\n\n\n\n\n\n\nNext the first step estimates are used to estimate the moment conditions which are in-turn used to estimate the optimal weighting matrix for the moment conditions.  This is then used as an input for the 2nd-step estimates.\n\n\n\n\n\n\nIn\u00a0[9]:\n\n    \nout = gmm_objective(step1opt, excessRet, factors, Winv, out=True)\nS = np.cov(out[1].T)\nWinv2 = inv(S)\nargs = (excessRet, factors, Winv2)\n\niteration = 0\nfunctionCount = 0\nstep2opt = fmin_bfgs(gmm_objective, step1opt, args=args, callback=iter_print)\n\n\n    \n\n\n\n\n\n\n\n\n\n    \n\n\n\nFunc value: 70.69178252370772, Iteration: 1, Function Count: 132\nFunc value: 69.26303959975596, Iteration: 2, Function Count: 176\nFunc value: 67.07244129650894, Iteration: 3, Function Count: 220\nFunc value: 64.57443451479321, Iteration: 4, Function Count: 264\nFunc value: 62.64097306083999, Iteration: 5, Function Count: 308\nFunc value: 60.38315319123633, Iteration: 6, Function Count: 352\nFunc value: 59.77131346063476, Iteration: 7, Function Count: 396\nFunc value: 59.016700262647376, Iteration: 8, Function Count: 440\nFunc value: 58.11824688768306, Iteration: 9, Function Count: 484\nFunc value: 57.16139475771817, Iteration: 10, Function Count: 528\nFunc value: 56.54119670206884, Iteration: 11, Function Count: 572\nFunc value: 55.76261111890216, Iteration: 12, Function Count: 616\nFunc value: 54.70774239263665, Iteration: 13, Function Count: 660\nFunc value: 54.16273697904013, Iteration: 14, Function Count: 748\nFunc value: 53.68442984106602, Iteration: 15, Function Count: 792\nFunc value: 53.24912513313372, Iteration: 16, Function Count: 836\nFunc value: 52.95654923541569, Iteration: 17, Function Count: 880\nFunc value: 52.70763030807515, Iteration: 18, Function Count: 924\nFunc value: 52.40947922763522, Iteration: 19, Function Count: 968\nFunc value: 52.28025850343027, Iteration: 20, Function Count: 1012\nFunc value: 52.0945930956645, Iteration: 21, Function Count: 1056\nFunc value: 51.92591993694722, Iteration: 22, Function Count: 1100\nFunc value: 51.69127887764556, Iteration: 23, Function Count: 1144\nFunc value: 51.32800767550518, Iteration: 24, Function Count: 1188\nFunc value: 50.8832556502003, Iteration: 25, Function Count: 1232\nFunc value: 50.61502081122463, Iteration: 26, Function Count: 1276\nFunc value: 50.3253061036018, Iteration: 27, Function Count: 1320\nFunc value: 49.82326422689157, Iteration: 28, Function Count: 1364\nFunc value: 49.458055584312206, Iteration: 29, Function Count: 1408\nFunc value: 49.30507269503761, Iteration: 30, Function Count: 1452\nFunc value: 49.080604460391186, Iteration: 31, Function Count: 1496\nFunc value: 48.86937171160105, Iteration: 32, Function Count: 1540\nFunc value: 48.76039718096907, Iteration: 33, Function Count: 1628\nFunc value: 48.61522962324979, Iteration: 34, Function Count: 1672\nFunc value: 48.43822338181308, Iteration: 35, Function Count: 1716\nFunc value: 48.223264727455955, Iteration: 36, Function Count: 1760\nFunc value: 48.119297612182464, Iteration: 37, Function Count: 1804\nFunc value: 47.9966953205165, Iteration: 38, Function Count: 1848\nFunc value: 47.82071403838669, Iteration: 39, Function Count: 1892\nFunc value: 47.59984420196816, Iteration: 40, Function Count: 1936\nFunc value: 47.19190580374522, Iteration: 41, Function Count: 1980\nFunc value: 46.46434101774428, Iteration: 42, Function Count: 2024\nFunc value: 46.17952767128317, Iteration: 43, Function Count: 2112\nFunc value: 45.64869841620502, Iteration: 44, Function Count: 2156\nFunc value: 44.79178194363791, Iteration: 45, Function Count: 2200\nFunc value: 44.31246192707072, Iteration: 46, Function Count: 2244\nFunc value: 44.31220746711396, Iteration: 47, Function Count: 2288\nFunc value: 44.31216779746252, Iteration: 48, Function Count: 2332\nFunc value: 44.31216776026349, Iteration: 49, Function Count: 2376\nFunc value: 44.31216775979089, Iteration: 50, Function Count: 2420\nFunc value: 44.31216775977227, Iteration: 51, Function Count: 2464\nFunc value: 44.31216775977222, Iteration: 52, Function Count: 3564\nWarning: Desired error not necessarily achieved due to precision loss.\n         Current function value: 44.312168\n         Iterations: 52\n         Function evaluations: 6786\n         Gradient evaluations: 154\n\n\n\n\n\n\n\n\n\n\n\nFinally the VCV of the parameter estimates is computed.\n\n\n\n\n\n\nIn\u00a0[10]:\n\n    \nout = gmm_objective(step2opt, excessRet, factors, Winv2, out=True)\nG = gmm_G(step2opt, excessRet, factors)\nS = np.cov(out[1].T)\nvcv = inv(G @ inv(S) @ G.T)/T\n\n\n    \n\n\n\n\n\n\n\nThe annualized risk premia and their associated t-stats.\n\n\n\n\n\n\nIn\u00a0[11]:\n\n    \npremia = step2opt[-3:]\npremia = Series(premia,index=['VWMe', 'SMB', 'HML'])\npremia_vcv = vcv[-3:,-3:]\nprint('Annualized Risk Premia')\nprint(12 * premia)\n\npremia_stderr = np.diag(premia_vcv)\npremia_stderr = Series(premia_stderr,index=['VWMe', 'SMB', 'HML'])\nprint('T-stats')\nprint(premia / premia_stderr)\n\n\n    \n\n\n\n\n\n\n\n\n\n    \n\n\n\nAnnualized Risk Premia\nVWMe    10.089708\nSMB      3.457167\nHML      7.620110\ndtype: float64\nT-stats\nVWMe    28.282294\nSMB     22.372714\nHML     43.791637\ndtype: float64",
      "tags": "",
      "url": "https://www.kevinsheppard.com/teaching/python/notes/notebooks/example-gmm-estimation/"
    },
    {
      "title": "Example: LaTeX Output",
      "text": "Example: Exporting to $\\LaTeX$\u00b6The first code block contains the imports needed and defines a flag which determines whether the \noutput $\\LaTeX$ should be compiled.\n\n\n\n\n\n\nIn\u00a0[1]:\n\n    \n# imports\nimport numpy as np\nimport subprocess\n\n# Flag to compile output tables\ncompileLatex = False\n\n\n    \n\n\n\n\n\n\n\nThe next code block loads the npz file created using the output from the Fama-MacBeth example.\nThe second part shows a generic method to restore all variables. The loaded data is in a dictionary,\nand so iterating over the keys and using globals() (a dictionary) in the main program.\n\n\n\n\n\n\nIn\u00a0[2]:\n\n    \n# Load variables\nf = np.load('fama-macBeth-results.npz')\ndata = f.items()\n# Manually load parameters and std errors\narp = f['arp']\narpSE = f['arpSE']\nbeta = f['beta']\nbetaSE = f['betaSE']\nJ = f['J']\nJpval = f['Jpval']\n\n# Generic restore of all data in a npz file\nfor key in f.keys():\n    globals()[key] = f[key]\nf.close()\n\n\n    \n\n\n\n\n\n\n\nThe document is be stored in a list. The first few lines contain the required header for a\n$\\LaTeX$ document, including some packages used to improve table display and to select a custom font.\n\n\n\n\n\n\nIn\u00a0[3]:\n\n    \n# List to hold table\nlatex = []\n# Initializd LaTeX document\nlatex.append(r'\\documentclass[a4paper]{article}')\nlatex.append(r'\\usepackage{amsmath}')\nlatex.append(r'\\usepackage{booktabs}')\nlatex.append(r'\\usepackage[adobe-utopia]{mathdesign}')\nlatex.append(r'\\usepackage[T1]{fontenc}')\nlatex.append(r'\\begin{document}')\n\n\n    \n\n\n\n\n\n\n\nTable 1 is stored in its own list, and then extend will be used to add it to the main list.\n\n\n\n\n\n\nIn\u00a0[4]:\n\n    \n# Table 1\ntable1 = []\ntable1.append(r'\\begin{center}')\ntable1.append(r'\\begin{tabular}{lrrr} \\toprule')\n# Header\ncolNames = [r'VWM$e$','SMB','HML']\nheader = ''\nfor cName in colNames:\n    header += ' & ' + cName\n\nheader += r'\\\\ \\cmidrule{2-4}'\ntable1.append(header)\n# Main row\nrow = ''\nfor a,se in zip(arp,arpSE):\n    row += r' & $\\underset{{({0:0.3f})}}{{{1:0.3f}}}$'.format(se,a)\ntable1.append(row)\n# Blank row\nrow = r'\\\\'\ntable1.append(row)\n# J-stat row\nrow = r'J-stat: $\\underset{{({0:0.3f})}}{{{1:0.1f}}}$ \\\\'.format(float(Jpval),float(J))\ntable1.append(row)\ntable1.append(r'\\bottomrule \\end{tabular}')\ntable1.append(r'\\end{center}')\n# Extend latex with table 1\nlatex.extend(table1)\nlatex.append(r'\\newpage')\n\n\n    \n\n\n\n\n\n\n\nTable 2 is a bit more complex, and uses loops to iterate over the rows of the arrays containing\nthe $\\beta$s and their standard errors.\n\n\n\n\n\n\nIn\u00a0[5]:\n\n    \n# Format information for table 2\nsizes = ['S','2','3','4','B']\nvalues = ['L','2','3','4','H']\n# Table 2 has the same header as table 1, copy with a slice\ntable2 = table1[:3]\nm = 0\nfor i in range(len(sizes)):\n    for j in range(len(values)):\n        row = 'Size: {:}, Value: {:} '.format(sizes[i],values[j])\n        b = beta[:,m]\n        s = betaSE[m,1:]\n        for k in range(len(b)):\n            row += r' & $\\underset{{({0:0.3f})}}{{{1: .3f}}}$'.format(s[k],b[k])\n        row += r'\\\\ '\n        table2.append(row)\n        m += 1\n    if i<(len(sizes)-1):\n        table2.append(r'\\cmidrule{2-4}')\n\ntable2.append(r'\\bottomrule \\end{tabular}')\ntable2.append(r'\\end{center}')\n# Extend with table 2\nlatex.extend(table2)\n\n\n    \n\n\n\n\n\n\n\nThe penultimate block finished the document, and uses write to write the lines to the $\\LaTeX$ file.\n\n\n\n\n\n\nIn\u00a0[6]:\n\n    \n# Finish document   \nlatex.append(r'\\end{document}')\n# Write to table\nfid = open('latex.tex','w')\nfor line in latex:\n    fid.write(line + '\\n')\nfid.close()\n\n\n    \n\n\n\n\n\n\n\nFinally, if the flag is set, subprocess is used to compile the LaTeX.\n\n\n\n\n\n\nIn\u00a0[7]:\n\n    \n# Compile if needed\nif compileLatex:\n    exitStatus = subprocess.run(['pdflatex', 'latex.tex'])",
      "tags": "",
      "url": "https://www.kevinsheppard.com/teaching/python/notes/notebooks/example-latex-output/"
    },
    {
      "title": "Python Course",
      "text": "This course is an introduction to Python and programming aimed at students working\nin Finance and Economics. The course is designed to be taught using the Jupyter notebooks\nthat are in the course GitHub repository and\nare linked below. The complete course is available for\ndownload as a pdf.\nGitHub\u00b6\nThe introduction is available on Github. \nIf you are happy to use git, you can download everything\nusing git, or for even fork the repo and save your progress to your own fork.\nSelf-paced Study\u00b6\nThis course is intended as an alternative to the MATLAB introduction and so\nis self-paced.  Each of the lessons is covered in one or more videos that are\navailable in a YouTube channel.\nNote: The video content is a work-in-progress and should be completed by mid-October 2019.\nNotebooks\u00b6\n\n\n\n\ufeffLesson\nLink to Download\nDemonstration(s)\n\n\n\n\n\nInstallation\nDownload\nInstallation\n\n\n\nLesson 1\nDownload\nLesson 1: Part 1, Part 2, Part 3\n\n\n\nLesson 2\nDownload\nLesson 2\n\n\n\nLesson 3\nDownload\nLesson 3\n\n\n\nLesson 4\nDownload\nLesson 4\n\n\n\nLesson 5\nDownload\nLesson 5\n\n\n\nLesson 6\nDownload\n\n\n\n\nLesson 7\nDownload\n\n\n\n\nLesson 8\nDownload\n\n\n\n\nLesson 9\nDownload\n\n\n\n\nLesson 10\nDownload\n\n\n\n\nLesson 11\nDownload\n\n\n\n\nLesson 12\nDownload\n\n\n\n\nLesson 13\nDownload\n\n\n\n\nLesson 14\nDownload\n\n\n\n\nLesson 15\nDownload\n\n\n\n\nLesson 16\nDownload\n\n\n\n\nLesson 17\nDownload\n\n\n\n\nLesson 18\nDownload\n\n\n\n\nLesson 19\nDownload\n\n\n\n\nLesson 20\nDownload\n\n\n\n\nLesson 21\nDownload\n\n\n\n\nLesson 22\nDownload\n\n\n\n\nFinal Exam\nDownload\n\n\n\n\n\nDownloading: Right-click and select Download to save the notebook files to your computer.\nData and Supporting Files\u00b6\nData",
      "tags": "",
      "url": "https://www.kevinsheppard.com/teaching/python/course/"
    },
    {
      "title": "Specimen",
      "text": "Specimen\u00b6\nBody copy\u00b6\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Cras arcu libero,\nmollis sed massa vel, ornare viverra ex. Mauris a ullamcorper lacus. Nullam\nurna elit, malesuada eget finibus ut, ullamcorper ac tortor. Vestibulum sodales\npulvinar nisl, pharetra aliquet est. Quisque volutpat erat ac nisi accumsan\ntempor.\nSed suscipit, orci non pretium pretium, quam mi gravida metus, vel\nvenenatis justo est condimentum diam. Maecenas non ornare justo. Nam a ipsum\neros. Nulla aliquam orci sit amet nisl posuere malesuada. Proin aliquet\nnulla velit, quis ultricies orci feugiat et. Ut tincidunt sollicitudin\ntincidunt. Aenean ullamcorper sit amet nulla at interdum.\nHeadings\u00b6\nThe 3rd level\u00b6\nThe 4th level\u00b6\nThe 5th level\u00b6\nThe 6th level\u00b6\nHeadings with secondary text\u00b6\nThe 3rd level with secondary text\u00b6\nThe 4th level with secondary text\u00b6\nThe 5th level with secondary text\u00b6\nThe 6th level with secondary text\u00b6\nBlockquotes\u00b6\n\nMorbi eget dapibus felis. Vivamus venenatis porttitor tortor sit amet rutrum.\n  Pellentesque aliquet quam enim, eu volutpat urna rutrum a. Nam vehicula nunc\n  mauris, a ultricies libero efficitur sed. Class aptent taciti sociosqu ad\n  litora torquent per conubia nostra, per inceptos himenaeos. Sed molestie\n  imperdiet consectetur.\n\nBlockquote nesting\u00b6\n\nSed aliquet, neque at rutrum mollis, neque nisi tincidunt nibh, vitae\n  faucibus lacus nunc at lacus. Nunc scelerisque, quam id cursus sodales, lorem\n  libero fermentum urna, ut efficitur elit ligula et nunc.\n\nMauris dictum mi lacus, sit amet pellentesque urna vehicula fringilla.\n    Ut sit amet placerat ante. Proin sed elementum nulla. Nunc vitae sem odio.\n    Suspendisse ac eros arcu. Vivamus orci erat, volutpat a tempor et, rutrum.\n    eu odio.\n\nSuspendisse rutrum facilisis risus, eu posuere neque commodo a.\n      Interdum et malesuada fames ac ante ipsum primis in faucibus. Sed nec leo\n      bibendum, sodales mauris ut, tincidunt massa.\n\n\n\nOther content blocks\u00b6\n\nVestibulum vitae orci quis ante viverra ultricies ut eget turpis. Sed eu\n  lectus dapibus, eleifend nulla varius, lobortis turpis. In ac hendrerit nisl,\n  sit amet laoreet nibh.\n\nvar _extends = function(target) {\nfor (var i = 1; i < arguments.length; i++) {\n  var source = arguments[i];\n  for (var key in source) {\n    target[key] = source[key];\n  }\n}\nreturn target;\n};\n\n\n\n\n\nPraesent at return target, sodales nibh vel, tempor felis. Fusce\n      vel lacinia lacus. Suspendisse rhoncus nunc non nisi iaculis ultrices.\n      Donec consectetur mauris non neque imperdiet, eget volutpat libero.\n\n\nLists\u00b6\nUnordered lists\u00b6\n\n\nSed sagittis eleifend rutrum. Donec vitae suscipit est. Nullam tempus tellus\n  non sem sollicitudin, quis rutrum leo facilisis. Nulla tempor lobortis orci,\n  at elementum urna sodales vitae. In in vehicula nulla, quis ornare libero.\n\nDuis mollis est eget nibh volutpat, fermentum aliquet dui mollis.\nNam vulputate tincidunt fringilla.\nNullam dignissim ultrices urna non auctor.\n\n\n\nAliquam metus eros, pretium sed nulla venenatis, faucibus auctor ex. Proin ut\n  eros sed sapien ullamcorper consequat. Nunc ligula ante, fringilla at aliquam\n  ac, aliquet sed mauris.\n\n\nNulla et rhoncus turpis. Mauris ultricies elementum leo. Duis efficitur\n  accumsan nibh eu mattis. Vivamus tempus velit eros, porttitor placerat nibh\n  lacinia sed. Aenean in finibus diam.\n\n\nOrdered lists\u00b6\n\n\nInteger vehicula feugiat magna, a mollis tellus. Nam mollis ex ante, quis\n  elementum eros tempor rutrum. Aenean efficitur lobortis lacinia. Nulla\n  consectetur feugiat sodales.\n\n\nCum sociis natoque penatibus et magnis dis parturient montes, nascetur\n  ridiculus mus. Aliquam ornare feugiat quam et egestas. Nunc id erat et quam\n  pellentesque lacinia eu vel odio.\n\n\nVivamus venenatis porttitor tortor sit amet rutrum. Pellentesque aliquet\n  quam enim, eu volutpat urna rutrum a. Nam vehicula nunc mauris, a\n  ultricies libero efficitur sed.\n\nMauris dictum mi lacus\nUt sit amet placerat ante\nSuspendisse ac eros arcu\n\n\n\nMorbi eget dapibus felis. Vivamus venenatis porttitor tortor sit amet\n  rutrum. Pellentesque aliquet quam enim, eu volutpat urna rutrum a. Sed\n  aliquet, neque at rutrum mollis, neque nisi tincidunt nibh.\n\n\nPellentesque eget var _extends ornare tellus, ut gravida mi.\n\n\n\n\nvar _extends = function(target) {\n  for (var i = 1; i < arguments.length; i++) {\n    var source = arguments[i];\n    for (var key in source) {\n      target[key] = source[key];\n    }\n  }\n  return target;\n};\n\n\n\n\nVivamus id mi enim. Integer id turpis sapien. Ut condimentum lobortis\n  sagittis. Aliquam purus tellus, faucibus eget urna at, iaculis venenatis\n  nulla. Vivamus a pharetra leo.\n\nDefinition lists\u00b6\n\nLorem ipsum dolor sit amet\n\nSed sagittis eleifend rutrum. Donec vitae suscipit est. Nullam tempus\ntellus non sem sollicitudin, quis rutrum leo facilisis. Nulla tempor\nlobortis orci, at elementum urna sodales vitae. In in vehicula nulla.\nDuis mollis est eget nibh volutpat, fermentum aliquet dui mollis.\nNam vulputate tincidunt fringilla.\nNullam dignissim ultrices urna non auctor.\n\nCras arcu libero\n\nAliquam metus eros, pretium sed nulla venenatis, faucibus auctor ex. Proin\nut eros sed sapien ullamcorper consequat. Nunc ligula ante, fringilla at\naliquam ac, aliquet sed mauris.\n\n\nCode blocks\u00b6\nInline\u00b6\nMorbi eget dapibus felis. Vivamus venenatis porttitor tortor sit amet\nrutrum. Class aptent taciti sociosqu ad litora torquent per conubia nostra,\nper inceptos himenaeos. Pellentesque aliquet quam enim, eu volutpat urna\nrutrum a.\nNam vehicula nunc return target mauris, a ultricies libero efficitur\nsed. Sed molestie imperdiet consectetur. Vivamus a pharetra leo. Pellentesque\neget ornare tellus, ut gravida mi. Fusce vel lacinia lacus.\nListing\u00b6\n1\n2\n3\n4\n5\n6\n7\n8\n9var _extends = function(target) {\n  for (var i = 1; i < arguments.length; i++) {\n    var source = arguments[i];\n    for (var key in source) {\n      target[key] = source[key];\n    }\n  }\n  return target;\n};\n\n\n\nHorizontal rules\u00b6\nAenean in finibus diam. Duis mollis est eget nibh volutpat, fermentum aliquet\ndui mollis. Nam vulputate tincidunt fringilla. Nullam dignissim ultrices urna\nnon auctor.\n\nInteger vehicula feugiat magna, a mollis tellus. Nam mollis ex ante, quis\nelementum eros tempor rutrum. Aenean efficitur lobortis lacinia. Nulla\nconsectetur feugiat sodales.\nData tables\u00b6\n\n\n\nSollicitudo / Pellentesi\nconsectetur\nadipiscing\nelit\narcu\nsed\n\n\n\n\nVivamus a pharetra\nyes\nyes\nyes\nyes\nyes\n\n\nOrnare viverra ex\nyes\nyes\nyes\nyes\nyes\n\n\nMauris a ullamcorper\nyes\nyes\npartial\nyes\nyes\n\n\nNullam urna elit\nyes\nyes\nyes\nyes\nyes\n\n\nMalesuada eget finibus\nyes\nyes\nyes\nyes\nyes\n\n\nUllamcorper\nyes\nyes\nyes\nyes\nyes\n\n\nVestibulum sodales\nyes\n-\nyes\n-\nyes\n\n\nPulvinar nisl\nyes\nyes\nyes\n-\n-\n\n\nPharetra aliquet est\nyes\nyes\nyes\nyes\nyes\n\n\nSed suscipit\nyes\nyes\nyes\nyes\nyes\n\n\nOrci non pretium\nyes\npartial\n-\n-\n-\n\n\n\nSed sagittis eleifend rutrum. Donec vitae suscipit est. Nullam tempus tellus\nnon sem sollicitudin, quis rutrum leo facilisis. Nulla tempor lobortis orci,\nat elementum urna sodales vitae. In in vehicula nulla, quis ornare libero.\n\n\n\nLeft\nCenter\nRight\n\n\n\n\nLorem\ndolor\namet\n\n\nipsum\nsit\n\n\n\n\nVestibulum vitae orci quis ante viverra ultricies ut eget turpis. Sed eu\nlectus dapibus, eleifend nulla varius, lobortis turpis. In ac hendrerit nisl,\nsit amet laoreet nibh.\n\n  \n    \n    \n  \n  \n    \n      Table\n      with colgroups (Pandoc)\n    \n  \n  \n    \n      Lorem\n      ipsum dolor sit amet.\n    \n    \n      Sed sagittis\n      eleifend rutrum. Donec vitae suscipit est.",
      "tags": "",
      "url": "https://www.kevinsheppard.com/specimen/"
    },
    {
      "title": "Research",
      "text": "Write your page here.",
      "tags": "",
      "url": "https://www.kevinsheppard.com/research/"
    },
    {
      "title": "LyX",
      "text": "LyX is a powerful WSYIWYG editor\nfor LaTeX. I am an avid user of LyX since it allows for a highly productive environment for \nwriting text and formatted math while continuing to allow for a high degree of customizability. \nLyX is an open source version of Scientific Workplace which is both more modern and has broader\ncompatibility with standard LaTeX.\nLyX is cross platform and works equally well on Windows, Linux or OS X.\nThese videos comprise a basic introduction to LyX and cover the core tools needed to write a \nThesis or paper in Economics or Econometrics (and many other fields, especially in mathematics, \nstatistics or social sciences).\nVideo Introduction\u00b6\n\nInstalling LyX on Windows\nInstalling LyX on Linux\nSetting up a New Document and Basic Structure\nBasic Text Input\nList Environments\nAdding Math\nTables\nFigures\nThe Bibliography\nAdding Custom LaTeX in LyX\nExporting Completed Documents\nPresentations (Beamer) in LyX\n\nWritten Guidance\u00b6\nSome people prefer a written guide. Fortunately (for me), a good guide has been written \n(by others) and is available at Lyx Guide.",
      "tags": "lyx",
      "url": "https://www.kevinsheppard.com/teaching/lyx/"
    },
    {
      "title": "Archived and Other Teaching",
      "text": "Archived Courses\u00b6\nAdvanced Econometrics is full course covering forecasting\nfrom high-dimensional spaces and evaluating forecasts when many models are tried (data snooping).\nOxCort Hacking\u00b6\nOxCORT is painful to use. The console in Firefox or Chrome can be used to automate filling out many\nforms. A simple example is:\nfor (i=0;i<=17;i++)\n{\n    temp = document.getElementById(\"RF_\" + i + \"_toCome\");\n    temp.value = 2;\n    temp = document.getElementById(\"RF_\" + i + \"_workSet\");\n    temp.value = 4;\n    temp = document.getElementById(\"RF_\" + i + \"_workDone\");\n    temp.value = 3;\n    temp = document.getElementById(\"RF_\" + i + \"_workLate\");\n    temp.value = 0;\n    temp = document.getElementById(\"RF_\" + i + \"_industry\");\n    temp.value = \"Very good\";\n    temp = document.getElementById(\"RF_\" + i + \"_progress\");\n    temp.value = \"Very good\";\n    temp = document.getElementById(\"RF_\" + i + \"_grade\");\n    temp.value = \"2.i/1\";;\n}\n\n\n\nWebsite-related content\u00b6\nSpecimen\nNotebook Specimen",
      "tags": "",
      "url": "https://www.kevinsheppard.com/teaching/other/"
    },
    {
      "title": "MATLAB",
      "text": "Introductory Notes and Course\u00b6\nMATLAB Notes and Course is a set of notes and an introductory\nMATLAB course designed for new users.\nMFE Companion Course\u00b6\nThe companion course is designed to accompany\nFinancial Econometrics I and II and to provide tools needed in Empirical Asset\npricing.  \nMFE Toolbox\u00b6\nThe MFE Toolbox provides a large collection of\nMATLAB functions for analyzing financial time series.",
      "tags": "",
      "url": "https://www.kevinsheppard.com/teaching/matlab/"
    },
    {
      "title": "Python",
      "text": "Python Notes\u00b6\nA set of notes that introduce the core concepts of Python that\nare relevant to applications in Statistics, Econometrics and many other\nnumerical areas. Codes Python fundamentals, NumPy, Pandas,\nand some parts of SciPy and statsmdoels.  \nPython Notes\nIntroductory Python Course\u00b6\nA short course designed for people new to Python, and often new\nto programming.  Starts with the basics - getting the Python environemnt\nright, and work through entering arrays and pandas DataFrame, selecting\nelements, basic looping and graphics.  \nIntroductory Course",
      "tags": "",
      "url": "https://www.kevinsheppard.com/teaching/python/"
    },
    {
      "title": "Python Notes",
      "text": "Python Notes\u00b6\nIntroduction to Python for Econometrics, Statistics and Numerical Analysis: Third Edition \nNew material added to the third edition on January 3, 2018.\nDownload the Notes\nPython is a widely used general purpose programming language, which\nhappens to be well suited to econometrics, data analysis and other more\ngeneral numeric problems. These notes provide an introduction to Python\nfor a beginning programmer. They may also be useful for an experienced\nPython programmer interested in using NumPy, SciPy, matplotlib and\npandas for numerical and statistical analysis (if this is the case, much\nof the beginning can be skipped).\nThird edition, Update 1\u00b6\n\nVerified that all code and examples work correctly against 2019 versions of modules. The\n   notable packages and their versions are:\nPython 3.7 (Preferred version)\nNumPy: 1.16\nSciPy: 1.3\npandas: 0.25\nmatplotlib: 3.1\nPython 2.7 support has been officially dropped, although most examples continue to work with 2.7.\n   Do not Python 2.7 in 2019 for numerical code.\n\nThird edition update\u00b6\n\nRewritten installation section focused exclusively on using\n    Continuum\\'s Anaconda.\nPython 3.5 is the default version of Python instead of 2.7. Python\n    3.5 (or newer) is well supported by the Python packages required to\n    analyze data and perform statistical analysis, and bring some new\n    useful features, such as a new operator for matrix multiplication\n    (@).\nRemoved distinction between integers and longs in built-in data\n    types chapter. This distinction is only relevant for Python 2.7.\ndot has been removed from most examples and replaced with @ to\n    produce more readable code.\nSplit Cython and Numba into separate chapters to highlight the\n    improved capabilities of Numba.\nVerified all code working on current versions of core libraries\n    using Python 3.5.\npandas\nUpdated syntax of pandas functions such as resample.\nAdded pandas Categorical.\nExpanded coverage of pandas groupby.\nExpanded coverage of date and time data types and functions.\n\n\nNew chapter introducing statsmodels, a package that facilitates\n    statistical analysis of data. statsmodels includes regression\n    analysis, Generalized Linear Models (GLM) and time-series analysis\n    using ARIMA models.\n\nSecond edition update\u00b6\n\nImproved Cython and Numba sections\nAdded sections discussing interfacing with C code\nAdded sections to the chapter on running code in Parallel covering\n    IPython\\'s cluster server and joblib\nFurther improvements in the installation based on feedback from the\n    Python Course\nUpdated Anaconda to 1.9\nAdded information about using Spyder as an initial IDE.\nAdded packages for Spyder to the installation instructions.\n\nNew in second edition\u00b6\n\nThe preferred installation method is now Continuum Analytics\\'\n    Anaconda. Anaconda is a complete scientific stack and is available\n    for all major platforms.\nNew chapter on pandas. pandas provides a simple but powerful tool to\n    manage data and perform basic analysis. It also greatly simplifies\n    importing and exporting data.\nNew chapter on advanced selection of elements from an array.\nNumba provides just-in-time compilation for numeric Python code\n    which often produces large performance gains when pure NumPy\n    solutions are not available (e.g. looping code).\nAddition to performance section covering line_profiler for\n    profiling code.\nDictionary, set and tuple comprehensions.\nNumerous typos fixed.\nAll code has been verified working against Anaconda 1.7.0.\n\nNotes\u00b6\nIntroduction to Python for Econometrics, Statistics and Numerical Analysis: Third Edition\nData and Notebooks\u00b6\nData\u00b6\n\nData and Code from the notes. These files are needed to run some of the code in the notes.\nThe Fama-French data set is used in the asset-pricing examples.\nThe FTSE 100 data from 1984 until 2012 is used in the GJR-GARCH example.\n\nNotebooks\u00b6\nThese notebooks contains the four extended examples from the Examples chapter.\n\nEstimation of a GJR-GARCH model (download)\nEstimation of risk premia using Fama-MacBeth (download)\nEstimation using the Generalized Method of Moments (GMM) (download)\nOutputting to LaTeX (download)\n\nMini-course\u00b6\nPython Course",
      "tags": "python",
      "url": "https://www.kevinsheppard.com/teaching/python/notes/"
    },
    {
      "title": "MFE Teaching Resources",
      "text": "This is a place holder for the 2019/20 MFE Course content. I lecture in Hilary term.\nNotes\u00b6\nThe complete set of notes covers all aspects of the Financial Econometrics I and II courses. \nMATLAB\u00b6\nThe companion course is designed to accompany Financial Econometrics I and II and\nto provide tools needed in Empirical Asset pricing.",
      "tags": "",
      "url": "https://www.kevinsheppard.com/teaching/mfe/"
    },
    {
      "title": "Moving to Static Site Generation",
      "text": "This is the first post on my new site.  This site is a static site generated using Nikola, \na static-site generator written in Python. I chose it because I know Python pretty well and\nso can customize any feature I want. It also natively supports Jupyter Notebooks, which is \na big plus. \n\n\nWhile switching over I seriously considered Hugo, a generator\nwritten in Go which seems to have a very large and dedicated base. I may eventually switch \nover. Hugo although the Jupyter integration is nearly non-existent (i.e., manually export to\nmarkdown).\nThe Old Stack\u00b6\nThe good\u00b6\nFor many years I have used mediawiki as a Content Management System. \nI found this to be a relatively simple approach since it allowed be to create and populate a page\nwith links to other documents or files, whether these existed or not. If a page or file did \nnot exist, I could click on its link (which has a 404-color code) and either edit the missing\npage or add the file.  The wiki software also has a number of special pages that let me see\nall missing file.  As a bonus, MediaWiki indexes all content so that the site is immediately \nsearchable. There are many extensions that are helpful in integrating with other services,\ne.g., embedding YouTube videos. \nThe bad\u00b6\nWhat I didn't like about the old site was its fragility.  I regularly received emails telling \nme that my site was down.  These were driven by a connectivity issue with the MariaDB that stored\nthe site's data or with php-fpm which managed the relationship between the nginx front end\nand the PHP engine. My site depended on the correct operation of:\n\nnginx\nMariaDB\nphp-fpm\nMediaWiki\nA DigitalOcean droplet\n\nI also didn't like the feeling that I had to regularly patch the software. While I could setup\nUbuntu to automatically apply patches, I was always nervous about doing this with the MediaWiki\nsoftware. Instead, I would manually patch when I received an email from their security mailing list.\nIn addition, I had to occasionally migrate PHP versions when the current LTS increased its minimum\nsupported version. This was particularly challenging for me since I do not regularly use PHP and so \nI had to reinvent the wheel each time this happened (which I think was only twice, in fairness)\nThe extension landscape was also very uneven.  Many extensions I tried had no long-term support and \nso would continue to work until they used a feature that had been removed. This required repeatedly \nsearching for new extensions, and eventually lead me to remove most of them.  \nThe new site\u00b6\nThe good\u00b6\nThe new site is static in the sense that it is only a collection of HTML, CSS, JavaScript, images\nand other content files.  The only server I need is a webserver (e.g., nginx). While I \nam initially hosting it on the same droplet I used for my MediaWiki installation, I plan \non moving to GitHub pages using Travis CI to build the pages.  This will both save my time and\nmoney.\nThe bad\u00b6\nWhile writing a simple site or pure blog is pretty food proof, Nikola is not a great site generator.\nThe biggest problems I have faced are (some) lack of out-of-box customizability, lack of\na theme I like, and nothing helping me ensure that I do not have missing or orphan pages.\nThe upside for me is that these are all pretty simple to fix writing a few custom plugins. \nFor example, I wrote one that reads the site contents, file a list of files and finds all\nlinks to these files.  It then uses a couple of set operations to determine if there are\nany missing files (really important) or orphan files (less important, but still annoying).",
      "tags": "code,website",
      "url": "https://www.kevinsheppard.com/blog/moving-to-static-site-generation/"
    },
    {
      "title": "index",
      "text": "Background\u00b6\nI currently work at the University of Oxford as a Financial Econometrician. \nMy research focuses on volatility and uncertainty. Measuring and modeling \nconditional correlation, a key input into portfolio risk models is a \ncornerstone of my research.\nI have produced a large volume of teaching resources, including a complete \nset of notes in Financial Econometrics, and introductions to both \nPython and MATLAB. \nI also maintain a number of widely used toolboxes related to my research. The most\nbroadly used of these are the MFE Toolbox for MATLAB, \nand the arch (documentation, \n) \nand linearmodels (documentation, )\nmodules for Python. See my GitHub page for a \ncomplete list of projects.\nI enjoy hiking and being outdoors, although I don't get out as much as I \nwould like. You can see some pictures of my adventures in the gallery. \nI have a sweet but rambunctious chocolate labrador, Callie.",
      "tags": "",
      "url": "https://www.kevinsheppard.com/"
    },
    {
      "title": "Search",
      "text": "Search results appear here.",
      "tags": "",
      "url": "https://www.kevinsheppard.com/search/"
    }
  ]
};