var tipuesearch = {
  "pages": [
    {
      "title": "MFE MATLAB",
      "text": "Solutions are posted after the class that covers the assignment has completed.  Solutions are available both as\nMATLAB Live Scripts, which provide an integrated view of code, text and mathematics and generic m-file scripts.\nLive Scripts are only usable in recent versions of MATLAB.\n\n\nMATLAB Notes\nIntroduction\nIntroduction Solutions\n\n\nCompanion Course\nSolutions\n\n\n\n\nMATLAB Notes\u00b6\nThis set of notes is a detailed introduction of using MATLAB and covers virtually all aspects required to implement\nnew models in MATLAB.  It assumes no knowledge of MATLAB and coverall everything required to complete econometric\nand statistical analysis in MATLAB.\nMATLAB Notes for Econometric and Statistical Analysis\nMATLAB Notes for Econometric and Statistical Analysis Data\nIntroduction\u00b6\nMATLAB Introduction Course\nMATLAB Introduction Course Data\nIntroduction Solutions\u00b6\n\n\n\nMATLAB Live Script (mlx)\nMATLAB Script (m)\n\n\n\n\nImporting Data into MATLAB\nImporting Data into MATLAB\n\n\nUsing functions\nUsing functions\n\n\nAccessing elements in matrices\nAccessing elements in matrices\n\n\nProgram flow\nProgram flow\n\n\nLogical statements\nLogical statements\n\n\nTables\nTables\n\n\nGraphics\nGraphics\n\n\n\nCompanion Course\u00b6\nMATLAB Companion Course (Complete)\nSolutions\u00b6\n\nSolution Availability\nSolutions are provided in the week when a module is taught.",
      "tags": "matlab,mfe",
      "url": "https://bashtage.github.io/kevinsheppard.com/teaching/matlab/mfe-matlab/"
    },
    {
      "title": "Presentations (Beamer) in LyX",
      "text": "",
      "tags": "lyx",
      "url": "https://bashtage.github.io/kevinsheppard.com/teaching/lyx/beamer-presentations/"
    },
    {
      "title": "Exporting Completed Documents",
      "text": "",
      "tags": "lyx",
      "url": "https://bashtage.github.io/kevinsheppard.com/teaching/lyx/exporting/"
    },
    {
      "title": "Adding Custom LaTeX in LyX",
      "text": "",
      "tags": "lyx",
      "url": "https://bashtage.github.io/kevinsheppard.com/teaching/lyx/custom-latex/"
    },
    {
      "title": "The Bibliography",
      "text": "",
      "tags": "lyx",
      "url": "https://bashtage.github.io/kevinsheppard.com/teaching/lyx/bibliography/"
    },
    {
      "title": "Figures",
      "text": "",
      "tags": "lyx",
      "url": "https://bashtage.github.io/kevinsheppard.com/teaching/lyx/figures/"
    },
    {
      "title": "Tables",
      "text": "",
      "tags": "lyx",
      "url": "https://bashtage.github.io/kevinsheppard.com/teaching/lyx/tables/"
    },
    {
      "title": "Adding Math",
      "text": "",
      "tags": "lyx",
      "url": "https://bashtage.github.io/kevinsheppard.com/teaching/lyx/math/"
    },
    {
      "title": "List Environments",
      "text": "",
      "tags": "lyx",
      "url": "https://bashtage.github.io/kevinsheppard.com/teaching/lyx/lists/"
    },
    {
      "title": "Basic Text Input",
      "text": "",
      "tags": "lyx",
      "url": "https://bashtage.github.io/kevinsheppard.com/teaching/lyx/basic-input/"
    },
    {
      "title": "Setting up a New Document and Basic Structure",
      "text": "",
      "tags": "lyx",
      "url": "https://bashtage.github.io/kevinsheppard.com/teaching/lyx/new-document/"
    },
    {
      "title": "Notebook Specimen",
      "text": "Jupyter Notebooks\u00b6The nbsphinx extension allow notebooks to be seemlessly integrated into a Sphinx website.  This page demonstrates how notebooks are rendered.\n\n\n\n\n\n\n\nMathematics\u00b6MathJax can use used to render mathematical equations. Equations can\nbe rendered either in their own line using double dollar signs\n$$ y_{it} = \\alpha_i + \\gamma_t + \\beta x_{it} + \\epsilon_{it} $$or inline using single dollar signs ($\\LaTeX$).\n\n\n\n\n\n\n\nDataFrames\u00b6pandas DataFrames are rendered with useful markup.\n\n\n\n\n\n\nIn\u00a0[1]:\n\n    \nimport numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame({'ints': [1, 2, 3], \n                   'floats': [np.pi, np.exp(1), (1+np.sqrt(5))/2],\n                   'strings': ['aardvark', 'bananarama', 'charcuterie' ]})\n\ndf\n\n\n    \n\n\n\n\n\n\n\n\n\n    Out[1]:\n\n\n\n\n\n\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n\n\n  \n    \n      \n      ints\n      floats\n      strings\n    \n  \n  \n    \n      0\n      1\n      3.141593\n      aardvark\n    \n    \n      1\n      2\n      2.718282\n      bananarama\n    \n    \n      2\n      3\n      1.618034\n      charcuterie\n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\nPlots and Figures\u00b6matplotlib can be used to produce plots in notebooks\nThis example comes from the matplotlib gallery.\n\n\n\n\n\n\nIn\u00a0[2]:\n\n    \n%matplotlib inline\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib import cm\n\nfig, ax = plt.subplots(figsize=(12,8))\n\ndata = np.clip(np.random.randn(250, 250), -1, 1)\n\ncax = ax.imshow(data, interpolation='nearest', cmap=cm.coolwarm)\nax.set_title('Gaussian noise with vertical colorbar', fontsize=16)\nplt.tick_params(labelsize=16)\n\n# Add colorbar, make sure to specify tick locations to match desired ticklabels\ncbar = fig.colorbar(cax, ticks=[-1, 0, 1])\ncbar.ax.set_yticklabels(['< -1', '0', '> 1'])  # vertically oriented colorbar\ncbar.ax.tick_params(labelsize=16)",
      "tags": "",
      "url": "https://bashtage.github.io/kevinsheppard.com/notebook-specimen/"
    },
    {
      "title": "Lesson 1",
      "text": "Installing\u00b6Install Anaconda\u00b6\nDownload the Anaconda Python/R Distirbution 2019.07 (or later).\nWhen the download is complete, install into your user account. \n\n\n\n\n\n\n\n\nInstall Pycharm Professional\u00b6\nDownload PyCharm Professional and install using the 30-day trial. You can get a free \ncopy using your academic email address if you want to continue after the first 30 days.\nOpen PyCharm, and create a new project called mfe-introduction\nOpen File > Setting and select Python Interpreter. Select the Anaconda interpreter if it\nis not already selected.\nCreate a new python file called first.py and enter\nprint(\"Python has a steeper curve than MATLAB but more long-run upside\")\n\n\nRight click on this file, and select \"Run\".\n\n\n\n\n\n\n\n\nInstall Visual Studio Code and the Python extension\u00b6\nDownload VS Code and install\nInstall the Python extension by clicking on Extensions and searching for \"Python\"\nOpen the mfe-introduction folder created in the previous step\nCreate a file called second.py and enter\n#%%\n\nprint(\"Python may be harder to learn than other languages since\")\nprint(\"there is rarely a single approach to completing a task.\")\n\n\nClick on Run Cell\n\nNote the #%% makes it a magic cell",
      "tags": "",
      "url": "https://bashtage.github.io/kevinsheppard.com/teaching/python/course/lesson-1/"
    },
    {
      "title": "Lesson 2",
      "text": "Getting Started\u00b6This lesson covers:\n\nOpening a terminal window\nLaunching Jupyter notebook\nRunning IPython in a Terminal\nRunning IPython in Jupyter QtConsole\nExecuting a standalone Python file in IPython\nOptional\nJupyter notebooks in VSCode\nJupyter notebooks in PyCharm Professional\n\n\n\n\n\n\n\n\n\n\nOpening a Terminal\u00b6Windows\u00b6Note: I strong recommend that you install \nWindows Terminal (Preview) from the Microsoft Store. You\nshould run these commands in the cmd tab.\nOn Windows, you should launch Windows Terminal (Preview). Alternatively you could run cmd.exe.\nOSX\u00b6Launch Terminal.app from spotlight.\nLinux\u00b6Open the terminal (instructions depend on your distribution).\n\n\n\n\n\n\n\nLaunching Jupyter notebook\u00b6\nOpen a terminal\nChange directory to the location where you store your notebooks.  It can also be any directory above the directory, but\ncannot be below. For example, if you store your work in /home/username/mfe/financial-econometrics/notebooks, than you could \nlaunch it in /home/username or /home/username/mfe/financial-econometrics, and then navigate to the notebooks directory.\nRun the command jupyter notebook. You should see a browser open and a window like the one below. I recommend using \nGoogle Chrome, although any modern browser should work fine.\n\nNote: To close the notebook application, press CTRL+C (or CMD+C) in the terminal window.\n\n\n\n\n\n\n\n\nRunning IPython in a Terminal\u00b6\nOpen a terminal.\nRun IPython by entering ipython in the terminal window. You should see a \nwindow like the one below with the iconic In [1] indicating that you are at \nthe start of a new IPython session.\n\n\n\n\n\n\n\n\n\nLaunching IPython in Jupyter QtConsole\u00b6Anaconda includes a QtConsole application which provides a rich interface to IPython that can display images inline. While I like\nthe experience that QtConsole provides to IPython, this method is optional and is only ideal for short sessions since it is less easy\nto save your work as you go.\nTo open QtConsole, launch Jupyter QtConsole from the Start menu, Spotlight, or your operating system's launcher. You should see\na window like the one below.\n\n\n\n\n\n\n\n\nExecuting a standalone Python file in IPython\u00b6\nOpen a text editor and enter the following lines. Save the file as lesson-2.py. \nNote that Python is white-space sensitive, and so these lines should not not indented.\n\nfrom math import exp, log\n\nx = exp(1)\ny = log(x)\n\nprint(f'exp(1)={x}, log(exp(1))={y}')\n\n\nRun the code in an IPython session using %run -i lesson-2.py.  Note: you should create the python file in the same directory as the notebook. \n\nIf everything works as expected, you should see\nexp(1)=2.718281828459045, log(exp(1))=1.0\n\n\n\n\n\n\n\n\nJupyter notebooks in PyCharm Professional\u00b6\nPyCharm Professions is my recommended approach if you are going to use Python throughout the course.\nIt provides the best experience and can be acquired for free using the student program.\nPyCharm Professions has deeply integrated Jupyter Notebooks. To create an IPython\nnotebook:\n\nOpen PyCharm Profession\nOpen the directory where your notebooks are stored\nRight click on the root directory and select New > Jupyter Notebook. Give your file a\nmeaningful name, and it will open in the main window.\n\n\nPyCharm uses a special syntax where cells look like code and so can be edited like text. This \nallows PyCharm to use introspection and code completion on wht code you have written, a highly\nuseful set of features. PyCharm stores the notebook in a Jupyter notebook file (.ipynb), which means that you \ncan trivially open it in any other Jupyter notebook aware app.  This differs from VS code\nwhich stores the file as a play Python file (.py) and requires an explicit export to \na Jupyter notebook file.\nA code cell is demarcated using #%% and a markdown cell begins with #%% md.  Below is a screenshot\nof this notebook in PyCharm.\n\nMagic Python in PyCharm\u00b6PyCharm supports Magic Python cell execution. To use Magic Python, you need to enable\nScientific Mode in the View menu. You can then use #%% to indicate the start and end of cells.\nIndividual Cells can be executed in the console by pressing CTRL+Enter.\n\nIn PyCharm, right click on the root directory and select New > Python File. Give you file a \nmeaning ful name.\nEnter\n#%%\nprint('This is the first cell')\n\n#%%\nprint('This is not executed when the first cell is run')\n\n\nEnable Scientific Mode in the View menu.\nRun the first cell by placing you mouse in the cell and pressing CTRL+Enter.\nRun the second cell by clicking on the Play button (arrow) that appears in the gutter of the editor.\n\n\nNote: Magic Python in PyCharm only supports python code, and so it is not possible to mix\nMarkdown text and Python in the same file.\n\n\n\n\n\n\n\nJupyter notebooks in VSCode\u00b6Visual Studio Code (or VS Code) is a lightweight IDE that \nsupports adding features through extensions.  The key extension for working with notebooks\nis Python extension for Visual Studio Code.\nWith this extension installed, it is possible to use a special file format called Magic Python\nto write notebook-like files that can be exported to Jupyter notebook files.\n\nInstall VS Code and the Python extension\nOpen the command palette and enter \"Jupyter start\" and select the only available item.\nThis is a Python file that support a cell demarcation using #%% for code cells and #%% [markdown] \nfor cells that contain markdown code.  Note that markdown text must be either:\n\nSurrounded by triple quotes, e.g. \"\"\"markdown text\"\"\" or '''markdown text'''; e.g.,\n\"\"\"\n# Cell Heading\n\nLikeness darkness. That give brought creeping. Doesn't may. Fruit kind \nmidst seed. Creature, let under created void god to. Them day was Was\ncreature set it from. Fourth. Created don't man. Man. Light fourth\nlight given the he image first multiply after deep she'd great. Morning \nlikeness very have give also fowl third land beast from moving thing\ncreepeth herb creeping won't fifth. Us bring was our beast wherein our\nvoid and green he fruit kind upon a given, saying fruit, moveth face \nforth. His you it. Good beginning hath.\n\"\"\"\n\n\nOr commented # (with a single space) at the start of each line,\n# # Cell Heading\n#\n# Likeness darkness. That give brought creeping. Doesn't may. Fruit kind \n# midst seed. Creature, let under created void god to. Them day was Was\n# creature set it from. Fourth. Created don't man. Man. Light fourth\n# light given the he image first multiply after deep she'd great. Morning \n# likeness very have give also fowl third land beast from moving thing\n# creepeth herb creeping won't fifth. Us bring was our beast wherein our\n# void and green he fruit kind upon a given, saying fruit, moveth face \n# forth. His you it. Good beginning hath.\n\n\n\n\n\nThe cells have a special button above them that allows the contents to be\nexecuted and the result to be displayed in the interactive window. See the screenshot \nbelow for an example of the experience of using VS Code. There is also an interactive \nconsole at the bottom left where commands can be directly executed.\n\n\n\n\n\n\n\n\nImporting an exiting notebook in VS Code\u00b6VS Code only understands Magic Python files as notebook-like documents, and so\n.ipynb files must be converted to use. The process of importing is simple:\n\nOpen a Jupyter notebook file\nClick on Import in the popup that appears.\n\n\n\n\n\n\n\n\n\nExporting to an Jupyter notebook\u00b6To export a Magic Python file, open the command palette and enter \"import jupyter\". Select the option to import\nthe notebook.",
      "tags": "",
      "url": "https://bashtage.github.io/kevinsheppard.com/teaching/python/course/lesson-2/"
    },
    {
      "title": "Lesson 3",
      "text": "Basic Input and Operators\u00b6This lesson covers:\n\nManually inputting data in scalars, vectors and matrices \nBasic mathematical operations \nSaving and loading data \n\n\nData\u00b6September 2018 prices (adjusted closing prices) for the S&P 500 EFT (SPY), Apple (AAPL) and \nGoogle (GOOG) are listed below:\n\n\nDate\nSPY Price\nAAPL Price\nGOOG Price\n\n\n\n\nSept4\n289.81\n228.36\n1197.00\n\n\nSept5\n289.03\n226.87\n1186.48\n\n\nSept6\n288.16\n223.10\n1171.44\n\n\nSept7\n287.60\n221.30\n1164.83\n\n\nSept10\n288.10\n218.33\n1164.64\n\n\nSept11\n289.05\n223.85\n1177.36\n\n\nSept12\n289.12\n221.07\n1162.82\n\n\nSept13\n290.83\n226.41\n1175.33\n\n\nSept14\n290.88\n223.84\n1172.53\n\n\nSept17\n289.34\n217.88\n1156.05\n\n\nSept18\n290.91\n218.24\n1161.22\n\n\nSept19\n291.44\n216.64\n1158.78\n\n\n\nPrices in September 2018\n\n\n\n\n\n\n\nProblem: Input scalar data\u00b6Create 3 variables, one labeled spy, one labeled aapl and one labeled goog that contain the\nSeptember 4 price of the asset. For example, to enter the Google data\ngoog = 1197.00\n\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Print the values\u00b6Print the values of the 3 variables you created in the previous step using print.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Print the values with formatting\u00b6Print the values of the 3 variables you created in the previous step using format strings following\nthe pattern TICKER: Value. For example, you can print the value of Google using print(f'GOOG: {goog}').\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Input a Vector\u00b6Create vectors for each of the days in the Table named sep_xx where xx is the \nnumeric date. For example,\nimport pandas as pd\n\nsep_04 = pd.Series([289.81,228.36,1197.00], index=['SPY','AAPL','GOOG']);\n\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Create a Vector of Dates\u00b6Use the pandas function pd.to_datetime to convert a list of string dates to a pandas \nDateTimeIndex, which can be used to set dates in other arrays. For example, the first two dates \nare\ndates_2 = pd.to_datetime(['4-9-2018','5-9-2018'])\nprint(dates_2)\n\nwhich produces\nDatetimeIndex(['2018-04-09', '2018-05-09'], dtype='datetime64[ns]', freq=None)\n\nCreate a vector containing all of the dates in the table.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Input a Vector with Dates\u00b6Create vectors for each of the ticker symbols in Table named spy, aapl and \ngoog, respectively. Use the variable dates that you created in the previous step.\nFor example\ngoog = pd.Series([1197.00,1186.48,1171.44,...], index=dates)\n\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Create a DataFrame\u00b6Create a DataFrame named prices containing Table. Set the column names equal to \nthe ticker and set the index to the dates you created previously.\nprices = pd.DataFrame([[289.81, 228.36, 1197.00], [289.03, 226.87, 1186.48]],\n                      columns = ['SPY', 'AAPL', 'GOOG'],index=dates_2)\n\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Construct a DataFrame from Series\u00b6DataCreate a second DataFrame named prices_row from the row vectors previously entered such that \nthe results are identical to prices. For example, the first two days worth of data are\npricess_row = pd.DataFrame([Sep04, Sep05])\n# Set the index after using concat to join\npricess_row.index = dates_2\n\nCreate a third DataFrame named prices_col from the 3 column vectors entered such that the results \nare identical to prices\nprices_col = pd.DataFrame([SPY,APPL,GOOG]).T\n\nNote: The .T above is transposes the 2-d array since DataFrame builds the array by rows.\nVerify that all three matrices are identical by printing the difference, e.g.,\nprint(pricescol - prices)\n\nand that all elements are 0.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Saving Data\u00b6Save the prices DataFrame to a pickle using prices.to_pickle('prices.pkl').\nDelete the prices variable using del prices, and then load it back using \nprices = pd.load_pickle('prices.pkl'). Finally print the loaded data to verify it is the same.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Addition and Subtraction\u00b6Add the prices of the three series together using .sum(axis=1). Add the prices in sep_04 to \nthe prices of goog. What happens?\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Multiplication\u00b6Multiply the price of Google by 2.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Constructing portfolio returns\u00b6Set up a vector or portfolio weights $w=\\left(\\frac{1}{3},\\,\\frac{1}{3}\\,,\\frac{1}{3}\\right)$ and \ncompute the price of a portfolio with $\\frac{1}{3}$ share of each.\nNote: Division uses the slash operator (/).\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Compute Returns\u00b6Compute returns using\nreturns = prices.pct_change()\n\nwhich computes the percentage change.\nAdditionally, extract returns for each name using\nspy_returns = returns['SPY']\n\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Compute Log Returns\u00b6import numpy as np\n\nlog_returns = np.log(prices).diff()\n\nfirst difference of the natural log of the prices. Mathematically this is \n$r_{t}=\\ln\\left(P_{t}\\right)-\\ln\\left(P_{t-1}\\right)=\\ln\\left(\\frac{P_{t}}{P_{t-1}}\\right)\\approx\\frac{P_{t}}{P_{t-1}}-1$.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Mean, Standard Deviation and Correlation\u00b6Using the function mean, compute the mean of the three returns series one at a time. For example\ngoog_mean = goog_returns.mean()\n\nNext, compute the mean of the matrix of returns using\nretmean = returns.mean()\n\nWhat is the relationship between these two? Repeat this exercise for the standard deviation (std()).\nFinally, compute the correlation of the matrix of returns (corr()).\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Summing all elements\u00b6Compute the sum of the columns of returns using .sum(). How is this related to the mean computed \nin the previous step?\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Maximum and Minimum Values\u00b6Compute the minimum and maximum values of the columns of returns using the min() and max() commands.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Rounding Up, Down and to the Closest Integer\u00b6Rounding up is handled by ceil, rounding down is handled by floor and rounding to the closest \ninteger is handled by round. Try all of these commands on 100 times returns. For example,\nrounded = (100*returns).round()\n\nUse ceil and floor to always round up and down, respectively.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Element-by-Element Multiplication\u00b6Mathematical commands in Python are element-by-element, except the @ operator which is matrix \nmultiplication and uses the rules of linear algebra.\nMultiply the returns of Google and SPY together using the dot operator.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Save Everything\u00b6Save everything created using dill\nimport dill\n\ndill.dump_session('lesson-3.dill')\n\nYou can load everything using dill.load_session('lesson-3.dill') later if you want to get \nthe data back.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:",
      "tags": "",
      "url": "https://bashtage.github.io/kevinsheppard.com/teaching/python/course/lesson-3/"
    },
    {
      "title": "Lesson 4",
      "text": "Functions\u00b6This lesson covers:\n\nCalling function with more than one input and output \nCalling functions when some inputs are not used \nWriting a custom function \n\n\n\n\n\n\n\n\nBegin by data in momentum.csv and creating some variable. This cell uses some magic to automate \nrepeated typing.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n# Setup: Load the momentum data\nimport pandas as pd\n\nmomentum = pd.read_csv('data/momentum.csv')\n\nprint(momentum.head())\n\nmom_01 = momentum['mom_01']\nmom_10 = momentum['mom_10']\n\n\n    \n\n\n\n\n\n\n\nThis data set contains 2 years of data on the 10 momentum portfolios from 2016\u20132018. The variables\nare named mom_XX where XX ranges from 01 (work return over the past 12 months) to 10 (best return \nover the past 12 months).\n\n\n\n\n\n\n\nProblem: Calling Functions\u00b6Functions were used in the previous lesson. Get used to calling functions by computing the mean,\nstd, kurtosis, max, and min of the 10 momentum portfolios . Also, explore the help \navailable for calling functions ? operator. For example,\nmomentum.std?\n\nopens a help window that shows the inputs and output, while\nhelp(momentum.std)\n\nshows the help.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Calling Functions with 2 Outputs\u00b6Some useful functions return 2 or more outputs. One example is stats.ttest_ind \nperforms a t-test that the mean of two independent samples is equal. It returns the\ntest statistic as the first return and the p-value as the second.\nUse this function to test whether the means of mom_01 and mom_10 are different.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Calling Functions with 2 Inputs\u00b6Many functions take two or more inputs. Like outputs, the inputs are simply listed in order\nseparated by commas. Use np.linsapce to produce a series of 11 points evenly spaced between 0 \nand 1. The help for np.linspace is listed below (linspace?).\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Calling Functions using Keyword Arguments\u00b6Many function have optional arguments. You can see these in a docstring since\noptional arguments take the form variable=default. For example, see\nthe help for np.mean\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nwhich is\nnp.mean(a, axis=None, dtype=None, out=None, keepdims=<no value>)\n\nThis tells us that only a is required and the other 4 possible inputs can\nbe omitted if you are happy with the defaults.  However, if we want to change \njust one optional input, we can directly use the inputs name in the function call.\nFor example, a pandas DataFrame has a function std that computes the standard\ndeviation. By default, it divides by n-1.  The 1 can be set using ddof.\nCompute std using ddof=0 on the momentum data.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Writing a Custom Function\u00b6Custom functions will play an important role later in the course when estimating parameters.\nConstruct a custom function that takes two arguments, mu and sigma2 and computes the\nlikelihood function of a normal random variable\n$$f(x;\\mu,\\sigma{2})=\\frac{1}{\\sqrt{2\\pi\\sigma{2}}}\\exp\\left(-\\frac{(x-\\mu){2}}{2\\sigma{2}}\\right)$$Use def to start the function and compute the likelihood of: $$x=0,\\mu=0,\\sigma{2}=1.$$\nThe text in the triple quotes is the doc string which is optional.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nExercises\u00b6Exercise: Custom Function\u00b6Write a function named summary_stats that will take a single input, x, a DataFrame and return a \nDataFrame with 4 columns and as many rows as there were columns in the original data where the\ncolumns contain the mean, standard deviation, skewness and kurtosis of x.\n\n\n\n\n\n\n\nExercise: Custom Function\u00b6Change your previous function to return 4 outputs, each a pandas Series for the mean,\nstandard deviation, skewness and the kurtosis.\nReturning multiple outputs uses the syntax\nreturn w, x, y, z",
      "tags": "",
      "url": "https://bashtage.github.io/kevinsheppard.com/teaching/python/course/lesson-4/"
    },
    {
      "title": "Lesson 5",
      "text": "Accessing Elements\u00b6This lesson covers:\n\nAccessing specific elements in NumPy arrays\nAssessing specific elements in Pandas Series and DataFrames \n\nAccessing elements in an array or a DataFrame is a common task. To begin this lesson, clear the\nworkspace set up some vectors and a $5\\times5$ array. These vectors and matrix will make it easy\nto determine which elements are selected by a command.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nZero-based indexing\u00b6Python indexing is 0 based so that the first element has position 0, the second has position 1 and \nso on until the last element has position n-1 in an array that contains n elements in total.\nProblem: Picking an Element out of a Matrix\u00b6\nSelect the third element of all three, x, y and z. \nSelect the 11${\\text{th}}$ element of x.\nUsing double index notation, select the (0,2) and the (2,0) element of x.\n\nIssues to ponder\n\nWhich index is rows and which index is columns?\nDoes NumPy count across first then down or down first then across? \n\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Selecting Entire Rows\u00b6\nSelect the 2nd row of x using the colon (:) operator.\nSelect the 2nd element of z and y using the same syntax.\n\nIssues to ponder\n\nWhat happens to the output in each case? \n\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Selecting Entire Columns\u00b6Select the 2nd column of x using the colon (:) operator.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Selecting Specific Rows or Columns\u00b6\nSelect the 2nd and 3rd columns of x using the colon (:) operator.\nSelect the 2nd and 4th rows of x. \nCombine these be combined to select columns 2 and 3 and rows 2 and 4. \n\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Use ix_ to select arbitrary rows and columns\u00b6Use ix_ to select the 2nd and 4th rows and 1st and 3rd columns of x.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Numeric indexing Series and DataFrame\u00b6Repeat the previous questions on y_s and x_df using .iloc.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Selecting by Name in Series and DataFrames\u00b6Using x_name and y_name:\n\nSelect the (0,2) and the (2,0) element of x_name.\nSelect the 2nd row of x_name using .loc.\nSelect the 2nd columns of x_name using .loc.\nSelect the 2nd element of y_name using both [] and loc.\nSelect the 2nd and 4th rows and 1st and 3rd columns of x_name.\n\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Selecting Data by Date\u00b6Load the data in momentum.csv.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n# Setup: Load the momentum data\n\nimport pandas as pd\n\nmomentum = pd.read_csv('data/momentum.csv', index_col='date', parse_dates=True)\nmomentum.head()\n\n\n    \n\n\n\n\n\n\n\n\nSelect returns on a February 16, 2016.\nSelect return in March 2016.\nSelect returns between May 1, 2016 and June 15, 2016\n\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:",
      "tags": "",
      "url": "https://bashtage.github.io/kevinsheppard.com/teaching/python/course/lesson-5/"
    },
    {
      "title": "Lesson 6",
      "text": "Program Flow\u00b6This lesson covers:\n\nfor loops \nNested loops \n\n\n\n\n\n\n\n\nProblem: Basic For Loops\u00b6Construct a for loop to sum the numbers between 1 and N for any N. A for loop that does nothing can be written\nn = 10\nfor i in range(n):\n    pass\n\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Compute a compound return\u00b6The compound return on a bond that pays interest annually at rate r is given by \n$cr_{t}=\\prod_{i=1}{T}(1+r)=(1+r){T}$. Use a for loop compute the total return for \n\u00a3100 invested today for $1,2,\\ldots,10$ years. Store this variable in a 10 by 1 vector cr.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Simulate a random walk\u00b6(Pseudo) Normal random variables can be simulated using the command\nnp.random.standard_normal(shape) where shape is a tuple (or a scalar) containing the \ndimensions of the desired random numbers. Simulate 100 normals in a 100 by 1 vector and name \nthe result e. Initialize a vector p containing zeros using the function zeros. Add the \n1st element of e to the first element of p. Use a for loop to simulate a process \n$y_{i}=y_{i-1}+e_{i}$. When finished plot the results using\n%matplotlib inline\n\nimport matplotlib.pyplot as plt\nplt.plot(y)\n\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Nested Loops\u00b6Begin by loading momentum data used in an earlier lesson. Begin by adding 1 to the returns to\nproduce gross returns.A gross return is the total the value in the current period of \u00a31 invested \nin the previous period. A net return subtracts the original investment to produce the net gain \nor loss. Use two loops to loop both across time and across the 10 portfolios to compute the \ntotal compound return.\nFor example, if only interested in a single series,\nn = mom_01.shape[0]\ncr=np.zeros(n) \ngr = 1 + mom_01 \ncr[0] = 1+mom_01[0] \nfor t in range(1, n):\n    cr[t]=cr[t-1]*gr[t]\n\ncomputes the cumulative return.\nWhen finished, plot the cumulative returns using plt.plot(cr). After finishing this problem,\nhave a look at np.cumsum? and np.cumprod?.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n# Setup: Load the momentum data\n\nimport pandas as pd\nmomentum = pd.read_csv('data/momentum.csv', index_col='date', parse_dates=True)\nmomentum = momentum / 100  # Convert to numeric values from percentages\n# Convert to a plain numpy array\nmomentum = momentum.to_numpy()\n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nExercises\u00b6Exercise\u00b6\nSimulate a 1000 by 10 matrix consisting of 10 standard random walks using both nested loops\nand np.cumsum. \nPlot the results. \n\nQuestion to think about\nIf you rerun the code in this Exercise, do the results change? Why?",
      "tags": "",
      "url": "https://bashtage.github.io/kevinsheppard.com/teaching/python/course/lesson-6/"
    },
    {
      "title": "Lesson 7",
      "text": "Logical Operators\u00b6This lesson covers:\n\nBasic logical operators \nCompound operators \nMixing logic and loops \nall and any \n\nBegin by loading the data in momentum.csv.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n# Setup: Load the momentum data\n\nimport pandas as pd\n\nmomentum = pd.read_csv('data/momentum.csv')\n\nprint(momentum.head())\n\nmom_01 = momentum['mom_01']\nmom_10 = momentum['mom_10']\nmom_05 = momentum['mom_05']\n\n\n    \n\n\n\n\n\n\n\nProblem: Basic Logical Statements\u00b6For portfolio 1 and portfolio 10, count the number of elements that are $<0$, $\\geq0$ and exactly\nequal to 0. Next count the number of times that the returns in portfolio 5 are greater, \nin absolute value, that 2 times the standard deviation of the returns in that portfolio.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Compound Statements\u00b6Count the number of times that the returns in both portfolio 1 and portfolio 10 are negative. \nNext count the number of times that the returns in portfolios 1 and 10 are both greater, in \nabsolute value, that 2 times their respective standard deviations.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Logical Statements and for Loops\u00b6Use a for loop along with an if statement to simulate an asymmetric random walk of the form\n$$y_{i}=y_{i-1}+e_{i}+I_{[e_{i}<0]}e_{i}$$where $I_{[e_{i}<0]}$ is known as an indicator variable that takes the value 1 if the statement in \nbrackets is true. Plot y.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Selecting Elements using Logical Statements\u00b6For portfolio 1 and portfolio 10, select the elements that are $<0$, $\\geq 0$ and exactly equal to \n$0$. Next select the elements where both portfolios are less than $0$.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Using where\u00b6Use find to select the index of the elements in portfolio 5 that are negative. Next, use the find \ncommand in its two output form to determine which elements of the portfolio return matrix are less \nthan -2%.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Combining flow control\u00b6For momentum portfolios 1 and 10, compute the length of the runs in the series. In pseudo code,\n\nStart at i=1 and define run(1) = 1\nFor i in 2,...,T, define run(i) = run(i-1) + 1 if $\\textrm{sgn}\\left(r_{i}\\right)=\\textrm{sgn}\\left(r_{i-1}\\right)$ else 1.\n\nYou will need to use length and zeros.\n\nCompute the length longest run in the series and the index of the location of the longest run. \nWas it positive or negative?\nHow many distinct runs lasted 5 or more days?\n\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nExercises\u00b6Exercise: all and any\u00b6Use all to determine the number of days where all of the portfolio returns were negative. Use any \nto compute the number of days with at least 1 negative return and with no negative returns (Hint: \nuse negation (~ or logical_not)).",
      "tags": "",
      "url": "https://bashtage.github.io/kevinsheppard.com/teaching/python/course/lesson-7/"
    },
    {
      "title": "Lesson 8",
      "text": "Importing Data\u00b6This lesson covers:\n\nImporting data \nConverting dates \nSaving data\n\n\n\n\n\n\n\n\nProblem: Reading in data with Dates\u00b6Read in the files GS10.csv and GS10.xlsx which have both been downloaded from\nFRED.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Converting Dates\u00b6\nLoad the csv file without converting the dates in read_csv.\nConvert the date column, remove it from the DataFrame, and set it as the index. \n\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Export to Excel, CSV, HDF and Pickle.\u00b6\nExport both gs10_excel and gs10_csv to the same Excel file\nExport gs10_excel to CSV. \nExport both to a HDF file (the closest thing to a \"native\" format in pandas)\nExport gs10_excel to a pickle file.\nCombine gs10_excel and gs10_csv into a dictionary and pickle the dictionary.\n\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Import from HDF and Pickle.\u00b6Import the data saved in steps 3-5 of the previous problem.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:",
      "tags": "",
      "url": "https://bashtage.github.io/kevinsheppard.com/teaching/python/course/lesson-8/"
    },
    {
      "title": "Lesson 9",
      "text": "Graphics\u00b6This lesson covers:\n\nBasic plotting \nSubplots \nHistograms \nScatter Plots\n\n\n\n\n\n\n\n\nPlotting in notebooks requires using a magic command, which starts with %, to initialize\nthe plotting backend.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n# Setup\n%matplotlib inline\n\n\n    \n\n\n\n\n\n\n\nBegin by loading the data in hf.hdf. This data set contains high-frequency price for IBM and MSFT\non a single day stored as two Series. IBM is stored as 'IBM' in the HDF file, and MSFT is stored\nas 'MSFT.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Basic Plotting\u00b6\nPlot the ibm series which contains the price of IBM. \nAdd a title and label the axes. \nAdd markers and remove the line. \n\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Subplot\u00b6Create a 2 by 1 subplot with the price of IBM in the top subplot and the price of MSFT in the\nbottom subplot.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Plot with Dates\u00b6Use matplotlib to directly plot ibm against its index. This is a repeat of a previous\nplot but shows how to directly use the plot command.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Histogram\u00b6Produce a histogram of MSFT 1-minute returns (Hint: you have to produce the 1-minute Microsoft\nreturns first using resample and pct_change).\n\n\n\n\n\n\nIn\u00a0[\u00a0]:\n\n    \n \n\n\n    \n\n\n\n\n\n\n\nProblem: Scatter Plot\u00b6Scatter the 5-minute MSFT returns against the 5-minute IBM returns.\nHint: You will need to create both 5 minute return series, merge them, and then plot using \nthe combined DataFrame.\n\n\n\n\n\n\nIn\u00a0[\u00a0]:",
      "tags": "",
      "url": "https://bashtage.github.io/kevinsheppard.com/teaching/python/course/lesson-9/"
    },
    {
      "title": "Example: Fama-MacBeth regression",
      "text": "Estimating the Risk Premia using Fama-MacBeth Regressions\u00b6\n\n\n\n\n\n\nThis example highlights how to implement a Fama-MacBeth 2-stage regression to estimate factor risk premia, make inference on the risk premia, and test whether a linear factor model can explain a cross-section of portfolio returns. This example closely follows [Cochrane::2001] (See also [JagannathanSkoulakisWang::2010]). As in the previous example, the first segment contains the imports.\n\n\n\n\n\n\nIn\u00a0[1]:\n\n    \nfrom numpy import mat, cov, mean, hstack, multiply,sqrt,diag, \\\n    squeeze, ones, array, vstack, kron, zeros, eye, savez_compressed\nfrom numpy.linalg import inv\nfrom scipy.stats import chi2\nfrom pandas import read_csv\nimport statsmodels.api as sm\n\n\n    \n\n\n\n\n\n\n\nNext, the data are imported. I formatted the data downloaded from Ken French's website into an easy-to-import CSV which can be read by pandas.read_csv. The data is split using named columns for the small sets of variables and ix for the portfolios. The code uses pure NumPy arrays, and so values is used to retrieve the array from the DataFrame. The dimensions are determined using shape. Finally the risk free rate is forced to have 2 dimensions so that it will be broadcastable with the portfolio returns in the construction of the excess returns to the Size and Value-weighted portfolios. asmatrix is used to return matrix views of all of the arrays. This code is linear algebra-heavy and so matrices are easier to use than arrays.\n\n\n\n\n\n\nIn\u00a0[2]:\n\n    \ndata = read_csv('FamaFrench.csv')\n\n# Split using both named colums and ix for larger blocks\ndates = data['date'].values\nfactors = data[['VWMe', 'SMB', 'HML']].values\nriskfree = data['RF'].values\nportfolios = data.iloc[:, 5:].values\n\n# Use mat for easier linear algebra\nfactors = mat(factors)\nriskfree = mat(riskfree)\nportfolios = mat(portfolios)\n\n# Shape information\nT,K = factors.shape\nT,N = portfolios.shape\n# Reshape rf and compute excess returns\nriskfree.shape = T,1\nexcessReturns = portfolios - riskfree\n\n\n    \n\n\n\n\n\n\n\nThe next block does 2 things:\n\nCompute the time-series $\\beta$s. This is done be regressing the full array of excess returns on the factors (augmented with a constant) using lstsq.\nCompute the risk premia using a cross-sectional regression of average excess returns on the estimates $\\beta$s. This is a standard regression where the step 1 $\\beta$ estimates are used as regressors, and the dependent variable is the average excess return.\n\n\n\n\n\n\n\nIn\u00a0[3]:\n\n    \n# Time series regressions\nX = sm.add_constant(factors)\nts_res = sm.OLS(excessReturns, X).fit()\nalpha = ts_res.params[0]\nbeta = ts_res.params[1:]\navgExcessReturns = mean(excessReturns, 0)\n# Cross-section regression\ncs_res = sm.OLS(avgExcessReturns.T, beta.T).fit()\nriskPremia = cs_res.params\n\n\n    \n\n\n\n\n\n\n\nThe asymptotic variance requires computing the covariance of the demeaned returns and the weighted pricing errors. The problem is formulated using 2-step GMM where the moment conditions are \n\\begin{equation}\ng_{t}\\left(\\theta\\right)=\\left[\\begin{array}{c}\n\\epsilon_{1t}\\\\\n\\epsilon_{1t}f_{t}\\\\\n\\epsilon_{2t}\\\\\n\\epsilon_{2t}f_{t}\\\\\n\\vdots\\\\\n\\epsilon_{Nt}\\\\\n\\epsilon_{Nt}f_{t}\\\\\n\\beta u_{t}\n\\end{array}\\right]\n\\end{equation}\nwhere $\\epsilon_{it}=r_{it}{e}-\\alpha_{i}-\\beta_{i}{\\prime}f_{t}$, $\\beta_{i}$ is a $K$ by 1 vector of factor loadings, $f_{t}$ is a $K$ by 1 set of factors, $\\beta=\\left[\\beta_{1}\\,\\beta_{2}\\ldots\\beta_{N}\\right]$ is a $K$ by $N$ matrix of all factor loadings, $u_{t}=r_{t}{e}-\\beta'\\lambda$ are the $N$ by 1 vector of pricing errors and $\\lambda$ is a $K$  by 1 vector of risk premia. \nThe vector of parameters is then $\\theta= \\left[\\alpha_{1}\\:\\beta_{1}{\\prime}\\:\\alpha_{2}\\:\\beta_{2}{\\prime}\\:\\ldots\\:\\alpha_{N}\\,\\beta_{N}{\\prime}\\:\\lambda'\\right]'$\n To make inference on this problem, the derivative of the moments with respect to the parameters, $\\partial g_{t}\\left(\\theta\\right)/\\partial\\theta{\\prime}$ is needed. With some work, the estimator of this matrix can be seen to be\n\\begin{equation}\n G=E\\left[\\frac{\\partial g_{t}\\left(\\theta\\right)}{\\partial\\theta{\\prime}}\\right]=\\left[\\begin{array}{cc}\n-I_{n}\\otimes\\Sigma_{X} & 0\\\\\nG_{21} & -\\beta\\beta{\\prime}\n\\end{array}\\right].\n\\end{equation}where $X_{t}=\\left[1\\: f_{t}{\\prime}\\right]'$  and $\\Sigma_{X}=E\\left[X_{t}X_{t}{\\prime}\\right]$. $G_{21}$ is a matrix with the structure\n\\begin{equation}\nG_{21}=\\left[G_{21,1}\\, G_{21,2}\\,\\ldots G_{21,N}\\right]\n\\end{equation}where\n\\begin{equation}\nG_{21,i}=\\left[\\begin{array}{cc} \n0_{K,1} & \\textrm{diag}\\left(E\\left[u_{i}\\right]-\\beta_{i}\\odot\\lambda\\right)\\end{array}\\right]\\end{equation}and where $E\\left[u_{i}\\right]$ is the expected pricing error. In estimation, all expectations are replaced with their sample analogues.\n\n\n\n\n\n\nIn\u00a0[4]:\n\n    \n# Moment conditions\nX = sm.add_constant(factors)\np = vstack((alpha, beta))\nepsilon = excessReturns - X @ p\nmoments1 = kron(epsilon, ones((1, K + 1)))\nmoments1 = multiply(moments1, kron(ones((1, N)), X))\nu = excessReturns - riskPremia[None,:] @ beta\nmoments2 = u * beta.T\n# Score covariance\nS = mat(cov(hstack((moments1, moments2)).T))\n# Jacobian\nG = mat(zeros((N * K + N + K, N * K + N + K)))\nSigmaX = (X.T @ X) / T\nG[:N * K + N, :N * K + N] = kron(eye(N), SigmaX)\nG[N * K + N:, N * K + N:] = -beta @ beta.T\nfor i in range(N):\n    temp = zeros((K, K + 1))\n    values = mean(u[:, i]) - multiply(beta[:, i], riskPremia)\n    temp[:, 1:] = diag(values)\n    G[N * K + N:, i * (K + 1):(i + 1) * (K + 1)] = temp\n\nvcv = inv(G.T) * S * inv(G) / T\n\n\n    \n\n\n\n\n\n\n\nThe $J$-test examines whether the average pricing errors, $\\hat{\\alpha}$, are zero. The $J$ statistic has an asymptotic $\\chi_{N}{2}$  distribution, and the model is badly rejected.\n\n\n\n\n\n\nIn\u00a0[5]:\n\n    \nvcvAlpha = vcv[0:N * K + N:4, 0:N * K + N:4]\nJ = alpha @ inv(vcvAlpha) @ alpha.T\nJ = J[0, 0]\nJpval = 1 - chi2(25).cdf(J)\n\n\n    \n\n\n\n\n\n\n\nThe final block using formatted output to present all of the results in a readable manner.\n\n\n\n\n\n\nIn\u00a0[6]:\n\n    \nvcvRiskPremia = vcv[N * K + N:, N * K + N:]\nannualizedRP = 12 * riskPremia\narp = list(squeeze(annualizedRP))\narpSE = list(sqrt(12 * diag(vcvRiskPremia)))\nprint('        Annualized Risk Premia')\nprint('           Market       SMB        HML')\nprint('--------------------------------------')\nprint('Premia     {0:0.4f}    {1:0.4f}     {2:0.4f}'.format(arp[0], arp[1], arp[2]))\nprint('Std. Err.  {0:0.4f}    {1:0.4f}     {2:0.4f}'.format(arpSE[0], arpSE[1], arpSE[2]))\nprint('\\n\\n')\n\nprint('J-test:   {:0.4f}'.format(J))\nprint('P-value:   {:0.4f}'.format(Jpval))\n\ni = 0\nbetaSE = []\nfor j in range(5):\n    for k in range(5):\n        a = alpha[i]\n        b = beta[:, i]\n        variances = diag(vcv[(K + 1) * i:(K + 1) * (i + 1), (K + 1) * i:(K + 1) * (i + 1)])\n        betaSE.append(sqrt(variances))\n        s = sqrt(variances)\n        c = hstack((a, b))\n        t = c / s\n        print('Size: {:}, Value:{:}   Alpha   Beta(VWM)   Beta(SMB)   Beta(HML)'.format(j + 1, k + 1))\n        print('Coefficients: {:>10,.4f}  {:>10,.4f}  {:>10,.4f}  {:>10,.4f}'.format(a, b[0], b[1], b[2]))\n        print('Std Err.      {:>10,.4f}  {:>10,.4f}  {:>10,.4f}  {:>10,.4f}'.format(s[0], s[1], s[2], s[3]))\n        print('T-stat        {:>10,.4f}  {:>10,.4f}  {:>10,.4f}  {:>10,.4f}'.format(t[0], t[1], t[2], t[3]))\n        print('')\n        i += 1\n\n\n    \n\n\n\n\n\n\n\n\n\n    \n\n\n\n        Annualized Risk Premia\n           Market       SMB        HML\n--------------------------------------\nPremia     6.6642    2.8731     2.8080\nStd. Err.  0.5994    0.4010     0.4296\n\n\n\nJ-test:   95.2879\nP-value:   0.0000\nSize: 1, Value:1   Alpha   Beta(VWM)   Beta(SMB)   Beta(HML)\nCoefficients:    -0.8354      1.3099      1.2892      0.3943\nStd Err.          0.1820      0.1269      0.1671      0.2748\nT-stat           -4.5904     10.3196      7.7127      1.4348\n\nSize: 1, Value:2   Alpha   Beta(VWM)   Beta(SMB)   Beta(HML)\nCoefficients:    -0.3911      1.0853      1.6100      0.3317\nStd Err.          0.1237      0.0637      0.1893      0.1444\nT-stat           -3.1616     17.0351      8.5061      2.2971\n\nSize: 1, Value:3   Alpha   Beta(VWM)   Beta(SMB)   Beta(HML)\nCoefficients:    -0.1219      1.0747      1.1812      0.4648\nStd Err.          0.0997      0.0419      0.0938      0.0723\nT-stat           -1.2225     25.6206     12.5952      6.4310\n\nSize: 1, Value:4   Alpha   Beta(VWM)   Beta(SMB)   Beta(HML)\nCoefficients:     0.0388      0.9630      1.2249      0.5854\nStd Err.          0.0692      0.0232      0.1003      0.0353\nT-stat            0.5614     41.5592     12.2108     16.5705\n\nSize: 1, Value:5   Alpha   Beta(VWM)   Beta(SMB)   Beta(HML)\nCoefficients:     0.0918      0.9850      1.3453      0.9052\nStd Err.          0.0676      0.0255      0.0818      0.0610\nT-stat            1.3580     38.5669     16.4489     14.8404\n\nSize: 2, Value:1   Alpha   Beta(VWM)   Beta(SMB)   Beta(HML)\nCoefficients:    -0.2397      1.0691      1.0520     -0.2647\nStd Err.          0.0725      0.0318      0.0609      0.0591\nT-stat           -3.3052     33.6540     17.2706     -4.4768\n\nSize: 2, Value:2   Alpha   Beta(VWM)   Beta(SMB)   Beta(HML)\nCoefficients:    -0.0194      1.0416      0.9880      0.1877\nStd Err.          0.0615      0.0170      0.0776      0.0350\nT-stat           -0.3162     61.1252     12.7393      5.3646\n\nSize: 2, Value:3   Alpha   Beta(VWM)   Beta(SMB)   Beta(HML)\nCoefficients:     0.0898      0.9590      0.8619      0.3553\nStd Err.          0.0517      0.0170      0.0733      0.0320\nT-stat            1.7359     56.4856     11.7528     11.0968\n\nSize: 2, Value:4   Alpha   Beta(VWM)   Beta(SMB)   Beta(HML)\nCoefficients:     0.0482      0.9788      0.8178      0.5562\nStd Err.          0.0495      0.0138      0.0454      0.0281\nT-stat            0.9733     70.7006     18.0210     19.8055\n\nSize: 2, Value:5   Alpha   Beta(VWM)   Beta(SMB)   Beta(HML)\nCoefficients:    -0.0109      1.0502      0.9373      0.8493\nStd Err.          0.0596      0.0182      0.0281      0.0263\nT-stat           -0.1830     57.7092     33.3971     32.2980\n\nSize: 3, Value:1   Alpha   Beta(VWM)   Beta(SMB)   Beta(HML)\nCoefficients:    -0.1556      1.1416      0.7883     -0.1980\nStd Err.          0.0591      0.0190      0.0445      0.0411\nT-stat           -2.6320     60.1173     17.6973     -4.8171\n\nSize: 3, Value:2   Alpha   Beta(VWM)   Beta(SMB)   Beta(HML)\nCoefficients:     0.0889      1.0133      0.5151      0.0720\nStd Err.          0.0553      0.0179      0.0340      0.0334\nT-stat            1.6068     56.6380     15.1651      2.1546\n\nSize: 3, Value:3   Alpha   Beta(VWM)   Beta(SMB)   Beta(HML)\nCoefficients:     0.1118      1.0129      0.4130      0.3379\nStd Err.          0.0578      0.0267      0.0324      0.0321\nT-stat            1.9344     37.9790     12.7488     10.5399\n\nSize: 3, Value:4   Alpha   Beta(VWM)   Beta(SMB)   Beta(HML)\nCoefficients:     0.0818      0.9615      0.4646      0.5068\nStd Err.          0.0568      0.0141      0.0475      0.0301\nT-stat            1.4399     68.3360      9.7754     16.8580\n\nSize: 3, Value:5   Alpha   Beta(VWM)   Beta(SMB)   Beta(HML)\nCoefficients:    -0.0526      1.1447      0.4970      0.9143\nStd Err.          0.0687      0.0197      0.0509      0.0390\nT-stat           -0.7655     58.0319      9.7690     23.4302\n\nSize: 4, Value:1   Alpha   Beta(VWM)   Beta(SMB)   Beta(HML)\nCoefficients:     0.0902      1.0661      0.2857     -0.3692\nStd Err.          0.0498      0.0151      0.0444      0.0323\nT-stat            1.8127     70.4710      6.4268    -11.4334\n\nSize: 4, Value:2   Alpha   Beta(VWM)   Beta(SMB)   Beta(HML)\nCoefficients:    -0.0104      1.0308      0.2430      0.1328\nStd Err.          0.0534      0.0217      0.0300      0.0294\nT-stat           -0.1952     47.5567      8.0926      4.5183\n\nSize: 4, Value:3   Alpha   Beta(VWM)   Beta(SMB)   Beta(HML)\nCoefficients:     0.0392      1.0096      0.2214      0.2980\nStd Err.          0.0572      0.0209      0.0436      0.0486\nT-stat            0.6862     48.3271      5.0836      6.1333\n\nSize: 4, Value:4   Alpha   Beta(VWM)   Beta(SMB)   Beta(HML)\nCoefficients:     0.0148      1.0437      0.2016      0.5857\nStd Err.          0.0593      0.0224      0.0343      0.0484\nT-stat            0.2497     46.5053      5.8694     12.0922\n\nSize: 4, Value:5   Alpha   Beta(VWM)   Beta(SMB)   Beta(HML)\nCoefficients:    -0.1762      1.2284      0.2974      0.9834\nStd Err.          0.0803      0.0224      0.0490      0.0378\nT-stat           -2.1927     54.8427      6.0726     26.0265\n\nSize: 5, Value:1   Alpha   Beta(VWM)   Beta(SMB)   Beta(HML)\nCoefficients:     0.0794      1.0310     -0.1507     -0.2508\nStd Err.          0.0372      0.0095      0.0247      0.0168\nT-stat            2.1369    108.0844     -6.1067    -14.9673\n\nSize: 5, Value:2   Alpha   Beta(VWM)   Beta(SMB)   Beta(HML)\nCoefficients:     0.0535      0.9576     -0.1893     -0.0107\nStd Err.          0.0457      0.0170      0.0243      0.0239\nT-stat            1.1690     56.3228     -7.7765     -0.4458\n\nSize: 5, Value:3   Alpha   Beta(VWM)   Beta(SMB)   Beta(HML)\nCoefficients:    -0.0236      0.9753     -0.2173      0.3127\nStd Err.          0.0559      0.0178      0.0309      0.0256\nT-stat           -0.4225     54.6936     -7.0217     12.2061\n\nSize: 5, Value:4   Alpha   Beta(VWM)   Beta(SMB)   Beta(HML)\nCoefficients:    -0.1978      1.0546     -0.1732      0.7115\nStd Err.          0.0587      0.0230      0.0300      0.0316\nT-stat           -3.3679     45.7933     -5.7749     22.5339\n\nSize: 5, Value:5   Alpha   Beta(VWM)   Beta(SMB)   Beta(HML)\nCoefficients:    -1.2737      1.1045      0.0076      0.8527\nStd Err.          0.3557      0.1143      0.1594      0.1490\nT-stat           -3.5805      9.6657      0.0477      5.7232\n\n\n\n\n\n\n\n\n\n\n\n\nThe final block converts the standard errors of $\\beta$ to be an array and saves the results.\n\n\n\n\n\n\nIn\u00a0[7]:\n\n    \nbetaSE = array(betaSE)\nsavez_compressed('fama-macbeth-results', alpha=alpha, beta=beta,\n                 betaSE=betaSE, arpSE=arpSE, arp=arp, J=J, Jpval=Jpval)\n\n\n    \n\n\n\n\n\n\n\nSave Results\u00b6Save the estimated values for use in the $\\LaTeX$ notebook.\n\n\n\n\n\n\nIn\u00a0[8]:\n\n    \nfrom numpy import savez\nsavez('fama-macBeth-results.npz', arp=arp, beta=beta, arpSE=arpSE,\n      betaSE=betaSE, J=J, Jpval=Jpval)",
      "tags": "",
      "url": "https://bashtage.github.io/kevinsheppard.com/teaching/python/notes/notebooks/example-fama-macbeth/"
    },
    {
      "title": "Example: GJR-GARCH Estimation",
      "text": "IPython Notebook Setup\u00b6This commands are used needed for plots to appear in the notebook.\n\n\n\n\n\n\nIn\u00a0[1]:\n\n    \n%matplotlib inline\n\n\n    \n\n\n\n\n\n\n\nEstimating the Parameters of a GJR-GARCH Model\u00b6This example will highlight the steps needed to estimate the parameters of a GJR-GARCH(1,1,1) model with a constant mean. The volatility dynamics in a GJR-GARCH model are given by \n$$\\sigma_{t}{2}=\\omega+\\sum_{i=1}{p}\\alpha_{i}\\epsilon_{t-i}{2}+\\sum_{j=1}{o}\\gamma_{j}r_{t-j}{2}I_{\\left[\\epsilon_{t-j}<0\\right]}+\\sum_{k=1}{q}\\beta_{k}\\sigma_{t-k}{2}.$$\nReturns are assumed to be conditionally normal, $r_{t}|\\mathcal{F}_{t-1}\\sim N\\left(\\mu,\\sigma_{t}{2}\\right)$, $\\epsilon_{t}=r_{t}-\\mu$ and parameters are estimated by maximum likelihood. To estimate the parameters, it is necessary to:\n\nProduce some starting values\nEstimate the parameters using (quasi-) maximum likelihood\nCompute standard errors using a \u201csandwich\u201d covariance estimator (also known as the [BollerslevWooldridge::1992] covariance estimator)\n\nThe first task is to write the log-likelihood which can be used in an optimizer. The log-likelihood function will compute the volatility recursion and the log-likelihood. It will also, optionally, return the $T$ by 1 vector of individual log-likelihoods which are useful when approximating the scores.\n\n\n\n\n\n\nIn\u00a0[2]:\n\n    \nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom numpy import size, log, pi, sum, array, zeros, diag, mat, asarray, sqrt, \\\n    copy\nfrom numpy.linalg import inv\nfrom scipy.optimize import fmin_slsqp\n\n\n    \n\n\n\n\n\n\n\nThe conditional log-likelihood of a normal random variable is\n$$\\ln f\\left(r_{t}|\\mu,\\sigma_{t}{2}\\right)=-\\frac{1}{2}\\left(\\ln2\\pi+\\ln\\sigma_{t}{2}+\\frac{\\left(r_{t}-\\mu\\right){2}}{\\sigma_{t}{2}}\\right),$$which is negated in the code since the optimizers all minimize.\n\n\n\n\n\n\nIn\u00a0[3]:\n\n    \ndef gjr_garch_likelihood(parameters, data, sigma2, out=None):\n    ''' Returns negative log-likelihood for GJR-GARCH(1,1,1) model.'''\n    mu = parameters[0]\n    omega = parameters[1]\n    alpha = parameters[2]\n    gamma = parameters[3]\n    beta = parameters[4]\n    \n    T = size(data,0)\n    eps = data - mu\n    # Data and sigma2 are T by 1 vectors\n    for t in range(1,T):\n        sigma2[t] = (omega + alpha * eps[t-1]**2 \n                     + gamma * eps[t-1]**2 * (eps[t-1]<0) + beta * sigma2[t-1])\n    \n    logliks = 0.5*(log(2*pi) + log(sigma2) + eps**2/sigma2)\n    loglik = sum(logliks)\n    \n    if out is None:\n        return loglik\n    else:\n        return loglik, logliks, copy(sigma2)\n\n\n    \n\n\n\n\n\n\n\nThe keyword argument out has a default value of None, and is used to determine whether to return 1 output or 3. This is common practice since the optimizer requires a single output -- the log-likelihood function value, but it is also useful to be able to output other useful quantities, such as $\\left\\{ \\sigma_{t}{2}\\right\\}$.\nThe optimization is constrained so that $\\alpha+\\gamma/2+\\beta\\leq 1$, and the constraint is provided in a separate function.\n\n\n\n\n\n\nIn\u00a0[4]:\n\n    \ndef gjr_constraint(parameters, data, sigma2, out=None):\n    ''' Constraint that alpha+gamma/2+beta<=1'''\n    \n    alpha = parameters[2]\n    gamma = parameters[3]\n    beta = parameters[4]\n\n    return array([1-alpha-gamma/2-beta])\n\n\n    \n\n\n\n\n\n\n\nNote that the constraint function takes the same inputs as the negative of the log-likelihood function, even though only parameters is required to compute the constraint.\nIt is necessary to discuss one other function before proceeding with the main block of code. The asymptotic variance is estimated using the \u201csandwich\u201d form which is commonly expressed as\n$$\\mathcal{J}{-1}\\mathcal{I}\\mathcal{J}{-1}$$where $\\mathcal{J}$ is the expected Hessian and $\\mathcal{I}$ is the covariance of the scores. Both are numerically approximated, and the strategy for computing the Hessian is to use the definition that\n$$\\mathcal{J}_{ij}\\approx\\frac{f\\left(\\theta+e_{i}h_{i}+e_{j}h_{j}\\right)-f\\left(\\theta+e_{i}h_{i}\\right)-f\\left(\\theta+e_{j}h_{j}\\right)+f\\left(\\theta\\right)}{h_{i}h_{j}}$$where $h_{i}$ is a scalar \u201cstep size\u201d and $e_{i}$ is a vector of 0s except for element $i$, which is 1. A 2-sided version of this approximation, which takes both forward and backward steps and then averages, is below. For more on numerical derivatives, see [FlanneryPressTeukolskyTeukolsky::1992].\n\n\n\n\n\n\nIn\u00a0[5]:\n\n    \ndef hessian_2sided(fun, theta, args):\n    f = fun(theta, *args)\n    h = 1e-5*np.abs(theta)\n    thetah = theta + h\n    h = thetah - theta\n    K = size(theta,0)\n    h = np.diag(h)\n    \n    fp = zeros(K)\n    fm = zeros(K)\n    for i in range(K):\n        fp[i] = fun(theta+h[i], *args)\n        fm[i] = fun(theta-h[i], *args)\n        \n    fpp = zeros((K,K))\n    fmm = zeros((K,K))\n    for i in range(K):\n        for j in range(i,K):\n            fpp[i,j] = fun(theta + h[i] + h[j],  *args)\n            fpp[j,i] = fpp[i,j]\n            fmm[i,j] = fun(theta - h[i] - h[j],  *args)\n            fmm[j,i] = fmm[i,j]\n            \n    hh = (diag(h))\n    hh = hh.reshape((K,1))\n    hh = hh @ hh.T\n    \n    H = zeros((K,K))\n    for i in range(K):\n        for j in range(i,K):\n            H[i,j] = (fpp[i,j] - fp[i] - fp[j] + f \n                       + f - fm[i] - fm[j] + fmm[i,j])/hh[i,j]/2\n            H[j,i] = H[i,j]\n    \n    return H\n\n\n    \n\n\n\n\n\n\n\nFinally, the code that does the actual work can be written. The first block imports the data, flips it using a slicing operator, and computes 100 times returns. Scaling data can be useful to improve optimizer performance, and ideally estimated parameters should have similar magnitudes (i.e. $\\omega\\approx.01$  and $\\alpha\\approx.05$).\n\n\n\n\n\n\nIn\u00a0[6]:\n\n    \n# Import data\nFTSE = pd.read_csv('FTSE_1984_2012.csv', parse_dates=[0])\n# Set index\nFTSE.index = FTSE.pop('Date')\n# Flip upside down\nFTSE = FTSE.iloc[::-1]\n# Compute returns\nFTSEprice = FTSE['Adj Close']\nFTSEreturn = 100 * FTSEprice.pct_change().dropna()\n\n\n    \n\n\n\n\n\n\n\nGood starting values are important. These are my guesses based on experience fitting these types of models models. An alternative is to attempt a crude grid search and use the best (smallest) log-likelihood value from the grid search.\n\n\n\n\n\n\nIn\u00a0[7]:\n\n    \n# Starting values\nstartingVals = array([FTSEreturn.mean(),\n                      FTSEreturn.var() * .01,\n                      .03, .09, .90])\n\n\n    \n\n\n\n\n\n\n\nBounds are used in estimation to ensure that all parameters in the conditional variance are $\\geq 0$  and to set sensible upper bounds on the mean and $\\omega$. The vector sigma2 is then initialized, and the arguments are placed in a tuple.\n\n\n\n\n\n\nIn\u00a0[8]:\n\n    \n# Estimate parameters\nfinfo = np.finfo(np.float64)\nbounds = [(-10*FTSEreturn.mean(), 10*FTSEreturn.mean()),\n          (finfo.eps, 2*FTSEreturn.var() ),\n          (0.0,1.0), (0.0,1.0), (0.0,1.0)]\n       \nT = FTSEreturn.shape[0]\nsigma2 = np.ones(T) * FTSEreturn.var()\n# Pass a NumPy array, not a pandas Series\nargs = (np.asarray(FTSEreturn), sigma2)\nestimates = fmin_slsqp(gjr_garch_likelihood, startingVals,\n                       f_ieqcons=gjr_constraint, bounds = bounds,\n                       args = args)\n\n\n    \n\n\n\n\n\n\n\n\n\n    \n\n\n\nOptimization terminated successfully.    (Exit mode 0)\n            Current function value: 9569.030507603133\n            Iterations: 12\n            Function evaluations: 101\n            Gradient evaluations: 12\n\n\n\n\n\n\n\n\n\n\n\nThe optimized log-likelihood and the time series of variances are computed by calling the objective using the keyword argument out=True.\n\n\n\n\n\n\nIn\u00a0[9]:\n\n    \nloglik, logliks, sigma2final = gjr_garch_likelihood(estimates, FTSEreturn,\n                                                    sigma2, out=True)\n\n\n    \n\n\n\n\n\n\n\nNext, the numerical scores and the covariance of the scores are computed. These exploit the definition of a derivative, so that for a scalar function,\n$$\\frac{\\partial f\\left(\\theta\\right)}{\\partial\\theta_{i}}\\approx\\frac{f\\left(\\theta+e_{i}h_{i}\\right)-f\\left(\\theta\\right)}{h_{i}}.$$The covariance is computed as the outer product of the scores since the scores should have mean 0 when evaluated at the solution to the optimization problem.\n\n\n\n\n\n\nIn\u00a0[10]:\n\n    \nstep = 1e-5 * estimates\nscores = zeros((T,5))\nfor i in range(5):\n    h = step[i]\n    delta = np.zeros(5)\n    delta[i] = h\n    \n    loglik, logliksplus, sigma2 = gjr_garch_likelihood(estimates + delta, \\\n                               np.asarray(FTSEreturn), sigma2, out=True)\n    loglik, logliksminus, sigma2 = gjr_garch_likelihood(estimates - delta, \\\n                              np.asarray(FTSEreturn), sigma2, out=True)                   \n               \n    scores[:,i] = (logliksplus - logliksminus)/(2*h)\n\nI = (scores.T @ scores)/T\n\n\n    \n\n\n\n\n\n\n\nThe next block calls hessian_2sided to estimate the Hessian, and then computes the asymptotic covariance.\n\n\n\n\n\n\nIn\u00a0[11]:\n\n    \nJ = hessian_2sided(gjr_garch_likelihood, estimates, args)\nJ = J/T\nJinv = mat(inv(J))\nvcv = Jinv*mat(I)*Jinv/T\nvcv = asarray(vcv)\n\n\n    \n\n\n\n\n\n\n\nThe penultimate step is to pretty print the results and to produce a plot of the conditional variances.\n\n\n\n\n\n\nIn\u00a0[12]:\n\n    \noutput = np.vstack((estimates,sqrt(diag(vcv)),estimates/sqrt(diag(vcv)))).T    \nprint('Parameter   Estimate       Std. Err.      T-stat')\nparam = ['mu','omega','alpha','gamma','beta']\nfor i in range(len(param)):\n    print('{0:<11} {1:>0.6f}        {2:0.6f}    {3: 0.5f}'.format(param[i],\n           output[i,0], output[i,1], output[i,2]))\n    \n\n\n    \n\n\n\n\n\n\n\n\n\n    \n\n\n\nParameter   Estimate       Std. Err.      T-stat\nmu          0.032146        0.010084     3.18795\nomega       0.017610        0.003330     5.28813\nalpha       0.030658        0.006730     4.55564\ngamma       0.091709        0.012944     7.08484\nbeta        0.906327        0.009784     92.62951\n\n\n\n\n\n\n\n\n\n\n\nThis final block produces a plot of the annualized conditional standard deviations.\n\n\n\n\n\n\nIn\u00a0[13]:\n\n    \n# Register date converters\nfrom pandas.plotting import register_matplotlib_converters\nregister_matplotlib_converters()\n\n# Produce a plot\ndates = FTSE.index[1:]\nfig = plt.figure()\nax = fig.add_subplot(111)\nvolatility = pd.DataFrame(np.sqrt(252 * sigma2), index=dates)\nax.plot(volatility.index,volatility)\nax.autoscale(tight='x')\nfig.autofmt_xdate()\nfig.tight_layout(pad=1.5)\nax.set_ylabel('Volatility')\nax.set_title('FTSE Volatility (GJR GARCH(1,1,1))')\nplt.show()",
      "tags": "",
      "url": "https://bashtage.github.io/kevinsheppard.com/teaching/python/notes/notebooks/example-gjr-garch/"
    },
    {
      "title": "Example: GMM Estimation",
      "text": "Risk Premia Estimation using GMM\u00b6\n\n\n\n\n\n\nStart by importing the modules and functions needed\n\n\n\n\n\n\nIn\u00a0[1]:\n\n    \nfrom numpy import hstack, ones, array, mat, tile, reshape, squeeze, eye, asmatrix\nfrom numpy.linalg import inv\nfrom pandas import read_csv, Series \nfrom scipy.linalg import kron\nfrom scipy.optimize import fmin_bfgs\nimport numpy as np\nimport statsmodels.api as sm\n\n\n    \n\n\n\n\n\n\n\nNext a callable function is used to produce iteration-by-iteration output when using the non-linear optimizer.\n\n\n\n\n\n\nIn\u00a0[2]:\n\n    \niteration = 0\nlastValue = 0\nfunctionCount = 0\n\ndef iter_print(params):\n    global iteration, lastValue, functionCount\n    iteration += 1\n    print('Func value: {0:}, Iteration: {1:}, Function Count: {2:}'.format(lastValue, iteration, functionCount))\n\n\n    \n\n\n\n\n\n\n\nThe GMM objective, which is minimized, is defined next.\n\n\n\n\n\n\nIn\u00a0[3]:\n\n    \ndef gmm_objective(params, pRets, fRets, Winv, out=False):\n    global lastValue, functionCount\n    T,N = pRets.shape\n    T,K = fRets.shape\n    beta = squeeze(array(params[:(N*K)]))\n    lam = squeeze(array(params[(N*K):]))\n    beta = reshape(beta,(N,K))\n    lam = reshape(lam,(K,1))\n    betalam = beta @ lam\n    expectedRet = fRets @ beta.T\n    e = pRets - expectedRet\n    instr = tile(fRets,N)\n    moments1  = kron(e,ones((1,K)))\n    moments1 = moments1 * instr\n    moments2 = pRets - betalam.T\n    moments = hstack((moments1,moments2))\n\n    avgMoment = moments.mean(axis=0)\n    \n    J = T * mat(avgMoment) * mat(Winv) * mat(avgMoment).T\n    J = J[0,0]\n    lastValue = J\n    functionCount += 1\n    if not out:\n        return J\n    else:\n        return J, moments\n\n\n    \n\n\n\n\n\n\n\nThe G matrix, which is the derivative of the GMM moments with respect to the parameters, is defined.\n\n\n\n\n\n\nIn\u00a0[4]:\n\n    \ndef gmm_G(params, pRets, fRets):\n    T,N = pRets.shape\n    T,K = fRets.shape\n    beta = squeeze(array(params[:(N*K)]))\n    lam = squeeze(array(params[(N*K):]))\n    beta = reshape(beta,(N,K))\n    lam = reshape(lam,(K,1))\n    G = np.zeros((N*K+K,N*K+N))\n    ffp = (fRets.T @ fRets) / T\n    G[:(N*K),:(N*K)]=kron(eye(N),ffp)\n    G[:(N*K),(N*K):] = kron(eye(N),-lam)\n    G[(N*K):,(N*K):] = -beta.T\n    \n    return G\n\n\n    \n\n\n\n\n\n\n\nNext, the data is imported and a subset of the test portfolios is selected to make the estimation faster.\n\n\n\n\n\n\nIn\u00a0[5]:\n\n    \ndata = read_csv('FamaFrench.csv')\n\n# Split using both named colums and ix for larger blocks\ndates = data['date'].values\nfactors = data[['VWMe','SMB','HML']].values\nriskfree = data['RF'].values\nportfolios = data.iloc[:,5:].values\n\nT,N = portfolios.shape\nportfolios = portfolios[:,np.arange(0,N,2)]\nT,N = portfolios.shape\nexcessRet = portfolios - np.reshape(riskfree,(T,1))\nK = np.size(factors,1)\n\n\n    \n\n\n\n\n\n\n\nStarting values for the factor loadings and rick premia are estimated using OLS and simple means.\n\n\n\n\n\n\nIn\u00a0[6]:\n\n    \nbetas = []\nfor i in range(N):\n    res = sm.OLS(excessRet[:,i],sm.add_constant(factors)).fit()\n    betas.append(res.params[1:])\n\navgReturn = excessRet.mean(axis=0)\navgReturn.shape = N,1\nbetas = array(betas)\nres = sm.OLS(avgReturn, betas).fit()\nriskPremia = res.params\n\n\n    \n\n\n\n\n\n\n\nThe starting values are computed the first step estimates are found using the non-linear optimizer.  The initial weighting matrix is just the identify matrix.\n\n\n\n\n\n\nIn\u00a0[7]:\n\n    \nriskPremia.shape = 3\nstartingVals = np.concatenate((betas.flatten(),riskPremia))\n\nWinv = np.eye(N*(K+1))\nargs = (excessRet, factors, Winv)\niteration = 0\nfunctionCount = 0\nstep1opt = fmin_bfgs(gmm_objective, startingVals, args=args, callback=iter_print)\n\n\n    \n\n\n\n\n\n\n\n\n\n    \n\n\n\nFunc value: 1915.975414620774, Iteration: 1, Function Count: 132\nFunc value: 1817.0224254364093, Iteration: 2, Function Count: 220\nFunc value: 1814.9526088153193, Iteration: 3, Function Count: 308\nFunc value: 1814.8636328788023, Iteration: 4, Function Count: 396\nFunc value: 1814.7320075212833, Iteration: 5, Function Count: 440\nFunc value: 1814.4944170296885, Iteration: 6, Function Count: 484\nFunc value: 1814.4840096314288, Iteration: 7, Function Count: 572\nFunc value: 1814.4835355894866, Iteration: 8, Function Count: 660\nFunc value: 1814.4834334886873, Iteration: 9, Function Count: 748\nFunc value: 1814.4832402214106, Iteration: 10, Function Count: 792\nFunc value: 1814.483239345376, Iteration: 11, Function Count: 880\nFunc value: 1814.4832044513546, Iteration: 12, Function Count: 1012\nFunc value: 1814.3989963962504, Iteration: 13, Function Count: 1276\nFunc value: 1814.3642859418874, Iteration: 14, Function Count: 1320\nFunc value: 1814.301102018856, Iteration: 15, Function Count: 1364\nFunc value: 1814.301098499327, Iteration: 16, Function Count: 1452\nFunc value: 1814.3010704933515, Iteration: 17, Function Count: 1540\nFunc value: 1814.296612835476, Iteration: 18, Function Count: 1716\nFunc value: 1814.2538448019918, Iteration: 19, Function Count: 1804\nFunc value: 1814.253749266872, Iteration: 20, Function Count: 1892\nFunc value: 1814.2536217543443, Iteration: 21, Function Count: 1936\nFunc value: 1814.2341819587186, Iteration: 22, Function Count: 2112\nFunc value: 1814.2190046927274, Iteration: 23, Function Count: 2156\nFunc value: 1814.1901664290635, Iteration: 24, Function Count: 2200\nFunc value: 1814.1900618989262, Iteration: 25, Function Count: 2288\nFunc value: 1814.1899629209177, Iteration: 26, Function Count: 2332\nFunc value: 1814.1315029565549, Iteration: 27, Function Count: 2552\nFunc value: 1814.1207160483482, Iteration: 28, Function Count: 2640\nFunc value: 1814.120651593227, Iteration: 29, Function Count: 2728\nFunc value: 1814.1206404952559, Iteration: 30, Function Count: 2816\nFunc value: 1814.093987040505, Iteration: 31, Function Count: 3080\nFunc value: 1814.0931557560025, Iteration: 32, Function Count: 3168\nFunc value: 1814.0922310255569, Iteration: 33, Function Count: 3212\nFunc value: 1814.0921898261458, Iteration: 34, Function Count: 3300\nFunc value: 1814.092112795961, Iteration: 35, Function Count: 3344\nFunc value: 1814.080248929288, Iteration: 36, Function Count: 3520\nFunc value: 1814.0799729900195, Iteration: 37, Function Count: 3608\nFunc value: 1814.079961881844, Iteration: 38, Function Count: 3696\nFunc value: 1814.0799614793552, Iteration: 39, Function Count: 3784\nFunc value: 1814.0757650935916, Iteration: 40, Function Count: 4092\nFunc value: 1814.0755830705248, Iteration: 41, Function Count: 4180\nFunc value: 1814.0755746091875, Iteration: 42, Function Count: 4268\nFunc value: 1814.0702842972405, Iteration: 43, Function Count: 4488\nFunc value: 1814.0700243731067, Iteration: 44, Function Count: 4576\nFunc value: 1814.0700110352632, Iteration: 45, Function Count: 4664\nFunc value: 1814.0678482400072, Iteration: 46, Function Count: 4840\nFunc value: 1814.067660339931, Iteration: 47, Function Count: 4928\nFunc value: 1814.067656754271, Iteration: 48, Function Count: 5016\nFunc value: 1814.065377183398, Iteration: 49, Function Count: 5236\nFunc value: 1814.0652521531151, Iteration: 50, Function Count: 5324\nFunc value: 1814.0652503654978, Iteration: 51, Function Count: 5412\nFunc value: 1814.0640861808768, Iteration: 52, Function Count: 5632\nFunc value: 1814.0640022668042, Iteration: 53, Function Count: 5720\nFunc value: 1814.0611488164795, Iteration: 54, Function Count: 5852\nFunc value: 1814.059515832646, Iteration: 55, Function Count: 5896\nFunc value: 1814.0595158325361, Iteration: 56, Function Count: 5940\nFunc value: 1814.0595158325355, Iteration: 57, Function Count: 6072\nWarning: Desired error not necessarily achieved due to precision loss.\n         Current function value: 1814.059516\n         Iterations: 57\n         Function evaluations: 9031\n         Gradient evaluations: 205\n\n\n\n\n\n\n\n\n\n\n\nHere we look at the risk premia estimates from the first step (inefficient) estimates.\n\n\n\n\n\n\nIn\u00a0[8]:\n\n    \npremia = step1opt[-3:]\npremia = Series(premia,index=['VWMe', 'SMB', 'HML'])\nprint('Annualized Risk Premia (First step)')\nprint(12 * premia)\n\n\n    \n\n\n\n\n\n\n\n\n\n    \n\n\n\nAnnualized Risk Premia (First step)\nVWMe    5.829995\nSMB     4.068224\nHML     1.680948\ndtype: float64\n\n\n\n\n\n\n\n\n\n\n\nNext the first step estimates are used to estimate the moment conditions which are in-turn used to estimate the optimal weighting matrix for the moment conditions.  This is then used as an input for the 2nd-step estimates.\n\n\n\n\n\n\nIn\u00a0[9]:\n\n    \nout = gmm_objective(step1opt, excessRet, factors, Winv, out=True)\nS = np.cov(out[1].T)\nWinv2 = inv(S)\nargs = (excessRet, factors, Winv2)\n\niteration = 0\nfunctionCount = 0\nstep2opt = fmin_bfgs(gmm_objective, step1opt, args=args, callback=iter_print)\n\n\n    \n\n\n\n\n\n\n\n\n\n    \n\n\n\nFunc value: 70.69178252370772, Iteration: 1, Function Count: 132\nFunc value: 69.26303959975596, Iteration: 2, Function Count: 176\nFunc value: 67.07244129650894, Iteration: 3, Function Count: 220\nFunc value: 64.57443451479321, Iteration: 4, Function Count: 264\nFunc value: 62.64097306083999, Iteration: 5, Function Count: 308\nFunc value: 60.38315319123633, Iteration: 6, Function Count: 352\nFunc value: 59.77131346063476, Iteration: 7, Function Count: 396\nFunc value: 59.016700262647376, Iteration: 8, Function Count: 440\nFunc value: 58.11824688768306, Iteration: 9, Function Count: 484\nFunc value: 57.16139475771817, Iteration: 10, Function Count: 528\nFunc value: 56.54119670206884, Iteration: 11, Function Count: 572\nFunc value: 55.76261111890216, Iteration: 12, Function Count: 616\nFunc value: 54.70774239263665, Iteration: 13, Function Count: 660\nFunc value: 54.16273697904013, Iteration: 14, Function Count: 748\nFunc value: 53.68442984106602, Iteration: 15, Function Count: 792\nFunc value: 53.24912513313372, Iteration: 16, Function Count: 836\nFunc value: 52.95654923541569, Iteration: 17, Function Count: 880\nFunc value: 52.70763030807515, Iteration: 18, Function Count: 924\nFunc value: 52.40947922763522, Iteration: 19, Function Count: 968\nFunc value: 52.28025850343027, Iteration: 20, Function Count: 1012\nFunc value: 52.0945930956645, Iteration: 21, Function Count: 1056\nFunc value: 51.92591993694722, Iteration: 22, Function Count: 1100\nFunc value: 51.69127887764556, Iteration: 23, Function Count: 1144\nFunc value: 51.32800767550518, Iteration: 24, Function Count: 1188\nFunc value: 50.8832556502003, Iteration: 25, Function Count: 1232\nFunc value: 50.61502081122463, Iteration: 26, Function Count: 1276\nFunc value: 50.3253061036018, Iteration: 27, Function Count: 1320\nFunc value: 49.82326422689157, Iteration: 28, Function Count: 1364\nFunc value: 49.458055584312206, Iteration: 29, Function Count: 1408\nFunc value: 49.30507269503761, Iteration: 30, Function Count: 1452\nFunc value: 49.080604460391186, Iteration: 31, Function Count: 1496\nFunc value: 48.86937171160105, Iteration: 32, Function Count: 1540\nFunc value: 48.76039718096907, Iteration: 33, Function Count: 1628\nFunc value: 48.61522962324979, Iteration: 34, Function Count: 1672\nFunc value: 48.43822338181308, Iteration: 35, Function Count: 1716\nFunc value: 48.223264727455955, Iteration: 36, Function Count: 1760\nFunc value: 48.119297612182464, Iteration: 37, Function Count: 1804\nFunc value: 47.9966953205165, Iteration: 38, Function Count: 1848\nFunc value: 47.82071403838669, Iteration: 39, Function Count: 1892\nFunc value: 47.59984420196816, Iteration: 40, Function Count: 1936\nFunc value: 47.19190580374522, Iteration: 41, Function Count: 1980\nFunc value: 46.46434101774428, Iteration: 42, Function Count: 2024\nFunc value: 46.17952767128317, Iteration: 43, Function Count: 2112\nFunc value: 45.64869841620502, Iteration: 44, Function Count: 2156\nFunc value: 44.79178194363791, Iteration: 45, Function Count: 2200\nFunc value: 44.31246192707072, Iteration: 46, Function Count: 2244\nFunc value: 44.31220746711396, Iteration: 47, Function Count: 2288\nFunc value: 44.31216779746252, Iteration: 48, Function Count: 2332\nFunc value: 44.31216776026349, Iteration: 49, Function Count: 2376\nFunc value: 44.31216775979089, Iteration: 50, Function Count: 2420\nFunc value: 44.31216775977227, Iteration: 51, Function Count: 2464\nFunc value: 44.31216775977222, Iteration: 52, Function Count: 3564\nWarning: Desired error not necessarily achieved due to precision loss.\n         Current function value: 44.312168\n         Iterations: 52\n         Function evaluations: 6786\n         Gradient evaluations: 154\n\n\n\n\n\n\n\n\n\n\n\nFinally the VCV of the parameter estimates is computed.\n\n\n\n\n\n\nIn\u00a0[10]:\n\n    \nout = gmm_objective(step2opt, excessRet, factors, Winv2, out=True)\nG = gmm_G(step2opt, excessRet, factors)\nS = np.cov(out[1].T)\nvcv = inv(G @ inv(S) @ G.T)/T\n\n\n    \n\n\n\n\n\n\n\nThe annualized risk premia and their associated t-stats.\n\n\n\n\n\n\nIn\u00a0[11]:\n\n    \npremia = step2opt[-3:]\npremia = Series(premia,index=['VWMe', 'SMB', 'HML'])\npremia_vcv = vcv[-3:,-3:]\nprint('Annualized Risk Premia')\nprint(12 * premia)\n\npremia_stderr = np.diag(premia_vcv)\npremia_stderr = Series(premia_stderr,index=['VWMe', 'SMB', 'HML'])\nprint('T-stats')\nprint(premia / premia_stderr)\n\n\n    \n\n\n\n\n\n\n\n\n\n    \n\n\n\nAnnualized Risk Premia\nVWMe    10.089708\nSMB      3.457167\nHML      7.620110\ndtype: float64\nT-stats\nVWMe    28.282294\nSMB     22.372714\nHML     43.791637\ndtype: float64",
      "tags": "",
      "url": "https://bashtage.github.io/kevinsheppard.com/teaching/python/notes/notebooks/example-gmm-estimation/"
    },
    {
      "title": "Example: LaTeX Output",
      "text": "Example: Exporting to $\\LaTeX$\u00b6The first code block contains the imports needed and defines a flag which determines whether the \noutput $\\LaTeX$ should be compiled.\n\n\n\n\n\n\nIn\u00a0[1]:\n\n    \n# imports\nimport numpy as np\nimport subprocess\n\n# Flag to compile output tables\ncompileLatex = False\n\n\n    \n\n\n\n\n\n\n\nThe next code block loads the npz file created using the output from the Fama-MacBeth example.\nThe second part shows a generic method to restore all variables. The loaded data is in a dictionary,\nand so iterating over the keys and using globals() (a dictionary) in the main program.\n\n\n\n\n\n\nIn\u00a0[2]:\n\n    \n# Load variables\nf = np.load('fama-macBeth-results.npz')\ndata = f.items()\n# Manually load parameters and std errors\narp = f['arp']\narpSE = f['arpSE']\nbeta = f['beta']\nbetaSE = f['betaSE']\nJ = f['J']\nJpval = f['Jpval']\n\n# Generic restore of all data in a npz file\nfor key in f.keys():\n    globals()[key] = f[key]\nf.close()\n\n\n    \n\n\n\n\n\n\n\nThe document is be stored in a list. The first few lines contain the required header for a\n$\\LaTeX$ document, including some packages used to improve table display and to select a custom font.\n\n\n\n\n\n\nIn\u00a0[3]:\n\n    \n# List to hold table\nlatex = []\n# Initializd LaTeX document\nlatex.append(r'\\documentclass[a4paper]{article}')\nlatex.append(r'\\usepackage{amsmath}')\nlatex.append(r'\\usepackage{booktabs}')\nlatex.append(r'\\usepackage[adobe-utopia]{mathdesign}')\nlatex.append(r'\\usepackage[T1]{fontenc}')\nlatex.append(r'\\begin{document}')\n\n\n    \n\n\n\n\n\n\n\nTable 1 is stored in its own list, and then extend will be used to add it to the main list.\n\n\n\n\n\n\nIn\u00a0[4]:\n\n    \n# Table 1\ntable1 = []\ntable1.append(r'\\begin{center}')\ntable1.append(r'\\begin{tabular}{lrrr} \\toprule')\n# Header\ncolNames = [r'VWM$e$','SMB','HML']\nheader = ''\nfor cName in colNames:\n    header += ' & ' + cName\n\nheader += r'\\\\ \\cmidrule{2-4}'\ntable1.append(header)\n# Main row\nrow = ''\nfor a,se in zip(arp,arpSE):\n    row += r' & $\\underset{{({0:0.3f})}}{{{1:0.3f}}}$'.format(se,a)\ntable1.append(row)\n# Blank row\nrow = r'\\\\'\ntable1.append(row)\n# J-stat row\nrow = r'J-stat: $\\underset{{({0:0.3f})}}{{{1:0.1f}}}$ \\\\'.format(float(Jpval),float(J))\ntable1.append(row)\ntable1.append(r'\\bottomrule \\end{tabular}')\ntable1.append(r'\\end{center}')\n# Extend latex with table 1\nlatex.extend(table1)\nlatex.append(r'\\newpage')\n\n\n    \n\n\n\n\n\n\n\nTable 2 is a bit more complex, and uses loops to iterate over the rows of the arrays containing\nthe $\\beta$s and their standard errors.\n\n\n\n\n\n\nIn\u00a0[5]:\n\n    \n# Format information for table 2\nsizes = ['S','2','3','4','B']\nvalues = ['L','2','3','4','H']\n# Table 2 has the same header as table 1, copy with a slice\ntable2 = table1[:3]\nm = 0\nfor i in range(len(sizes)):\n    for j in range(len(values)):\n        row = 'Size: {:}, Value: {:} '.format(sizes[i],values[j])\n        b = beta[:,m]\n        s = betaSE[m,1:]\n        for k in range(len(b)):\n            row += r' & $\\underset{{({0:0.3f})}}{{{1: .3f}}}$'.format(s[k],b[k])\n        row += r'\\\\ '\n        table2.append(row)\n        m += 1\n    if i<(len(sizes)-1):\n        table2.append(r'\\cmidrule{2-4}')\n\ntable2.append(r'\\bottomrule \\end{tabular}')\ntable2.append(r'\\end{center}')\n# Extend with table 2\nlatex.extend(table2)\n\n\n    \n\n\n\n\n\n\n\nThe penultimate block finished the document, and uses write to write the lines to the $\\LaTeX$ file.\n\n\n\n\n\n\nIn\u00a0[6]:\n\n    \n# Finish document   \nlatex.append(r'\\end{document}')\n# Write to table\nfid = open('latex.tex','w')\nfor line in latex:\n    fid.write(line + '\\n')\nfid.close()\n\n\n    \n\n\n\n\n\n\n\nFinally, if the flag is set, subprocess is used to compile the LaTeX.\n\n\n\n\n\n\nIn\u00a0[7]:\n\n    \n# Compile if needed\nif compileLatex:\n    exitStatus = subprocess.run(['pdflatex', 'latex.tex'])",
      "tags": "",
      "url": "https://bashtage.github.io/kevinsheppard.com/teaching/python/notes/notebooks/example-latex-output/"
    },
    {
      "title": "Python Course",
      "text": "This course is an introduction to Python and programming aimed at students working\nin Finance and Economics. The course is designed to be taught using the Jupyter notebooks\nthat are in the course GitHub repository and\nare linked below. The complete course is available for\ndownload as a pdf.\nGitHub\u00b6\nThe introduction is available on Github. \nIf you are happy to use git, you can download everything\nusing git, or for even fork the repo and save your progress to your own fork.\nNotebooks\u00b6\n\nLesson 1 (notebook)\nLesson 2 (notebook)\nLesson 3 (notebook)\nLesson 4 (notebook)\nLesson 5 (notebook)\nLesson 6 (notebook)\nLesson 7 (notebook)\nLesson 8 (notebook)\nLesson 9 (notebook)\n\nDownloading: Right-click and select Download to save the notebook files to your computer.\nData and Supporting Files\u00b6\nData",
      "tags": "",
      "url": "https://bashtage.github.io/kevinsheppard.com/teaching/python/course/"
    },
    {
      "title": "Specimen",
      "text": "Specimen\u00b6\nBody copy\u00b6\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Cras arcu libero,\nmollis sed massa vel, ornare viverra ex. Mauris a ullamcorper lacus. Nullam\nurna elit, malesuada eget finibus ut, ullamcorper ac tortor. Vestibulum sodales\npulvinar nisl, pharetra aliquet est. Quisque volutpat erat ac nisi accumsan\ntempor.\nSed suscipit, orci non pretium pretium, quam mi gravida metus, vel\nvenenatis justo est condimentum diam. Maecenas non ornare justo. Nam a ipsum\neros. Nulla aliquam orci sit amet nisl posuere malesuada. Proin aliquet\nnulla velit, quis ultricies orci feugiat et. Ut tincidunt sollicitudin\ntincidunt. Aenean ullamcorper sit amet nulla at interdum.\nHeadings\u00b6\nThe 3rd level\u00b6\nThe 4th level\u00b6\nThe 5th level\u00b6\nThe 6th level\u00b6\nHeadings with secondary text\u00b6\nThe 3rd level with secondary text\u00b6\nThe 4th level with secondary text\u00b6\nThe 5th level with secondary text\u00b6\nThe 6th level with secondary text\u00b6\nBlockquotes\u00b6\n\nMorbi eget dapibus felis. Vivamus venenatis porttitor tortor sit amet rutrum.\n  Pellentesque aliquet quam enim, eu volutpat urna rutrum a. Nam vehicula nunc\n  mauris, a ultricies libero efficitur sed. Class aptent taciti sociosqu ad\n  litora torquent per conubia nostra, per inceptos himenaeos. Sed molestie\n  imperdiet consectetur.\n\nBlockquote nesting\u00b6\n\nSed aliquet, neque at rutrum mollis, neque nisi tincidunt nibh, vitae\n  faucibus lacus nunc at lacus. Nunc scelerisque, quam id cursus sodales, lorem\n  libero fermentum urna, ut efficitur elit ligula et nunc.\n\nMauris dictum mi lacus, sit amet pellentesque urna vehicula fringilla.\n    Ut sit amet placerat ante. Proin sed elementum nulla. Nunc vitae sem odio.\n    Suspendisse ac eros arcu. Vivamus orci erat, volutpat a tempor et, rutrum.\n    eu odio.\n\nSuspendisse rutrum facilisis risus, eu posuere neque commodo a.\n      Interdum et malesuada fames ac ante ipsum primis in faucibus. Sed nec leo\n      bibendum, sodales mauris ut, tincidunt massa.\n\n\n\nOther content blocks\u00b6\n\nVestibulum vitae orci quis ante viverra ultricies ut eget turpis. Sed eu\n  lectus dapibus, eleifend nulla varius, lobortis turpis. In ac hendrerit nisl,\n  sit amet laoreet nibh.\n\nvar _extends = function(target) {\nfor (var i = 1; i < arguments.length; i++) {\n  var source = arguments[i];\n  for (var key in source) {\n    target[key] = source[key];\n  }\n}\nreturn target;\n};\n\n\n\n\n\nPraesent at return target, sodales nibh vel, tempor felis. Fusce\n      vel lacinia lacus. Suspendisse rhoncus nunc non nisi iaculis ultrices.\n      Donec consectetur mauris non neque imperdiet, eget volutpat libero.\n\n\nLists\u00b6\nUnordered lists\u00b6\n\n\nSed sagittis eleifend rutrum. Donec vitae suscipit est. Nullam tempus tellus\n  non sem sollicitudin, quis rutrum leo facilisis. Nulla tempor lobortis orci,\n  at elementum urna sodales vitae. In in vehicula nulla, quis ornare libero.\n\nDuis mollis est eget nibh volutpat, fermentum aliquet dui mollis.\nNam vulputate tincidunt fringilla.\nNullam dignissim ultrices urna non auctor.\n\n\n\nAliquam metus eros, pretium sed nulla venenatis, faucibus auctor ex. Proin ut\n  eros sed sapien ullamcorper consequat. Nunc ligula ante, fringilla at aliquam\n  ac, aliquet sed mauris.\n\n\nNulla et rhoncus turpis. Mauris ultricies elementum leo. Duis efficitur\n  accumsan nibh eu mattis. Vivamus tempus velit eros, porttitor placerat nibh\n  lacinia sed. Aenean in finibus diam.\n\n\nOrdered lists\u00b6\n\n\nInteger vehicula feugiat magna, a mollis tellus. Nam mollis ex ante, quis\n  elementum eros tempor rutrum. Aenean efficitur lobortis lacinia. Nulla\n  consectetur feugiat sodales.\n\n\nCum sociis natoque penatibus et magnis dis parturient montes, nascetur\n  ridiculus mus. Aliquam ornare feugiat quam et egestas. Nunc id erat et quam\n  pellentesque lacinia eu vel odio.\n\n\nVivamus venenatis porttitor tortor sit amet rutrum. Pellentesque aliquet\n  quam enim, eu volutpat urna rutrum a. Nam vehicula nunc mauris, a\n  ultricies libero efficitur sed.\n\nMauris dictum mi lacus\nUt sit amet placerat ante\nSuspendisse ac eros arcu\n\n\n\nMorbi eget dapibus felis. Vivamus venenatis porttitor tortor sit amet\n  rutrum. Pellentesque aliquet quam enim, eu volutpat urna rutrum a. Sed\n  aliquet, neque at rutrum mollis, neque nisi tincidunt nibh.\n\n\nPellentesque eget var _extends ornare tellus, ut gravida mi.\n\n\n\n\nvar _extends = function(target) {\n  for (var i = 1; i < arguments.length; i++) {\n    var source = arguments[i];\n    for (var key in source) {\n      target[key] = source[key];\n    }\n  }\n  return target;\n};\n\n\n\n\nVivamus id mi enim. Integer id turpis sapien. Ut condimentum lobortis\n  sagittis. Aliquam purus tellus, faucibus eget urna at, iaculis venenatis\n  nulla. Vivamus a pharetra leo.\n\nDefinition lists\u00b6\n\nLorem ipsum dolor sit amet\n\nSed sagittis eleifend rutrum. Donec vitae suscipit est. Nullam tempus\ntellus non sem sollicitudin, quis rutrum leo facilisis. Nulla tempor\nlobortis orci, at elementum urna sodales vitae. In in vehicula nulla.\nDuis mollis est eget nibh volutpat, fermentum aliquet dui mollis.\nNam vulputate tincidunt fringilla.\nNullam dignissim ultrices urna non auctor.\n\nCras arcu libero\n\nAliquam metus eros, pretium sed nulla venenatis, faucibus auctor ex. Proin\nut eros sed sapien ullamcorper consequat. Nunc ligula ante, fringilla at\naliquam ac, aliquet sed mauris.\n\n\nCode blocks\u00b6\nInline\u00b6\nMorbi eget dapibus felis. Vivamus venenatis porttitor tortor sit amet\nrutrum. Class aptent taciti sociosqu ad litora torquent per conubia nostra,\nper inceptos himenaeos. Pellentesque aliquet quam enim, eu volutpat urna\nrutrum a.\nNam vehicula nunc return target mauris, a ultricies libero efficitur\nsed. Sed molestie imperdiet consectetur. Vivamus a pharetra leo. Pellentesque\neget ornare tellus, ut gravida mi. Fusce vel lacinia lacus.\nListing\u00b6\n1\n2\n3\n4\n5\n6\n7\n8\n9var _extends = function(target) {\n  for (var i = 1; i < arguments.length; i++) {\n    var source = arguments[i];\n    for (var key in source) {\n      target[key] = source[key];\n    }\n  }\n  return target;\n};\n\n\n\nHorizontal rules\u00b6\nAenean in finibus diam. Duis mollis est eget nibh volutpat, fermentum aliquet\ndui mollis. Nam vulputate tincidunt fringilla. Nullam dignissim ultrices urna\nnon auctor.\n\nInteger vehicula feugiat magna, a mollis tellus. Nam mollis ex ante, quis\nelementum eros tempor rutrum. Aenean efficitur lobortis lacinia. Nulla\nconsectetur feugiat sodales.\nData tables\u00b6\n\n\n\nSollicitudo / Pellentesi\nconsectetur\nadipiscing\nelit\narcu\nsed\n\n\n\n\nVivamus a pharetra\nyes\nyes\nyes\nyes\nyes\n\n\nOrnare viverra ex\nyes\nyes\nyes\nyes\nyes\n\n\nMauris a ullamcorper\nyes\nyes\npartial\nyes\nyes\n\n\nNullam urna elit\nyes\nyes\nyes\nyes\nyes\n\n\nMalesuada eget finibus\nyes\nyes\nyes\nyes\nyes\n\n\nUllamcorper\nyes\nyes\nyes\nyes\nyes\n\n\nVestibulum sodales\nyes\n-\nyes\n-\nyes\n\n\nPulvinar nisl\nyes\nyes\nyes\n-\n-\n\n\nPharetra aliquet est\nyes\nyes\nyes\nyes\nyes\n\n\nSed suscipit\nyes\nyes\nyes\nyes\nyes\n\n\nOrci non pretium\nyes\npartial\n-\n-\n-\n\n\n\nSed sagittis eleifend rutrum. Donec vitae suscipit est. Nullam tempus tellus\nnon sem sollicitudin, quis rutrum leo facilisis. Nulla tempor lobortis orci,\nat elementum urna sodales vitae. In in vehicula nulla, quis ornare libero.\n\n\n\nLeft\nCenter\nRight\n\n\n\n\nLorem\ndolor\namet\n\n\nipsum\nsit\n\n\n\n\nVestibulum vitae orci quis ante viverra ultricies ut eget turpis. Sed eu\nlectus dapibus, eleifend nulla varius, lobortis turpis. In ac hendrerit nisl,\nsit amet laoreet nibh.\n\n  \n    \n    \n  \n  \n    \n      Table\n      with colgroups (Pandoc)\n    \n  \n  \n    \n      Lorem\n      ipsum dolor sit amet.\n    \n    \n      Sed sagittis\n      eleifend rutrum. Donec vitae suscipit est.",
      "tags": "",
      "url": "https://bashtage.github.io/kevinsheppard.com/specimen/"
    },
    {
      "title": "Research",
      "text": "Write your page here.",
      "tags": "",
      "url": "https://bashtage.github.io/kevinsheppard.com/research/"
    },
    {
      "title": "LyX",
      "text": "LyX is a powerful WSYIWYG editor\nfor LaTeX. I am an avid user of LyX since it allows for a highly productive environment for \nwriting text and formatted math while continuing to allow for a high degree of customizability. \nLyX is an open source version of Scientific Workplace which is both more modern and has broader\ncompatibility with standard LaTeX.\nLyX is cross platform and works equally well on Windows, Linux or OS X.\nThese videos comprise a basic introduction to LyX and cover the core tools needed to write a \nThesis or paper in Economics or Econometrics (and many other fields, especially in mathematics, \nstatistics or social sciences).\nVideo Introduction\u00b6\n\nInstalling LyX on Windows\nInstalling LyX on Linux\nSetting up a New Document and Basic Structure\nBasic Text Input\nList Environments\nAdding Math\nTables\nFigures\nThe Bibliography\nAdding Custom LaTeX in LyX\nExporting Completed Documents\nPresentations (Beamer) in LyX\n\nWritten Guidance\u00b6\nSome people prefer a written guide. Fortunately (for me), a good guide has been written \n(by others) and is available at Lyx Guide.",
      "tags": "lyx",
      "url": "https://bashtage.github.io/kevinsheppard.com/teaching/lyx/"
    },
    {
      "title": "Archived and Other Teaching",
      "text": "Website-related content\u00b6\nSpecimen\nNotebook Specimen",
      "tags": "",
      "url": "https://bashtage.github.io/kevinsheppard.com/teaching/other/"
    },
    {
      "title": "MATLAB",
      "text": "Under Construction\u00b6\n This content has not been ported from my other site.",
      "tags": "",
      "url": "https://bashtage.github.io/kevinsheppard.com/teaching/matlab/"
    },
    {
      "title": "Python",
      "text": "Python Notes\u00b6\nA set of notes that introduce the core concepts of Python that\nare relevant to applications in Statistics, Econometrics and many other\nnumerical areas. Codes Python fundamentals, NumPy, Pandas,\nand some parts of SciPy and statsmdoels.  \nPython Notes\nIntroductory Python Course\u00b6\nA short course designed for people new to Python, and often new\nto programming.  Starts with the basics - getting the Python environemnt\nright, and work through entering arrays and pandas DataFrame, selecting\nelements, basic looping and graphics.  \nIntroductory Course",
      "tags": "",
      "url": "https://bashtage.github.io/kevinsheppard.com/teaching/python/"
    },
    {
      "title": "Python Notes",
      "text": "Python Notes\u00b6\nIntroduction to Python for Econometrics, Statistics and Numerical Analysis: Third Edition \nNew material added to the third edition on January 3, 2018.\nDownload the Notes\nPython is a widely used general purpose programming language, which\nhappens to be well suited to econometrics, data analysis and other more\ngeneral numeric problems. These notes provide an introduction to Python\nfor a beginning programmer. They may also be useful for an experienced\nPython programmer interested in using NumPy, SciPy, matplotlib and\npandas for numerical and statistical analysis (if this is the case, much\nof the beginning can be skipped).\nThird edition, Update 1\u00b6\n\nVerified that all code and examples work correctly against 2019 versions of modules. The\n   notable packages and their versions are:\nPython 3.7 (Preferred version)\nNumPy: 1.16\nSciPy: 1.3\npandas: 0.25\nmatplotlib: 3.1\nPython 2.7 support has been officially dropped, although most examples continue to work with 2.7.\n   Do not Python 2.7 in 2019 for numerical code.\n\nThird edition update\u00b6\n\nRewritten installation section focused exclusively on using\n    Continuum\\'s Anaconda.\nPython 3.5 is the default version of Python instead of 2.7. Python\n    3.5 (or newer) is well supported by the Python packages required to\n    analyze data and perform statistical analysis, and bring some new\n    useful features, such as a new operator for matrix multiplication\n    (@).\nRemoved distinction between integers and longs in built-in data\n    types chapter. This distinction is only relevant for Python 2.7.\ndot has been removed from most examples and replaced with @ to\n    produce more readable code.\nSplit Cython and Numba into separate chapters to highlight the\n    improved capabilities of Numba.\nVerified all code working on current versions of core libraries\n    using Python 3.5.\npandas\nUpdated syntax of pandas functions such as resample.\nAdded pandas Categorical.\nExpanded coverage of pandas groupby.\nExpanded coverage of date and time data types and functions.\n\n\nNew chapter introducing statsmodels, a package that facilitates\n    statistical analysis of data. statsmodels includes regression\n    analysis, Generalized Linear Models (GLM) and time-series analysis\n    using ARIMA models.\n\nSecond edition update\u00b6\n\nImproved Cython and Numba sections\nAdded sections discussing interfacing with C code\nAdded sections to the chapter on running code in Parallel covering\n    IPython\\'s cluster server and joblib\nFurther improvements in the installation based on feedback from the\n    Python Course\nUpdated Anaconda to 1.9\nAdded information about using Spyder as an initial IDE.\nAdded packages for Spyder to the installation instructions.\n\nNew in second edition\u00b6\n\nThe preferred installation method is now Continuum Analytics\\'\n    Anaconda. Anaconda is a complete scientific stack and is available\n    for all major platforms.\nNew chapter on pandas. pandas provides a simple but powerful tool to\n    manage data and perform basic analysis. It also greatly simplifies\n    importing and exporting data.\nNew chapter on advanced selection of elements from an array.\nNumba provides just-in-time compilation for numeric Python code\n    which often produces large performance gains when pure NumPy\n    solutions are not available (e.g. looping code).\nAddition to performance section covering line_profiler for\n    profiling code.\nDictionary, set and tuple comprehensions.\nNumerous typos fixed.\nAll code has been verified working against Anaconda 1.7.0.\n\nNotes\u00b6\nIntroduction to Python for Econometrics, Statistics and Numerical Analysis: Third Edition\nData and Notebooks\u00b6\nData\u00b6\n\nData and Code from the notes. These files are needed to run some of the code in the notes.\nThe Fama-French data set is used in the asset-pricing examples.\nThe FTSE 100 data from 1984 until 2012 is used in the GJR-GARCH example.\n\nNotebooks\u00b6\nThese notebooks contains the four extended examples from the Examples chapter.\n\nEstimation of a GJR-GARCH model (download)\nEstimation of risk premia using Fama-MacBeth (download)\nEstimation using the Generalized Method of Moments (GMM) (download)\nOutputting to LaTeX (download)\n\nMini-course\u00b6\nPython Course",
      "tags": "python",
      "url": "https://bashtage.github.io/kevinsheppard.com/teaching/python/notes/"
    },
    {
      "title": "MFE Teaching Resources",
      "text": "This is a place holder for the 2019/20 MFE Course content. I lecture in Hilary term.\nMATLAB\u00b6\nThe companion course is designed to accompany Financial Econometrics I and II and\nto provide tools needed in Empirical Asset pricing.",
      "tags": "",
      "url": "https://bashtage.github.io/kevinsheppard.com/teaching/mfe/"
    },
    {
      "title": "Welcome",
      "text": "Write your post here.",
      "tags": "",
      "url": "https://bashtage.github.io/kevinsheppard.com/blog/welcome/"
    },
    {
      "title": "Subpage2",
      "text": "This is a subpage",
      "tags": "",
      "url": "https://bashtage.github.io/kevinsheppard.com/subpages/subpage/"
    },
    {
      "title": "Subpage",
      "text": "This is not really a subpage.",
      "tags": "",
      "url": "https://bashtage.github.io/kevinsheppard.com/subpage/"
    },
    {
      "title": "index",
      "text": "",
      "tags": "",
      "url": "https://bashtage.github.io/kevinsheppard.com/"
    },
    {
      "title": "Welcome",
      "text": "Write your page here.",
      "tags": "",
      "url": "https://bashtage.github.io/kevinsheppard.com/welcome/"
    },
    {
      "title": "Kevin Sheppard's Photos",
      "text": "body {\n    background-color: #212121 !important;\n  }\n  nav  div.dropdown-menu {\n      background-color: #212121 !important;\n  }\n  nav a.dropdown-item:hover {\n    background-color: #303030 !important;\n  }\n  nav a {\n    color: #f8f8f8 !important;\n  }\n    input.form-control, input.custom-file-control, input.form-control::placeholder, input.custom-file-control::placeholder {\n    color: #666 !important;\n  }\n   .form-control:focus {\n        border-color: #f8f8f8 !important;\n  }\n  .form-control, .custom-file-control, .is-focused .form-control, .is-focused .custom-file-control {\n    background-image: linear-gradient(to top, #f8f8f8 2px, rgba(9, 92, 159, 0) 2px), linear-gradient(to top, rgba(0, 0, 0, 0.26) 0, rgba(0, 0, 0, 0) 0);\n  }\n  input.bg-light {\n    background: transparent !important;\n  }\n.bg-page {\n    color: #f5f5f5 !important;\n    background-color: rgba(0, 0, 0, 0) !important;;\n    border-color: #f5f5f5 !important;;\n}\n\n\n    \n    \n        \n        \n        \n            \n                \n                    \n                \n                \n                    Callie (2015)\n                \n            \n        \n        \n        \n        \n        \n            \n                \n                    \n                \n                \n                    Hawaii (2012)\n                \n            \n        \n        \n        \n        \n        \n            \n                \n                    \n                \n                \n                    Yosemite (2012)\n                \n            \n        \n        \n        \n        \n        \n            \n                \n                    \n                \n                \n                    Lake District (2011)\n                \n            \n        \n        \n        \n        \n        \n            \n                \n                    \n                \n                \n                    Arizona (2010)\n                \n            \n        \n        \n        \n        \n        \n            \n                \n                    \n                \n                \n                    MLK Memorial (2010)\n                \n            \n        \n        \n        \n        \n        \n            \n                \n                    \n                \n                \n                    Quito (2008)\n                \n            \n        \n        \n        \n        \n        \n            \n                \n                    \n                \n                \n                    Austin (2007)\n                \n            \n        \n        \n        \n        \n        \n            \n                \n                    \n                \n                \n                    Australia (2006)\n                \n            \n        \n        \n        \n        \n        \n            \n                \n                    \n                \n                \n                    California (2005)\n                \n            \n        \n        \n        \n        \n        \n            \n                \n                    \n                \n                \n                    Washington (2003)\n                \n            \n        \n        \n        \n        \n        \n            \n                \n                    \n                \n                \n                    Italy (2002)\n                \n            \n        \n        \n        \n        \n        \n            \n                \n                    \n                \n                \n                    ECB (2002)\n                \n            \n        \n        \n        \n        \n        \n            \n                \n                    \n                \n                \n                    London (2001)\n                \n            \n        \n        \n        \n        \n        \n            \n                \n                    \n                \n                \n                    Wales (2001)",
      "tags": "",
      "url": "https://bashtage.github.io/kevinsheppard.com/photos/"
    },
    {
      "title": "Search",
      "text": "Search results appear here.",
      "tags": "",
      "url": "https://bashtage.github.io/kevinsheppard.com/search/"
    }
  ]
};